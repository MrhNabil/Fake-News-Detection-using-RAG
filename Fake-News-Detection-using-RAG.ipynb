{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dC8xxC7ZEjPm",
        "outputId": "dfe7c76f-97e5-4ada-9eb8-644d424a5b61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Project folders ready: /content/fake-news-rag\n"
          ]
        }
      ],
      "source": [
        "%pip -q install --upgrade pip\n",
        "%pip -q install sentence-transformers==2.7.0 faiss-cpu\n",
        "%pip -q install pandas numpy scikit-learn matplotlib tqdm langdetect\n",
        "%pip -q install beautifulsoup4 requests\n",
        "%pip -q install gradio\n",
        "\n",
        "import os, sys, json, re, time, math, textwrap, random\n",
        "from pathlib import Path\n",
        "\n",
        "# Persistent base dir (Colab: /content)\n",
        "BASE_DIR = Path(\"/content/fake-news-rag\")\n",
        "DATA_DIR = BASE_DIR / \"data\"\n",
        "RAW_DIR = DATA_DIR / \"raw\"\n",
        "PROC_DIR = DATA_DIR / \"processed\"\n",
        "MODEL_DIR = BASE_DIR / \"models\"\n",
        "EMB_DIR = MODEL_DIR / \"embeddings\"\n",
        "\n",
        "for d in [BASE_DIR, DATA_DIR, RAW_DIR, PROC_DIR, MODEL_DIR, EMB_DIR]:\n",
        "    d.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"Project folders ready:\", BASE_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOWhuIETFA7F",
        "outputId": "d4b73ef9-4910-4606-c33f-830dc287b835"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.100.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.14.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
            "<think>\n",
            "Okay, let's see what kind of problem I need to solve here. The user mentioned \"Phi-4 Mini!\" and called me Phi. Hmm, maybe there's a trick here. Let me check the original message again.\n",
            "\n",
            "The user wrote: \"You will be given a problem. Please reason step by step, and put your final answer within \\boxed{}: Hello, Phi-4 Mini!\" \n",
            "\n",
            "Wait, so the problem is just the phrase \"Hello, Phi-4 Mini!\"? That seems a bit odd. Maybe it's a riddle or a puzzle related to the name itself. Let's break it down.\n",
            "\n",
            "First, \"Phi-4 Mini!\" Phi... Oh, Phi could refer to the golden ratio, which is approximately 1.618. The \"4 Mini\" part might be indicating version 4, but mini? Maybe it's a play on words. Let's think about the letters. \n",
            "\n",
            "Phi is the Greek letter œÜ. The \"-4 Mini\" could be a reference to something else. Maybe electrical circuits? The PHI-4 could be a model of a device, and Mini might refer to a small version. But I'm not sure. Alternatively, could it be something to do with the periodic table? Phosphorus is element 15, but maybe not. Wait, maybe it's a calculator puzzle. If I take the letters in \"Phi-4 Mini!\" and convert them to their ASCII values or something.\n",
            "\n",
            "Let's try that. Let's take each character's ASCII code. Let's see:\n",
            "\n",
            "Hello, Phi-4 Mini!\n",
            "\n",
            "Breaking it down:\n",
            "\n",
            "H (72), e (101), l (108), l (108), o (111), , (44), space (32), P (80), h (104), i (105), - (45), 4 (52), space (32), M (77), i (105), n(i? Wait, M i n i? Let's check:\n",
            "\n",
            "H e l l o ,   P h i - 4   M i n i !\n",
            "\n",
            "Wait, \"Mini\" is M i n i. So M is 77, i is 105, n is 110, i is 105, and then exclamation mark is 33.\n",
            "\n",
            "So putting all those numbers together: 72, 101, 108, 108, 111, 44, 32, 80, 104, 105, 45, 52, 32, 77, 105, 110, 105, 33.\n",
            "\n",
            "Is there a pattern here? Maybe adding them up? Let's try:\n",
            "\n",
            "72 + 101 = 173\n",
            "\n",
            "173 + 108 = 281\n",
            "\n",
            "281 + 108 = 389\n",
            "\n",
            "389 + 111 = 500\n",
            "\n",
            "500 + 44 = 544\n",
            "\n",
            "544 + 32 = 576\n",
            "\n",
            "576 + 80 = 656\n",
            "\n",
            "656 + 104 = 760\n",
            "\n",
            "760 + 105 = 865\n",
            "\n",
            "865 + 45 = 910\n",
            "\n",
            "910 + 52 = 962\n",
            "\n",
            "962 + 32 = 994\n",
            "\n",
            "994 + 77 = 1071\n",
            "\n",
            "1071 + 105 = 1176\n",
            "\n",
            "1176 + 110 = 1286\n",
            "\n",
            "1286 + 105 = 1391\n",
            "\n",
            "1391 + 33 = 1424\n",
            "\n",
            "Total sum is 1424. Hmm, does that number mean anything? Not sure. Maybe not the right approach.\n",
            "\n",
            "Alternatively, maybe consider the phrase \"Phi-4 Mini!\" as a model number or something. Wait, PHI-4 Mini could be a reference to a calculator, like the Texas Instruments TI-84 Plus CE, but that's a stretch. Or maybe a smartphone model? Not sure.\n",
            "\n",
            "Wait, another thought: \"Phi-4 Mini\" might be hinting at a mathematical concept involving phi (the golden ratio) and a 4th iteration or a mini version. Maybe a fractal or a recursive formula? For example, the golden ratio is (1 + sqrt(5))/2, approximately 1.618. If we take phi to the 4th power, that's ((1 + sqrt(5))/2)^4. Let me calculate that:\n",
            "\n",
            "First, sqrt(5) is approximately 2.23607. So (1 + 2.23607)/2 = 1.61803. Then, 1.61803^4. Let's compute that step by step:\n",
            "\n",
            "1.61803^2 ‚âà 2.61803\n",
            "\n",
            "Then, 2.61803^2 ‚âà 6.8541\n",
            "\n",
            "So, phi^4 ‚âà 6.8541. Maybe that's the answer? But why would the problem be phrased as \"Hello, Phi-4 Mini!\"? Maybe it's a greeting to Phi, and the task is to compute phi^4.\n",
            "\n",
            "Alternatively, maybe it's a base conversion problem. \"Phi-4 Mini\" might refer to base 4, and \"Mini\" is a hint. Maybe convert \"Phi\" from base 4 to decimal? Let's see: \"Phi\" in base 4. Wait, \"Phi\" as a word, but each letter corresponds to a digit in base 4. But letters go up to 26, which is higher than base 4. Maybe the letters are Roman numerals? Let's check:\n",
            "\n",
            "Phi in Roman numerals is not a standard numeral. F is 5, I is 1, H is 8. Wait, but in \"Phi-4 Mini!\", maybe taking the letters P, H, I, etc., as Roman numerals. But P is not a Roman numeral. H is 500 in some contexts, but not standard. I is 1. Maybe this is not the right path.\n",
            "\n",
            "Wait, another angle: \"Phi-4 Mini!\" could be a reference to a version number, like Phi version 4 Mini. Maybe a software version, but I don't think that helps. Alternatively, maybe it's a play on \"phi four\" sounding like \"five four\" or something else. Not sure.\n",
            "\n",
            "Alternatively, maybe the exclamation mark is significant. In some contexts, \"!\" denotes a factorial. But phi-4 would be phi minus 4? But phi is approximately 1.618, so 1.618 - 4 = negative number. That doesn't seem helpful.\n",
            "\n",
            "Wait, maybe it's a concatenated number. \"Phi-4 Mini!\" could be 4-12 (if M is 13th letter) but not sure. Let's see: phi, 4, mini. Maybe 4 Mini represents days or something? Not helpful.\n",
            "\n",
            "Wait, going back to the original problem: the user says \"You will be given a problem. Please reason step by step...\" and the problem is \"Hello, Phi-4 Mini!\". So the task is probably to interpret this phrase as a math problem. Since Phi is related to the golden ratio, maybe the problem is to compute something about phi, specifically phi^4.\n",
            "\n",
            "Alternatively, maybe it's a cipher. Let's check if shifting letters. \"Phi-4 Mini!\" ‚Äì maybe each letter is shifted by 4? Let's try:\n",
            "\n",
            "Phi: P -> V, H -> L, I -> M. So \"Phi\" becomes \"VML\". Then \"Mini!\" becomes \"Olt!\" (M+4=O, i+4= m? Wait, i is the 9th letter, i+4 is m (13th). n+4= t (20th), i+4=m. So \"Mini\" becomes \"OmtM!\" Then the whole phrase becomes \"Hello, VLM OmtM!\". That doesn't make sense. Maybe shifting backwards by 4? P-4=P-4=G (P is 16th letter, 16-4=12= L), H-4=D (H is 8, 8-4=4=D), I-4=E (9-4=5=E). So \"Phi\" becomes \"D E\". Then \"Mini\": M-4=I (13-4=9=I), i-4= e (9-4=5=E), n-4= j (14-4=10=j), i-4=e. So \"Mini\" becomes \"I ej e!\". So the phrase becomes \"Hello, De E I ej e!\". That seems like gibberish. Maybe not.\n",
            "\n",
            "Alternatively, maybe take the letters and convert them to numbers: A=1, B=2, etc. Let's try:\n",
            "\n",
            "Hello, Phi-4 Mini!\n",
            "\n",
            "H=8, E=5, L=12, L=12, O=15, ,= maybe 44? Or just ignore punctuation. P=16, H=8, I=9, -, 4, M=13, I=9, N=14, I=9, !.\n",
            "\n",
            "So the numbers would be: 8,5,12,12,15,16,8,9,4,13,9,14,9. Then maybe phi-4 refers to taking the 4th number? The fourth number is 12. But 12 in letters is L. Not sure.\n",
            "\n",
            "Alternatively, maybe split the phrase into parts. \"Phi-4 Mini!\" could be split into \"Phi\" and \"4 Mini\". Phi is approximately 1.618, 4 Mini could be 4 times a mini something. Not helpful.\n",
            "\n",
            "Wait, maybe \"Mini\" refers to a Mini-MP3 or similar device, but not relevant here. Alternatively, in electronics, a mini version of a PHI-4 device. But I don't know what that device is.\n",
            "\n",
            "Alternatively, think of \"Phi\" as the Greek letter, which looks like a backwards F. Maybe a play on \"phi four\" sounding like \"five for\"? Not helpful.\n",
            "\n",
            "Wait, maybe it's a reference to a mathematical constant or a sequence. The golden ratio phi is (1 + sqrt(5))/2. Phi^4 would be [(1 + sqrt(5))/2]^4. Let's compute that:\n",
            "\n",
            "First, phi = (1 + sqrt(5))/2 ‚âà 1.618\n",
            "\n",
            "So phi^2 = phi + 1 ‚âà 2.618\n",
            "\n",
            "phi^3 = phi*phi^2 ‚âà 1.618*2.618 ‚âà 4.236\n",
            "\n",
            "phi^4 = phi*phi^3 ‚âà 1.618*4.236 ‚âà 6.854\n",
            "\n",
            "So phi^4 ‚âà 6.854. Maybe the answer is 6.854, but in exact terms?\n",
            "\n",
            "Let's compute phi^4 exactly:\n",
            "\n",
            "phi^2 = phi + 1\n",
            "\n",
            "phi^3 = phi*phi^2 = phi*(phi + 1) = phi^2 + phi = (phi + 1) + phi = 2phi + 1\n",
            "\n",
            "phi^4 = phi*phi^3 = phi*(2phi + 1) = 2phi^2 + phi = 2(phi + 1) + phi = 2phi + 2 + phi = 3phi + 2\n",
            "\n",
            "Since phi = (1 + sqrt(5))/2, substitute:\n",
            "\n",
            "3phi + 2 = 3*(1 + sqrt(5))/2 + 2 = (3 + 3sqrt(5))/2 + 4/2 = (7 + 3sqrt(5))/2\n",
            "\n",
            "So phi^4 = (7 + 3sqrt(5))/2. Let's check that:\n",
            "\n",
            "(7 + 3‚àö5)/2 ‚âà (7 + 6.708)/2 ‚âà 13.708/2 ‚âà 6.854, which matches the approximate value.\n",
            "\n",
            "So phi^4 can be expressed exactly as (7 + 3‚àö5)/2. Maybe that's the answer the problem is expecting. Given that the problem was presented as \"Hello, Phi-4 Mini!\", perhaps it's a greeting followed by the instruction to compute phi^4. Since Phi-4 could be read as phi to the 4th power.\n",
            "\n",
            "Alternatively, maybe the problem is expecting the value of phi minus 4, but that would be negative, which doesn't seem likely. Or perhaps phi multiplied by 4? phi*4 ‚âà 6.472. But the exact value would be 2(phi + 2) = 2*(1 + sqrt(5))/2 + 4 = (1 + sqrt(5)) + 4 = 5 + sqrt(5). Wait, no:\n",
            "\n",
            "Wait, phi = (1 + sqrt(5))/2\n",
            "\n",
            "4*phi = 4*(1 + sqrt(5))/2 = 2*(1 + sqrt(5)) = 2 + 2sqrt(5). That's approximately 2 + 4.472 = 6.472. But that's different from phi^4.\n",
            "\n",
            "Alternatively, maybe the problem is a trick question, and the answer is simply \"Hello, Phi-4 Mini!\" converted into a mathematical expression. But I can't see how.\n",
            "\n",
            "Wait, another angle: \"Phi-4 Mini!\" might be a way to write \"phi sub four\" in a stylized way. So the problem is to compute phi^4. As we did earlier, which is (7 + 3‚àö5)/2. So maybe the answer is that expression.\n",
            "\n",
            "Alternatively, the problem might be expecting the numerical value, approximately 6.854. But given that it's a math problem, exact form is preferable.\n",
            "\n",
            "Alternatively, perhaps the problem is a reference to the PHI-4, which is a model of a processor, and Mini refers to a small version, but I don't know the connection.\n",
            "\n",
            "Wait, considering that the user mentioned \"You will be given a problem. Please reason step by step...\", and the problem is \"Hello, Phi-4 Mini!\", maybe it's a test to see if I recognize that the problem is to compute phi^4, given the mention of Phi-4. Since \"Mini\" might be irrelevant or just a name.\n",
            "\n",
            "Therefore, after considering various possibilities, the most plausible answer is that the problem asks for phi^4, which is (7 + 3‚àö5)/2. So I'll go with that.\n",
            "</think>\n",
            "\n",
            "The problem presented is \"Hello, Phi-4 Mini!\" which appears to be a playful reference to calculating the fourth power of the golden ratio (œÜ). \n",
            "\n",
            "**Step-by-Step Explanation:**\n",
            "\n",
            "1. **Identify Key Terms:** The phrase mentions \"Phi-4,\" which refers to the golden ratio (œÜ) raised to the fourth power.\n",
            "2. **Recall the Golden Ratio:** œÜ = (1 + ‚àö5)/2 ‚âà 1.618.\n",
            "3. **Compute œÜ¬≤:** Using the property of œÜ, œÜ¬≤ = œÜ + 1.\n",
            "4. **Compute œÜ¬≥:** œÜ¬≥ = œÜ * œÜ¬≤ = œÜ(œÜ + 1) = 2œÜ + 1.\n",
            "5. **Compute œÜ‚Å¥:** œÜ‚Å¥ = œÜ * œÜ¬≥ = œÜ(2œÜ + 1) = 3œÜ + 2.\n",
            "6. **Substitute œÜ:** Substitute œÜ = (1 + ‚àö5)/2 into the expression:\n",
            "   - 3œÜ + 2 = 3*(1 + ‚àö5)/2 + 2 = (3 + 3‚àö5)/2 + 4/2 = (7 + 3‚àö5)/2.\n",
            "\n",
            "**Final Answer:**  \n",
            "The exact value of œÜ‚Å¥ is \\boxed{\\dfrac{7 + 3\\sqrt{5}}{2}}.\n"
          ]
        }
      ],
      "source": [
        "# Install the OpenAI Python SDK\n",
        "!pip install openai\n",
        "\n",
        "import os\n",
        "from openai import AzureOpenAI\n",
        "\n",
        "# Set your Azure OpenAI endpoint and API key (from Azure portal)\n",
        "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"\"\n",
        "os.environ[\"AZURE_OPENAI_API_KEY\"]  = \"\"\n",
        "\n",
        "# Create the AzureOpenAI client\n",
        "client = AzureOpenAI(\n",
        "    azure_endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
        "    api_key=os.environ[\"AZURE_OPENAI_API_KEY\"],\n",
        "    api_version=\"\"  # use the latest supported API version\n",
        ")\n",
        "\n",
        "# Send a chat completion request to your Phi-4 Mini deployment\n",
        "response = client.chat.completions.create(\n",
        "    model=\"Phi-4-mini-reasoning-2\",  # your Phi-4 Mini deployment name\n",
        "    messages=[{\"role\": \"user\", \"content\": \"Hello, Phi-4 Mini!\"}]\n",
        ")\n",
        "\n",
        "# Print the assistant's reply\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0b30ca33",
        "outputId": "7195f02d-c946-4e5a-965e-30e3f0da3c6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: azure-ai-inference in /usr/local/lib/python3.12/dist-packages (1.0.0b9)\n",
            "Requirement already satisfied: isodate>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from azure-ai-inference) (0.7.2)\n",
            "Requirement already satisfied: azure-core>=1.30.0 in /usr/local/lib/python3.12/dist-packages (from azure-ai-inference) (1.35.0)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from azure-ai-inference) (4.14.1)\n",
            "Requirement already satisfied: requests>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from azure-core>=1.30.0->azure-ai-inference) (2.32.4)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from azure-core>=1.30.0->azure-ai-inference) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.21.0->azure-core>=1.30.0->azure-ai-inference) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.21.0->azure-core>=1.30.0->azure-ai-inference) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.21.0->azure-core>=1.30.0->azure-ai-inference) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.21.0->azure-core>=1.30.0->azure-ai-inference) (2025.8.3)\n"
          ]
        }
      ],
      "source": [
        "%pip install azure-ai-inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xceYLJgAm9tR",
        "outputId": "f8e2b1c1-98bc-4636-cba5-015eaca5773d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: faiss-gpu-cu12 in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.12/dist-packages (from faiss-gpu-cu12) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-gpu-cu12) (25.0)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12>=12.1.105 in /usr/local/lib/python3.12/dist-packages (from faiss-gpu-cu12) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cublas-cu12>=12.1.3.1 in /usr/local/lib/python3.12/dist-packages (from faiss-gpu-cu12) (12.6.4.1)\n"
          ]
        }
      ],
      "source": [
        "pip install faiss-gpu-cu12 --index-url https://pypi.org/simple\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d11be96a"
      },
      "source": [
        "Now that the necessary package is installed, I'll correct the placeholder for the API key in the client initialization. You should replace `<YOUR_AZURE_API_KEY>` with your actual key, which is recommended to be stored securely using Colab's Secrets Manager."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "181988c8"
      },
      "outputs": [],
      "source": [
        "from azure.ai.inference import ChatCompletionsClient\n",
        "from azure.core.credentials import AzureKeyCredential\n",
        "import os\n",
        "\n",
        "# For Serverless API or Managed Compute endpoints\n",
        "client = ChatCompletionsClient(\n",
        "    endpoint=\"\",\n",
        "    credential=AzureKeyCredential(os.environ[\"AZURE_OPENAI_API_KEY\"]), # Use the API key from environment variables\n",
        "    api_version=\"\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0e76997",
        "outputId": "5d53fe57-fdee-44b0-8f3b-b14bf8ab54a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting newspaper3k\n",
            "  Using cached newspaper3k-0.2.8-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.12/dist-packages (from newspaper3k) (4.13.4)\n",
            "Requirement already satisfied: Pillow>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from newspaper3k) (11.3.0)\n",
            "Requirement already satisfied: PyYAML>=3.11 in /usr/local/lib/python3.12/dist-packages (from newspaper3k) (6.0.2)\n",
            "Collecting cssselect>=0.9.2 (from newspaper3k)\n",
            "  Using cached cssselect-1.3.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: lxml>=3.6.0 in /usr/local/lib/python3.12/dist-packages (from newspaper3k) (5.4.0)\n",
            "Requirement already satisfied: nltk>=3.2.1 in /usr/local/lib/python3.12/dist-packages (from newspaper3k) (3.9.1)\n",
            "Requirement already satisfied: requests>=2.10.0 in /usr/local/lib/python3.12/dist-packages (from newspaper3k) (2.32.4)\n",
            "Collecting feedparser>=5.2.1 (from newspaper3k)\n",
            "  Using cached feedparser-6.0.11-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting tldextract>=2.0.1 (from newspaper3k)\n",
            "  Using cached tldextract-5.3.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting feedfinder2>=0.0.4 (from newspaper3k)\n",
            "  Using cached feedfinder2-0.0.4-py3-none-any.whl\n",
            "Collecting jieba3k>=0.35.1 (from newspaper3k)\n",
            "  Using cached jieba3k-0.35.1-py3-none-any.whl\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from newspaper3k) (2.9.0.post0)\n",
            "Collecting tinysegmenter==0.3 (from newspaper3k)\n",
            "  Using cached tinysegmenter-0.3-py3-none-any.whl\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4>=4.4.1->newspaper3k) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4>=4.4.1->newspaper3k) (4.14.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from feedfinder2>=0.0.4->newspaper3k) (1.17.0)\n",
            "Collecting sgmllib3k (from feedparser>=5.2.1->newspaper3k)\n",
            "  Using cached sgmllib3k-1.0.0-py3-none-any.whl\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk>=3.2.1->newspaper3k) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk>=3.2.1->newspaper3k) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk>=3.2.1->newspaper3k) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk>=3.2.1->newspaper3k) (4.67.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.10.0->newspaper3k) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.10.0->newspaper3k) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.10.0->newspaper3k) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.10.0->newspaper3k) (2025.8.3)\n",
            "Collecting requests-file>=1.4 (from tldextract>=2.0.1->newspaper3k)\n",
            "  Using cached requests_file-2.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.12/dist-packages (from tldextract>=2.0.1->newspaper3k) (3.19.1)\n",
            "Using cached newspaper3k-0.2.8-py3-none-any.whl (211 kB)\n",
            "Using cached cssselect-1.3.0-py3-none-any.whl (18 kB)\n",
            "Using cached feedparser-6.0.11-py3-none-any.whl (81 kB)\n",
            "Using cached tldextract-5.3.0-py3-none-any.whl (107 kB)\n",
            "Using cached requests_file-2.1.0-py2.py3-none-any.whl (4.2 kB)\n",
            "Installing collected packages: tinysegmenter, sgmllib3k, jieba3k, feedparser, cssselect, requests-file, feedfinder2, tldextract, newspaper3k\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m9/9\u001b[0m [newspaper3k]\n",
            "\u001b[1A\u001b[2KSuccessfully installed cssselect-1.3.0 feedfinder2-0.0.4 feedparser-6.0.11 jieba3k-0.35.1 newspaper3k-0.2.8 requests-file-2.1.0 sgmllib3k-1.0.0 tinysegmenter-0.3 tldextract-5.3.0\n"
          ]
        }
      ],
      "source": [
        "%pip install newspaper3k"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6fcbe4c",
        "outputId": "e86424f8-5bbc-4ded-88c6-3f5da3b74454"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting lxml_html_clean\n",
            "  Downloading lxml_html_clean-0.4.2-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.12/dist-packages (from lxml_html_clean) (5.4.0)\n",
            "Downloading lxml_html_clean-0.4.2-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: lxml_html_clean\n",
            "Successfully installed lxml_html_clean-0.4.2\n"
          ]
        }
      ],
      "source": [
        "%pip install lxml_html_clean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhkpejeqtGM-",
        "outputId": "bf2b8200-2ff8-4d92-e803-b007a85d06a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ GPU enabled: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"‚úÖ GPU enabled:\", torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"‚ö†Ô∏è No GPU found, using CPU.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6efda44a",
        "outputId": "12e47fed-9087-460e-daa1-22fbde0b43b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.12/dist-packages (1.0.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from langdetect) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "%pip install langdetect"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1eu3oVqGK7O",
        "outputId": "d6642afc-7fa2-4969-f240-24acf110faba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ All datasets found (ISOT + DailyStar).\n",
            "ISOT Fake shape: (23481, 4)\n",
            "ISOT True shape: (21417, 4)\n",
            "DailyStar shape: (2573, 5)\n",
            "                                               title  date  \\\n",
            "0               3 BNP men among 5 held for extortion   NaN   \n",
            "1               Sayeed Hossain Chowdhury passes away   NaN   \n",
            "2            Youth dies being hit by train in Khulna   NaN   \n",
            "3                 ‚ÄòI won‚Äôt play with planes anymore‚Äô   NaN   \n",
            "4  Preventing project delays: Govt to make guidel...   NaN   \n",
            "\n",
            "                                             content  \\\n",
            "0  Avijit murder convict Farabi freed on bail\\nBo...   \n",
            "1  Avijit murder convict Farabi freed on bail\\nBo...   \n",
            "2  Avijit murder convict Farabi freed on bail\\nBo...   \n",
            "3  Avijit murder convict Farabi freed on bail\\nBo...   \n",
            "4  Avijit murder convict Farabi freed on bail\\nBo...   \n",
            "\n",
            "                                              source error  \n",
            "0  https://www.thedailystar.net/news/bangladesh/c...   NaN  \n",
            "1  https://www.thedailystar.net/news/bangladesh/n...   NaN  \n",
            "2  https://www.thedailystar.net/news/bangladesh/a...   NaN  \n",
            "3  https://www.thedailystar.net/news/bangladesh/n...   NaN  \n",
            "4  https://www.thedailystar.net/news/bangladesh/n...   NaN  \n"
          ]
        }
      ],
      "source": [
        "# ===== 2) DATASET LOADING =====\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "from pathlib import Path\n",
        "from newspaper import Article  # Import Article from newspaper\n",
        "\n",
        "# Define RAW_DIR if not already defined\n",
        "RAW_DIR = Path(\"/content/fake-news-rag/data/raw\")\n",
        "RAW_DIR.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "# Define dataset paths\n",
        "FAKE_CSV = RAW_DIR / \"Fake.csv\"\n",
        "TRUE_CSV = RAW_DIR / \"True.csv\"\n",
        "DAILYSTAR_CSV = RAW_DIR / \"dailystar_news.csv\"\n",
        "\n",
        "def ensure_datasets_present():\n",
        "    \"\"\"Check if all required datasets exist in RAW_DIR.\"\"\"\n",
        "    missing = []\n",
        "    if not FAKE_CSV.exists():\n",
        "        missing.append(\"Fake.csv\")\n",
        "    if not TRUE_CSV.exists():\n",
        "        missing.append(\"True.csv\")\n",
        "    if not DAILYSTAR_CSV.exists():\n",
        "        missing.append(\"dailystar_news.csv\")\n",
        "\n",
        "    if missing:\n",
        "        print(\"‚ùå Missing datasets:\", \", \".join(missing))\n",
        "        print(\"üëâ Please place them at:\", RAW_DIR)\n",
        "        print(\"Expected columns:\")\n",
        "        print(\" - Fake.csv / True.csv: ['title','text','subject','date']\")\n",
        "        print(\" - dailystar_news.csv: at least ['title','text','date'] (or similar)\")\n",
        "    else:\n",
        "        print(\"‚úÖ All datasets found (ISOT + DailyStar).\")\n",
        "\n",
        "# Run the check\n",
        "ensure_datasets_present()\n",
        "\n",
        "# Load datasets (if available)\n",
        "if FAKE_CSV.exists() and TRUE_CSV.exists():\n",
        "    fake_df = pd.read_csv(FAKE_CSV)\n",
        "    true_df = pd.read_csv(TRUE_CSV)\n",
        "    print(\"ISOT Fake shape:\", fake_df.shape)\n",
        "    print(\"ISOT True shape:\", true_df.shape)\n",
        "\n",
        "if DAILYSTAR_CSV.exists():\n",
        "    dailystar_df = pd.read_csv(DAILYSTAR_CSV)\n",
        "    print(\"DailyStar shape:\", dailystar_df.shape)\n",
        "    print(dailystar_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "oKhnrHyRHMhp",
        "outputId": "6c0638d9-10af-45b0-8e68-3fdc11a62ca1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed DailyStar dataset saved: /content/fake-news-rag/data/processed/dailystar_clean.csv (rows=2573)\n",
            "Scraped data not available; creating empty DataFrame\n",
            "Processed dataset saved: /content/fake-news-rag/data/processed/clean_dataset.csv (rows=41106)\n",
            "Language distribution:\n",
            "lang\n",
            "en    41098\n",
            "de        6\n",
            "sw        1\n",
            "vi        1\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"display(combined_df\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"As Congo refugees pour over border, Angola's backing for Kabila in doubt\",\n          \"India's Modi heads to Myanmar as Rohingya refugee crisis worsens\",\n          \"NBC Chairman SHREDS \\u2018Demented\\u2019 Trump, Rips Ratings For The Apprentice\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"DUNDO, Angola (Reuters) - Captured by militia and accused of being married to a Congolese government official, Kimpanga Caro could smell the fire she was told would be used to burn her decapitated head to ash. Caro, whose husband is a pastor not an official, was freed when one of the militiamen recognized her. She raced back home to find her husband in their ransacked village. They fled south, on foot with their five children, towards a country they heard was safe: Angola. Thirty thousand of her compatriots have made the same journey so far, among 1.4 million people driven from their homes in a year of violence in the central Kasai region of the Democratic Republic of Congo. There are signs that the refugee crisis is causing Angola a powerful regional ally that helped sustain Congolese President Joseph Kabila and his father in power for two decades to question its support for the leader of its volatile neighbor. At least 3,300 people have been killed in Kasai since the Kamuina Nsapu militia launched an insurrection to force a military withdrawal from the area. Refugees say villages have been destroyed and women have been raped both by the militiamen and by soldiers who have fought them. Their flight into the Angolan province of Lunda Norte has brought an international relief effort to the area for the first time since Angola s own 27-year civil war ended in 2002. A cooling in Angola s support for Kabila would leave the Congolese president more isolated than ever and make it even harder for him to hang on to power beyond the end of this year, when he has pledged to hold an election already a year late. Angola, with the third largest economy in sub-Saharan Africa and one of the region s strongest militaries, has twice in the past sent troops to prop up Kabila. Now, its soldiers are trying to contain the violence on the frontier. Luanda has doubled its troops and police on the border, according to Marcelino Caetano, provincial director of the Service for Migration and Foreigners, responsible for Lunda Norte province s 770-kilometre border with the DRC. We will maintain this level of control for as long as we have to, he said in his cramped, well-guarded offices in Dundo, an old diamond mining town just 9 kilometers from the border, declining to give exact numbers for Angolan troops in the area. Angola had pushed Kinshasa to allow U.N. officials into Kasai to help, but the Congolese have declined, he said. Since March, two Angolan border guards and one immigration official have been killed in attacks by Congolese militia on four separate border posts, said Inacio Feliciano, a senior police commander. Aid agencies suspect Angolan forces are patrolling inside Congo, though Caetano denied this. The unrest is not the only change that could alter Angola s policy of supporting Kabila: in Luanda, a new president is about to take power after 38 years of rule by Jose Eduardo dos Santos. Jo o Louren o, a military man and former defense minister, lacks dos Santos s historic ties with Kabila and his father Laurent, who took power in Congo in 1997 and was killed in 2001. Louren o regards Kabila as an increasingly destabilizing force, according to a diplomat familiar with his thinking, although the diplomat said military intervention against Kabila remains unlikely as it would probably make things worse. He doesn t want a Libya on his doorstep. Angola has worried about the 2,600-kilometre border it shares with the DRC for decades. During Angola s civil war, enemies of the ruling MPLA party hid, trained and armed in the former Zaire. Unrest in the vast, mineral rich Congo has had a tendency to draw its neighbors into regional conflict. With the victims of the Kasai violence now crossing into Angola and the threat of militia groups moving across the border too, the benefit of keeping Kabila as an ally is less obvious. At the Chissanda crossing last week, located just north of Dundo, two officials said the border was closed. Guards sat around chatting and watching the sun set. Authorities say they are letting refugees cross, though the stream has stopped in recent weeks. Some are even choosing to return home. The Congolese army says it has taken back control of Kasai, though Commander Feliciano said he had received reports of clashes around the city of Kananga on Sept 7. Refugees interviewed by Reuters told of soldiers raping and executing residents for supporting the militia in villages the army had taken back. We expect it to get worse again as we approach the end of the year, said Guy-Rufin Guernas, the local head for the United Nations refugee agency (UNHCR) in Dundo. Kabila agreed to hold presidential elections, due in 2016, by December. But the vote looks unlikely to happen by then, potentially sparking a violent backlash. UNHCR is working on the basis that another 50,000 refugees could cross into Angola before 2017 ends. To accommodate them, a new settlement is being constructed about 100 km outside Dundo, in the municipality of Lovua. Last Wednesday, recent arrivals were digging up roots on the 25x25 meter plots of land that families are being given in this remote area of sparse forest. Getting equipment, from solar lights to bulldozers, is difficult and expensive. Located at the north-eastern tip of Angola, Dundo s airport only just re-opened. Most goods are brought in by truck from Saurimo, the provincial capital of neighboring Lunda Sul, three hours away. At night there is almost total darkness. Buying basic goods is difficult. The cost of taking in the refugees is steep for Angola, which is in the midst of recession after the fall in the price of oil, its main source of wealth. Angola has had its own war, it understands the suffering these people are going through, said Guernas. In Cacanda, an earlier more ad-hoc settlement where nearly 7,000 refugees are still crammed under tarpaulin before they move to Lovua, many complain of a lack of food and shelter. Rafael Tshimbumba, 50, says the conditions may be basic but he cannot return to Kasai. He lost four children in the violence, when militias arrived at his village and began killing anyone that spoke Tshiluba, language of the Baluba people, highlighting the increasingly tribal element of the conflict. Here at least we are safe, he said, wearing the red and black t-shirt of the MPLA party that governs Angola. For Caro, who escaped from Congo with her pastor husband after the militia threatened to kill her, the flight itself led only to more danger. As the family stopped to rest in a village near the border, a passing car snatched her 5-year old boy. She searched for him for days and put a message out on the local radio, but found nothing. Only God knows where he s gone, she said, holding her youngest child in her arms.\",\n          \"NEW DELHI (Reuters) - Indian Prime Minister Narendra Modi will discuss rising violence in Myanmar s western Rakhine state during a visit that begins on Tuesday, and push for greater progress on long-running Indian infrastructure projects, officials said. India seeks to boost economic ties with resource-rich Myanmar, with which it shares a 1,600-km (1,000-mile) border, to counter Chinese influence and step up connectivity with a country it considers its gateway to Southeast Asia. Two-way trade has grown to around $2.2 billion as India courted Myanmar following the gradual end of military rule, but Indian-funded projects have moved slowly. Modi s promises to Act East and cement ties with India s eastern neighbor have slipped even as China has strengthened its influence. His first bilateral visit comes amid a spike in violence in Rakhine, after a military counter-offensive against insurgents killed at least 400 people and triggered the exodus of nearly 90,000 villagers to Bangladesh since Aug. 25. The violence could hit development of a transport corridor that begins in Rakhine, with the Indian-built port of Sittwe and includes road links to India s remote northeast, analysts said. It s going to be a very vexed and complex issue, said Tridivesh Singh Maini, a New Delhi-based expert on ties with Myanmar. You need to play it very smartly. You need to make it clear that Rakhine violence has regional implications... but India will not get into saying, This is how you should resolve it. Last month, India said it wanted to deport 40,000 Rohingya refugees who left Myanmar in previous years. Modi arrives from China late on Tuesday in the capital Naypyidaw to meet President Htin Kyaw on a three-day visit. New Delhi believes the best way to reduce tension in Rakhine is through development efforts, such as the Kaladan transport project there, said Indian foreign ministry official Sripriya Ranganathan. We are very confident that once that complete corridor is functional, there will be a positive impact on the situation in the state, she told reporters. Modi will meet Myanmar leader Aung San Suu Kyi and visit the heritage city of Bagan and a Hindu temple. The countries share close cultural ties, and several in Myanmar trace their roots to India. Modi will also talk up a trilateral highway project connecting India s northeast with Myanmar and Thailand. There is a fear that China is already going full steam ahead, said Udai Bhanu Singh of Delhi think-tank, the Institute for Defence Studies and Analyses. From the Indian side, there has been some laxity. Singh said India could offer Myanmar help in building its navy and coastguard, while Myanmar would seek assurances that India was a reliable economic partner and an alternative power to Beijing.\",\n          \"NBC Entertainment chairman Bob Greenblatt took to his Facebook account to rip demented Donald Trump, calling him pompous and toxic, then took a shot at the ratings of Celebrity Apprentice. That post has since been deleted but Marlow Stern of The Daily Beast took a screen shot. The sad state of affairs thanks to a pompous businessman turned reality-TV star (whose show consistently ran LAST in its time period, by the way) who thinks speaking his mind is refreshing, Greenblatt wrote. It s actually corrosive and toxic because his mind is so demented; and his effect will unfortunately linger long after he s been told to get off the stage. The Donald often brags about the ratings for The Apprentice, just like he bragged about polls until recently when all national polls showed his campaign spiraling downward. Apparently, his ratings were nothing to brag about either.The Daily Beast reports:Greenblatt s Facebook post was a personal response to a recent New York Times op-ed penned by Nicholas Kristof that shows how all across America Donald Trump is mainstreaming hate. The column touches on bullying in schools, and recounts a moment during a high-school physics class in Forest Grove, Oregon, in which a group of white students suddenly began jeering at their Latino classmates and chanting: Build a wall! Build a wall!' (Greenblatt, who is the first openly gay broadcast TV chairman, has long been active in pro-LGBT advocacy, as well as in anti-bullying efforts.)In 2015, Donald tweeted, People don t understand that I left The Apprentice to run for Pres the Apprentice DID NOT leave me. Bob Greenblatt & folks @NBC were GREAT! Donald has claimed many times that The Apprentice was the number one show on television. As television critic Tim Goodman put it at the time, Nobody spins like Trump. Nobody. It s just bloviation. Bloviation is a good word for Donald s presidential run, too. Bloviate is to talk at length, especially in an inflated or empty way. That s him alright.The GOP presidential candidate is going to be a sad panda today after reading Greenblatt s opinion of him.Featured image via screen capture.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5773502691896258,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lang\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"en\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"source\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"isot\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-b3ea7a7d-570f-4078-9773-ee6f3d85a00f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>lang</th>\n",
              "      <th>source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>36647</th>\n",
              "      <td>As Congo refugees pour over border, Angola's b...</td>\n",
              "      <td>DUNDO, Angola (Reuters) - Captured by militia ...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>en</td>\n",
              "      <td>isot</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38116</th>\n",
              "      <td>India's Modi heads to Myanmar as Rohingya refu...</td>\n",
              "      <td>NEW DELHI (Reuters) - Indian Prime Minister Na...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>en</td>\n",
              "      <td>isot</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5025</th>\n",
              "      <td>NBC Chairman SHREDS ‚ÄòDemented‚Äô Trump, Rips Rat...</td>\n",
              "      <td>NBC Entertainment chairman Bob Greenblatt took...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>en</td>\n",
              "      <td>isot</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b3ea7a7d-570f-4078-9773-ee6f3d85a00f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b3ea7a7d-570f-4078-9773-ee6f3d85a00f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b3ea7a7d-570f-4078-9773-ee6f3d85a00f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-9c09a30a-22d5-4dbc-83eb-a4665afb5224\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9c09a30a-22d5-4dbc-83eb-a4665afb5224')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-9c09a30a-22d5-4dbc-83eb-a4665afb5224 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                                   title  \\\n",
              "36647  As Congo refugees pour over border, Angola's b...   \n",
              "38116  India's Modi heads to Myanmar as Rohingya refu...   \n",
              "5025   NBC Chairman SHREDS ‚ÄòDemented‚Äô Trump, Rips Rat...   \n",
              "\n",
              "                                                    text  label lang source  \n",
              "36647  DUNDO, Angola (Reuters) - Captured by militia ...    1.0   en   isot  \n",
              "38116  NEW DELHI (Reuters) - Indian Prime Minister Na...    1.0   en   isot  \n",
              "5025   NBC Entertainment chairman Bob Greenblatt took...    0.0   en   isot  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# ===== 3) PREPROCESSING & CLEANING =====\n",
        "import numpy as np\n",
        "import re  # Added missing import\n",
        "from langdetect import detect, LangDetectException\n",
        "from pathlib import Path  # Added missing import\n",
        "import pandas as pd  # Added missing import\n",
        "\n",
        "# Define PROC_DIR if not already defined\n",
        "PROC_DIR = Path(\"/content/fake-news-rag/data/processed\")  # Adjust path as needed\n",
        "PROC_DIR.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "def clean_text(s: str) -> str:\n",
        "    if not isinstance(s, str):\n",
        "        return \"\"\n",
        "    s = re.sub(r\"<[^>]+>\", \" \", s)           # HTML\n",
        "    s = re.sub(r\"http\\S+|www\\.\\S+\", \" \", s)  # URLs\n",
        "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
        "    return s\n",
        "\n",
        "def detect_lang_safe(s: str) -> str:\n",
        "    try:\n",
        "        return detect(s) if s else \"unknown\"\n",
        "    except LangDetectException:\n",
        "        return \"unknown\"\n",
        "\n",
        "def load_isot(fake_csv: Path, true_csv: Path) -> pd.DataFrame:\n",
        "    if not fake_csv.exists() or not true_csv.exists():\n",
        "        return pd.DataFrame(columns=[\"title\",\"text\",\"subject\",\"date\",\"label\"])\n",
        "    fake = pd.read_csv(fake_csv)\n",
        "    true = pd.read_csv(true_csv)\n",
        "    fake[\"label\"] = 0\n",
        "    true[\"label\"] = 1\n",
        "    df = pd.concat([fake, true], ignore_index=True)\n",
        "    # Normalize column names\n",
        "    if \"text\" not in df.columns:\n",
        "        if \"content\" in df.columns:\n",
        "            df[\"text\"] = df[\"content\"]\n",
        "        else:\n",
        "            df[\"text\"] = \"\"\n",
        "    if \"title\" not in df.columns:\n",
        "        df[\"title\"] = \"\"\n",
        "    return df[[\"title\",\"text\",\"label\"]]\n",
        "\n",
        "# --- Load ISOT ---\n",
        "isot_df = load_isot(FAKE_CSV, TRUE_CSV)\n",
        "\n",
        "if not isot_df.empty:\n",
        "    isot_df[\"title\"] = isot_df[\"title\"].astype(str).apply(clean_text)\n",
        "    isot_df[\"text\"]  = isot_df[\"text\"].astype(str).apply(clean_text)\n",
        "    isot_df[\"lang\"]  = isot_df[\"text\"].apply(detect_lang_safe)\n",
        "else:\n",
        "    print(\"ISOT not loaded; continuing with scraped only.\")\n",
        "\n",
        "# --- Load DailyStar ---\n",
        "if DAILYSTAR_CSV.exists():\n",
        "    try:\n",
        "        dailystar_df = pd.read_csv(DAILYSTAR_CSV)\n",
        "        if not dailystar_df.empty:\n",
        "            if \"text\" not in dailystar_df.columns:\n",
        "                if \"content\" in dailystar_df.columns:\n",
        "                    dailystar_df[\"text\"] = dailystar_df[\"content\"]\n",
        "                else:\n",
        "                    dailystar_df[\"text\"] = \"\"\n",
        "            if \"title\" not in dailystar_df.columns:\n",
        "                dailystar_df[\"title\"] = \"\"\n",
        "\n",
        "            dailystar_df[\"title\"] = dailystar_df[\"title\"].astype(str).apply(clean_text)\n",
        "            dailystar_df[\"text\"]  = dailystar_df[\"text\"].astype(str).apply(clean_text)\n",
        "            dailystar_df[\"label\"] = np.nan  # unknown\n",
        "            dailystar_df[\"lang\"]  = dailystar_df[\"text\"].apply(detect_lang_safe)\n",
        "        else:\n",
        "            print(\"DailyStar dataset is empty, skipping.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading DailyStar dataset: {e}\")\n",
        "        dailystar_df = pd.DataFrame(columns=[\"title\",\"text\",\"label\",\"lang\"])\n",
        "else:\n",
        "    print(\"DailyStar CSV not found.\")\n",
        "    dailystar_df = pd.DataFrame(columns=[\"title\",\"text\",\"label\",\"lang\"])\n",
        "\n",
        "# Save a separate cleaned DailyStar file for reuse\n",
        "if not dailystar_df.empty:\n",
        "    DAILYSTAR_PROC_PATH = PROC_DIR / \"dailystar_clean.csv\"\n",
        "    dailystar_df.to_csv(DAILYSTAR_PROC_PATH, index=False, encoding=\"utf-8\")\n",
        "    print(f\"Processed DailyStar dataset saved: {DAILYSTAR_PROC_PATH} (rows={len(dailystar_df)})\")\n",
        "\n",
        "# --- Prepare scraped ---\n",
        "if 'scraped_df' in globals() and not scraped_df.empty:\n",
        "    scraped_df = scraped_df.rename(columns={\"content\":\"text\"})\n",
        "    scraped_df[\"title\"] = scraped_df[\"title\"].astype(str).apply(clean_text)\n",
        "    scraped_df[\"text\"]  = scraped_df[\"text\"].astype(str).apply(clean_text)\n",
        "    scraped_df[\"label\"] = np.nan  # unknown\n",
        "    scraped_df[\"lang\"]  = scraped_df[\"text\"].apply(detect_lang_safe)\n",
        "else:\n",
        "    print(\"Scraped data not available; creating empty DataFrame\")\n",
        "    scraped_df = pd.DataFrame(columns=[\"title\", \"text\", \"label\", \"lang\"])\n",
        "\n",
        "# --- Merge (ISOT labeled + DailyStar unlabeled + Scraped unlabeled) ---\n",
        "combined_df = pd.DataFrame(columns=[\"title\",\"text\",\"label\",\"lang\",\"source\"])\n",
        "frames = []\n",
        "if not isot_df.empty:\n",
        "    a = isot_df.copy()\n",
        "    a[\"source\"] = \"isot\"\n",
        "    frames.append(a)\n",
        "if not scraped_df.empty:\n",
        "    b = scraped_df[[\"title\",\"text\",\"label\",\"lang\"]].copy()\n",
        "    b[\"source\"] = \"scraped\"\n",
        "    frames.append(b)\n",
        "if not dailystar_df.empty:\n",
        "    c = dailystar_df[[\"title\",\"text\",\"label\",\"lang\"]].copy()\n",
        "    c[\"source\"] = \"dailystar\"\n",
        "    frames.append(c)\n",
        "\n",
        "if frames:\n",
        "    combined_df = pd.concat(frames, ignore_index=True)\n",
        "\n",
        "# --- Drop empties / dedup ---\n",
        "combined_df = combined_df.dropna(subset=[\"text\"])\n",
        "combined_df = combined_df[combined_df[\"text\"].str.len() > 30]  # minimal length\n",
        "combined_df = combined_df.drop_duplicates(subset=[\"title\",\"text\"]).reset_index(drop=True)\n",
        "\n",
        "# --- Save combined dataset ---\n",
        "PROC_PATH = PROC_DIR / \"clean_dataset.csv\"\n",
        "combined_df.to_csv(PROC_PATH, index=False, encoding=\"utf-8\")\n",
        "print(f\"Processed dataset saved: {PROC_PATH} (rows={len(combined_df)})\")\n",
        "print(\"Language distribution:\")\n",
        "print(combined_df[\"lang\"].value_counts())\n",
        "display(combined_df.sample(min(3, len(combined_df))))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 751,
          "referenced_widgets": [
            "2f9ad5024a3e4d018e1daa8c7b59e536",
            "f4848866aed14d0b9c34ed83517c3ffa",
            "ab49787838f9431e8989c4353ac06cc4",
            "de634170aae94f0f908241d053355240",
            "1ddaa8806cd2490d8f0c58962a15ff09",
            "5c027b3f1f254500a17991e789be5d55",
            "d49b83e1ec92416d8aecbfd3c1be3f4b",
            "a359bf0eccc746549e17dd2e25638475",
            "6b109ac4c2fb4298848155d2ca086e87",
            "f473b89b15a1485d95529d3a1ecd1ed5",
            "9a876577cacc46fb9c5782b7fbc51970",
            "f4e9109c2019456daad2e2033a4e1b2a",
            "963109c277a64d8198c91192594f485b",
            "78a18a14ba2f41bfae95b30e6b3afe21",
            "bac9c8af2f00460b9f86b988809e7d76",
            "9aa98daf9603439081e0ec54990c8b9a",
            "23d5c3ea6ec7415aa8f975ca817e4050",
            "623029aa8f1f4550884eaac59b66334d",
            "ac992cc0c3684def8d883dc472fad3ff",
            "a4de35a08564472c83f9355c20028e77",
            "50f67d13731247c2a74a34c20d6ad938",
            "031e78b85e694f1691b2025e8df50f91",
            "073aaa7d800648699288619ed9595582",
            "0e9a74fdd2ad440f995d8cffed3ff9e7",
            "78fae15523c349a39849802d10f270b3",
            "720c0c8b186c4214a5d09fdf1b4eb2c5",
            "1b7e17aeb2bd4f4c958509e2dcf85274",
            "0072a138386946ea81513fc31686eba8",
            "ff905cbc53944959b7d2f566edf86ee0",
            "d9141647d1c04412b64f185a783c1f15",
            "d1a836be77cf44e98580127d77131514",
            "8299d8e55bff443382ba45b66ceb6308",
            "39da3935f477495bba954048ed3071c1",
            "c7affbf1141346f297f8f6dd025fe283",
            "b2bfc3119ead46059fb9d29a85cdd307",
            "b47f36d9e2664f599ce59179bf2bedee",
            "2d1faa0237e64ea28735751f9d79bc47",
            "c2567507212542efae5971e7a17dd52d",
            "ff0f01e2f8114b91ae720deac404c5a2",
            "6af96c869f8e4e87a3ee8b1e7708847b",
            "5a09c93c579542c19be9dba04e9ea8c9",
            "6174e162802848a48974c8090e534b6a",
            "3dca4dfa644e47268d3e11869eec8863",
            "734b599fe6e1407e9f2d49c1ce2fe438",
            "28816f7017014f00b7b9f01f1c9da8df",
            "819327bf3744425796173ee322e3713e",
            "c3efff7950694371ab5c2b6bb0ec7475",
            "3ae8c99acb014c40b60e34013813cc05",
            "8b23374b437b49a39d56b8386b4d3c75",
            "dc78f3a22a174727a95197bb028ed3b4",
            "c00f810178144fa49b3d61e2e1afe685",
            "7da29a3c8de34ac79660dfcb9611543f",
            "a2473a44d0e546a5aaf0f7ba73d9cd05",
            "bc70116afe1f4259bdf5a71e24f71b12",
            "78f5be1d67e2495ca555018d94bdec84",
            "5053df7e4b894db4a9a3e5dd57b0e3d4",
            "0cac8e0a9407486cab22195ea3f43938",
            "7e1358ec934741de8d4c39ce35d172cb",
            "1ccc32a07af94551abaad81ca76b7d36",
            "df132ecf32664796a26eff18ba1d2905",
            "d25f9e7460b84cd38709afd757d22a86",
            "d393aa1e9cea44239435f8e7ebd5747d",
            "26472bcf39734d33950ddc12e5dd123b",
            "483b033f5aa04f21a66b0009c2f58462",
            "54386a0a68c348c3aaf05717a93581c7",
            "ba61a61a707e4f12a5c4f5ada82a0afe",
            "7253acf5fdf0493c9e936c2c5c6ae9f3",
            "5389f2b090e046b3bbc0a04d3f9d4db5",
            "d9bdd5ed3b3a48e3a79a0ada5aeafed9",
            "0464c326ac564d579fbe73ebd012e90a",
            "e208c8e75c044c60bff704344b33fb45",
            "bc8bbe6be44b4efbb071721fe69368c9",
            "efff53f20e1746e1b3af769d231ba9db",
            "a6d4d1926e05489599d8e225a27c2392",
            "9f6b68e5b86b47578c433338eb0eb0ca",
            "db1a31a0375a4880be9eeb18abb29e73",
            "a241b6e430424a54abea72fbc8b2cdcc",
            "bfd5d7316e9e43cc9c3e03152965ca55",
            "1d94cfe2f2ed4cfdbc560956b1dfa6c8",
            "cb9540ef20ea4ae1b72ad68e0cc87c53",
            "1f1cf1f11d514086a6aa8b4c351dc879",
            "508e5a0bd3f9472ea76c040d0c128b2d",
            "57a252f89c5f4dbca6f762a1adf69669",
            "4f75e53a9f614e1c80d472bff9c8140f",
            "808ac88693ed4a568cd708471494f5a4",
            "ff0ee30d0b594e768df74b1311d3bf54",
            "768134f2917c4e608b44a5b08adc98d1",
            "66a578809f74419fb0b005f6ea3a3685",
            "4a845836d78847528d3954188cb5ec6b",
            "05e22d82b626439b8b571cb5562e9adf",
            "4b632dafd1f243ea82e172dd43a795b1",
            "f0cdba05febf42f69330938839cd211e",
            "26b7dcb1622a45439c3c9b0671b4eae5",
            "f296912f9b1c4c9db3ce031becda7e09",
            "0c3dda43cbff46c7bd0f95efdf8eb9b1",
            "852d66f125f34983a7a4dd0dbdce010f",
            "5627043e037d4a8db3d62fb4296b1c97",
            "c8197f984195441eb211f30cd2c1a5b3",
            "9fdb7a17910e4aa4ab0b3731cb658474",
            "215f5ef8a0544666a08b4561d986ab3b",
            "24dbbfd546624dbe9fa792a69a5dd5c5",
            "bf838dfdc9e84e939da40419ee168b2c",
            "dd6039a0f6224492a472f5be47fedd9f",
            "b3aeb2e5f52f4580b941dd17af06cd3c",
            "4ad64d8e7d3b4c86ac8ac55382630278",
            "77aaf5fa5ab9418d9b2a9d2000aeec10",
            "dbc3d6be1300404e96463b436b18f15a",
            "00d835220a134d9894ec9ca61182dca8",
            "655cd10efac14126adb8a82dff15033f",
            "04014c3dc9af461aa4c646a8fd3583da",
            "3370a3cccfc74ebc8bedc04fe34b8660",
            "9aa1c83fd6404a0997d41b3144c5fbe9",
            "b722e6dde45f40ad91de2c73cc8568d5",
            "7cddaf24bc9749acaa67aac27b92182b",
            "6bfd5b1568924b0cb8636523ee5137d9",
            "f208df844b974a928609a6a8eac792d9",
            "6f6e83929dac4fc3bf9df7dae6d9a8ff",
            "0f057ca26f1f4392950c872b752a9d00",
            "44be934c6dd24cfe8d20f2ed7579b478",
            "a04a817b04664b3489cc904de9a55372",
            "5201d68284db4ede9a924ab7364a9e6a",
            "ef8d017153304b8f8b6e5adbbf061296",
            "c99c6694ca4e4e8385416df0a2dbabd2",
            "87a2a3f5059c4943b4dadc6d38040510",
            "b4a9719dbf2d4e70b370d48f66299aa2",
            "efc0489f16764aae9c4bd190a42fda84",
            "80499a2236a6468f9900cbb2e96ee9f6",
            "1add4484d62d48f9ac4bf7cd8ef8943b",
            "ad73f82470f94dcda3c7cfcef1551ec3",
            "de23b16033b540e7be5136077ce1df3b",
            "41660cd5b6484e918a7b5a28a5b7b1c0",
            "0aae48e5fb854dd398898b078db9200c"
          ]
        },
        "id": "KBRiBMH7JE8m",
        "outputId": "72437502-edf6-491a-9982-9cdfa557bccb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "Embedding 41106 documents...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2f9ad5024a3e4d018e1daa8c7b59e536",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f4e9109c2019456daad2e2033a4e1b2a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "073aaa7d800648699288619ed9595582",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c7affbf1141346f297f8f6dd025fe283",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "28816f7017014f00b7b9f01f1c9da8df",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5053df7e4b894db4a9a3e5dd57b0e3d4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7253acf5fdf0493c9e936c2c5c6ae9f3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bfd5d7316e9e43cc9c3e03152965ca55",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4a845836d78847528d3954188cb5ec6b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "215f5ef8a0544666a08b4561d986ab3b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3370a3cccfc74ebc8bedc04fe34b8660",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ef8d017153304b8f8b6e5adbbf061296",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/643 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Embeddings shape: (41106, 384)\n",
            "Using FAISS CPU index.\n",
            "FAISS ntotal: 41106\n",
            "‚úÖ Saved: /content/fake-news-rag/models/embeddings/faiss.index and /content/fake-news-rag/models/embeddings/metadata.json\n",
            "FAISS index contains 41106 vectors with dimension 384\n",
            "\n",
            "Sample query: 'news about politics'\n",
            "Top 3 similar documents:\n",
            "1. Distance: 0.5570, Title: OBAMA BLAMES RUSSIA For Hillary‚Äôs Loss, But NEW HARVARD STUDY Exposes Who REALLY...\n",
            "2. Distance: 0.5220, Title: NOTHING NEW: ‚ÄòFake‚Äô & Weaponized News Has Long Haunted Our War-Weary World...\n",
            "3. Distance: 0.5214, Title: FAKE NEWS WEEK: Mainstream Media ‚Äì All the Fake News That‚Äôs Fit to Print...\n"
          ]
        }
      ],
      "source": [
        "# ===== 4) EMBEDDINGS + FAISS =====\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "import json\n",
        "from pathlib import Path\n",
        "import torch\n",
        "\n",
        "# Detect GPU device\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Define EMB_DIR if not already defined\n",
        "EMB_DIR = Path(\"/content/fake-news-rag/models/embeddings\")\n",
        "EMB_DIR.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "# Check if combined_df exists and has data\n",
        "if 'combined_df' not in globals() or len(combined_df) == 0:\n",
        "    PROC_PATH = PROC_DIR / \"clean_dataset.csv\"\n",
        "    if PROC_PATH.exists():\n",
        "        print(\"Loading combined_df from processed file...\")\n",
        "        try:\n",
        "            combined_df = pd.read_csv(PROC_PATH)\n",
        "            if len(combined_df) == 0:\n",
        "                raise ValueError(\"Processed file is empty.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Could not load processed file ({e}). Attempting to re-create combined_df...\")\n",
        "\n",
        "            # Load ISOT\n",
        "            isot_df = load_isot(FAKE_CSV, TRUE_CSV)\n",
        "            print(f\"Loaded ISOT data: {len(isot_df)} rows\")\n",
        "\n",
        "            # Load DailyStar if available\n",
        "            if DAILYSTAR_CSV.exists():\n",
        "                try:\n",
        "                    dailystar_df = pd.read_csv(DAILYSTAR_CSV)\n",
        "                    print(f\"Loaded DailyStar data: {len(dailystar_df)} rows\")\n",
        "\n",
        "                    if not dailystar_df.empty:\n",
        "                        dailystar_df[\"title\"] = dailystar_df[\"title\"].astype(str).apply(clean_text)\n",
        "                        dailystar_df[\"text\"]  = dailystar_df[\"text\"].astype(str).apply(clean_text)\n",
        "                        dailystar_df[\"label\"] = np.nan  # unknown\n",
        "                        dailystar_df[\"lang\"]  = dailystar_df[\"text\"].apply(detect_lang_safe)\n",
        "                        dailystar_df[\"source\"] = \"dailystar\"\n",
        "                except Exception as e:\n",
        "                    print(f\"Error loading DailyStar dataset: {e}\")\n",
        "                    dailystar_df = pd.DataFrame(columns=[\"title\",\"text\",\"label\",\"lang\",\"source\"])\n",
        "            else:\n",
        "                print(\"DailyStar CSV not found.\")\n",
        "                dailystar_df = pd.DataFrame(columns=[\"title\",\"text\",\"label\",\"lang\",\"source\"])\n",
        "\n",
        "            # Mock scraped fallback\n",
        "            print(\"Generating mock scraped data as fallback...\")\n",
        "            mock_data = {\n",
        "                'title': [\n",
        "                    'Bangladesh Government Announces New Economic Policy',\n",
        "                    'Dhaka Metro Rail Expansion Project Approved',\n",
        "                    'New Solar Power Plant Inaugurated in Rural Area',\n",
        "                    'Prime Minister Meets with Foreign Dignitaries',\n",
        "                    'Inflation Rate Shows Slight Decrease'\n",
        "                ],\n",
        "                'content': [\n",
        "                    'The government has introduced a new set of economic policies aimed at boosting foreign investment and stabilizing the national currency...',\n",
        "                    'The long-awaited expansion of the Dhaka Metro Rail project received final approval today...',\n",
        "                    'A new large-scale solar power plant was inaugurated today in a rural district...',\n",
        "                    'Prime Minister Sheikh Hasina held meetings with several foreign dignitaries today...',\n",
        "                    'According to the latest report from the Bureau of Statistics, the national inflation rate saw a slight decrease last month...'\n",
        "                ],\n",
        "                'source': [\n",
        "                    'https://example.com/news/economic-policy',\n",
        "                    'https://example.com/news/metro-rail',\n",
        "                    'https://example.com/news/solar-plant',\n",
        "                    'https://example.com/news/pm-meeting',\n",
        "                    'https://example.com/news/inflation-report'\n",
        "                ],\n",
        "                'error': [None, None, None, None, None]\n",
        "            }\n",
        "            scraped_df = pd.DataFrame(mock_data)\n",
        "            print(f\"Generated mock scraped data: {len(scraped_df)} rows\")\n",
        "\n",
        "            # Cleaning & merging\n",
        "            if not isot_df.empty:\n",
        "                isot_df[\"title\"] = isot_df[\"title\"].astype(str).apply(clean_text)\n",
        "                isot_df[\"text\"]  = isot_df[\"text\"].astype(str).apply(clean_text)\n",
        "                isot_df[\"lang\"]  = isot_df[\"text\"].apply(detect_lang_safe)\n",
        "                isot_df[\"source\"] = \"isot\"\n",
        "\n",
        "            if not scraped_df.empty:\n",
        "                scraped_df = scraped_df.rename(columns={\"content\":\"text\"})\n",
        "                scraped_df[\"title\"] = scraped_df[\"title\"].astype(str).apply(clean_text)\n",
        "                scraped_df[\"text\"]  = scraped_df[\"text\"].astype(str).apply(clean_text)\n",
        "                scraped_df[\"label\"] = np.nan\n",
        "                scraped_df[\"lang\"]  = scraped_df[\"text\"].apply(detect_lang_safe)\n",
        "                scraped_df[\"source\"] = \"scraped\"\n",
        "\n",
        "            frames = []\n",
        "            if not isot_df.empty: frames.append(isot_df)\n",
        "            if not scraped_df.empty: frames.append(scraped_df[[\"title\",\"text\",\"label\",\"lang\",\"source\"]])\n",
        "            if not dailystar_df.empty: frames.append(dailystar_df[[\"title\",\"text\",\"label\",\"lang\",\"source\"]])\n",
        "\n",
        "            if frames:\n",
        "                combined_df = pd.concat(frames, ignore_index=True)\n",
        "            else:\n",
        "                combined_df = pd.DataFrame(columns=[\"title\",\"text\",\"label\",\"lang\",\"source\"])\n",
        "                print(\"No data frames to concatenate.\")\n",
        "\n",
        "            combined_df = combined_df.dropna(subset=[\"text\"])\n",
        "            combined_df = combined_df[combined_df[\"text\"].str.len() > 30]\n",
        "            combined_df = combined_df.drop_duplicates(subset=[\"title\",\"text\"]).reset_index(drop=True)\n",
        "\n",
        "            if len(combined_df) == 0:\n",
        "                raise ValueError(\"Failed to re-create combined_df with enough data.\")\n",
        "            else:\n",
        "                print(f\"Successfully re-created combined_df with {len(combined_df)} rows.\")\n",
        "    else:\n",
        "        print(\"No data to embed. Ensure ISOT, DailyStar, or scraping succeeded.\")\n",
        "        raise SystemExit(\"No data to embed.\")\n",
        "\n",
        "print(f\"Embedding {len(combined_df)} documents...\")\n",
        "\n",
        "MODEL_NAME = \"all-MiniLM-L6-v2\"\n",
        "embedder = SentenceTransformer(MODEL_NAME, device=device)  # use GPU if available\n",
        "\n",
        "# Encode title + text\n",
        "def to_doc(row):\n",
        "    return f\"{row['title']}. {row['text']}\"\n",
        "\n",
        "docs = combined_df.apply(to_doc, axis=1).tolist()\n",
        "\n",
        "# Compute embeddings on GPU if available\n",
        "emb = embedder.encode(\n",
        "    docs,\n",
        "    batch_size=64,\n",
        "    convert_to_numpy=True,\n",
        "    show_progress_bar=True,\n",
        "    normalize_embeddings=True,\n",
        "    device=device\n",
        ").astype(\"float32\")\n",
        "\n",
        "if emb.shape[0] == 0:\n",
        "    raise ValueError(\"No embeddings generated. The input documents list might be empty.\")\n",
        "\n",
        "dim = emb.shape[1]\n",
        "print(\"Embeddings shape:\", emb.shape)\n",
        "\n",
        "# Use IndexFlatIP for cosine similarity (dot product on normalized vectors)\n",
        "# Always use CPU index to avoid GPU resource issues\n",
        "index = faiss.IndexFlatIP(dim)  # CPU version\n",
        "print(\"Using FAISS CPU index.\")\n",
        "\n",
        "index.add(emb)\n",
        "print(\"FAISS ntotal:\", index.ntotal)\n",
        "\n",
        "# Save index + metadata\n",
        "FAISS_PATH = EMB_DIR / \"faiss.index\"\n",
        "META_PATH  = EMB_DIR / \"metadata.json\"\n",
        "\n",
        "if index.ntotal > 0:\n",
        "    faiss.write_index(index, str(FAISS_PATH))\n",
        "\n",
        "    metadata = {\n",
        "        \"rows\": len(combined_df),\n",
        "        \"dimension\": dim,\n",
        "        \"model\": MODEL_NAME,\n",
        "        \"documents\": [\n",
        "            {\n",
        "                \"index\": i,\n",
        "                \"title\": str(row['title'])[:100],\n",
        "                \"text_preview\": str(row['text'])[:200] if pd.notna(row['text']) else \"\",\n",
        "                \"label\": row['label'] if 'label' in row and pd.notna(row['label']) else \"unknown\",\n",
        "                \"source\": row['source'] if 'source' in row else \"unknown\"\n",
        "            }\n",
        "            for i, (_, row) in enumerate(combined_df.iterrows())\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    with open(META_PATH, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(metadata, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    print(\"‚úÖ Saved:\", FAISS_PATH, \"and\", META_PATH)\n",
        "    print(f\"FAISS index contains {index.ntotal} vectors with dimension {dim}\")\n",
        "\n",
        "    # Test query\n",
        "    sample_query = \"news about politics\"\n",
        "    query_embedding = embedder.encode([sample_query], normalize_embeddings=True, device=device).astype(\"float32\")\n",
        "    D, I = index.search(query_embedding, 3)\n",
        "\n",
        "    print(f\"\\nSample query: '{sample_query}'\")\n",
        "    print(\"Top 3 similar documents:\")\n",
        "    for i, (distance, idx) in enumerate(zip(D[0], I[0])):\n",
        "        if idx < len(combined_df):\n",
        "            doc_title = combined_df.iloc[idx]['title']\n",
        "            print(f\"{i+1}. Distance: {distance:.4f}, Title: {doc_title[:80]}...\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Skipping FAISS index saving as no embeddings were generated.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LaLbBR6nPpY6",
        "outputId": "81ec23b5-0599-4753-db78-8aaa8597a9ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Existing models found:\n",
            "  faiss: ‚úì\n",
            "  metadata: ‚úì\n",
            "  classifier: ‚úó\n",
            "  combined_df: ‚úì\n",
            "  dailystar: ‚úì\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path  # Added missing import\n",
        "\n",
        "def check_existing_models():\n",
        "    \"\"\"Check which models already exist to avoid retraining\"\"\"\n",
        "    existing_models = {}\n",
        "\n",
        "    # Define MODEL_DIR and other necessary directories if not already defined\n",
        "    BASE_DIR = Path(\"/content/fake-news-rag\")\n",
        "    MODEL_DIR = BASE_DIR / \"models\"\n",
        "    EMB_DIR = MODEL_DIR / \"embeddings\"\n",
        "    PROC_DIR = BASE_DIR / \"data\" / \"processed\"\n",
        "\n",
        "    # Check for FAISS index\n",
        "    FAISS_PATH = EMB_DIR / \"faiss.index\"\n",
        "    existing_models['faiss'] = FAISS_PATH.exists()\n",
        "\n",
        "    # Check for metadata\n",
        "    META_PATH = EMB_DIR / \"metadata.json\"\n",
        "    existing_models['metadata'] = META_PATH.exists()\n",
        "\n",
        "    # Check for classifier\n",
        "    CLASSIFIER_PATH = MODEL_DIR / \"logistic_classifier.joblib\"  # Assuming classifier is saved in MODEL_DIR\n",
        "    existing_models['classifier'] = CLASSIFIER_PATH.exists()\n",
        "\n",
        "    # Check for combined dataframe (ISOT + others)\n",
        "    COMBINED_DF_PATH = PROC_DIR / \"combined_dataframe.pkl\"  # Or .csv if saved that way\n",
        "    CLEAN_CSV_PATH = PROC_DIR / \"clean_dataset.csv\"\n",
        "    existing_models['combined_df'] = COMBINED_DF_PATH.exists() or CLEAN_CSV_PATH.exists()\n",
        "\n",
        "    # ‚úÖ Check for DailyStar-specific processed/cleaned files\n",
        "    DAILYSTAR_CSV_PATH = PROC_DIR / \"dailystar_clean.csv\"\n",
        "    DAILYSTAR_PKL_PATH = PROC_DIR / \"dailystar_dataframe.pkl\"\n",
        "    existing_models['dailystar'] = DAILYSTAR_CSV_PATH.exists() or DAILYSTAR_PKL_PATH.exists()\n",
        "\n",
        "    return existing_models\n",
        "\n",
        "# Check what we already have\n",
        "existing_models = check_existing_models()\n",
        "print(\"Existing models found:\")\n",
        "for model, exists in existing_models.items():\n",
        "    print(f\"  {model}: {'‚úì' if exists else '‚úó'}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PAJ25uc5Z7gv",
        "outputId": "e3373df0-6464-4602-fcad-42fad09d4352"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Azure OpenAI client initialized successfully.\n"
          ]
        }
      ],
      "source": [
        "# ===== 5) AZURE PHI-4 MINI INTEGRATION =====\n",
        "import os\n",
        "import json  # Added missing import\n",
        "import textwrap  # Added missing import\n",
        "from typing import List, Dict, Any, Optional\n",
        "from openai import AzureOpenAI\n",
        "\n",
        "# ---- Set your secrets here (or use os.environ[...] before running this cell) ----\n",
        "# os.environ[\"AZURE_OPENAI_ENDPOINT\"]    = \"https://<your-resource>.openai.azure.com\"\n",
        "# os.environ[\"AZURE_OPENAI_API_KEY\"]     = \"<your-azure-openai-key>\"\n",
        "# os.environ[\"AZURE_OPENAI_DEPLOYMENT\"]  = \"Phi-4-mini-reasoning-2\"   # <-- your deployment name (not base model name)\n",
        "# os.environ[\"AZURE_OPENAI_API_VERSION\"] = \"2024-10-21\"        # pick a stable version available to your resource\n",
        "\n",
        "AZURE_ENDPOINT   = os.getenv(\"AZURE_OPENAI_ENDPOINT\", \"\")\n",
        "AZURE_API_KEY    = os.getenv(\"AZURE_OPENAI_API_KEY\", \"\")\n",
        "AZURE_DEPLOYMENT = os.getenv(\"AZURE_OPENAI_DEPLOYMENT\", \"Phi-4-mini-reasoning\")\n",
        "AZURE_API_VERSION= os.getenv(\"AZURE_OPENAI_API_VERSION\", \"\")\n",
        "\n",
        "def get_azure_client() -> Optional[AzureOpenAI]:\n",
        "    if not AZURE_ENDPOINT or not AZURE_API_KEY:\n",
        "        print(\"Azure credentials missing. Using MOCK generation (for dev/testing).\")\n",
        "        return None\n",
        "    try:\n",
        "        client = AzureOpenAI(\n",
        "            azure_endpoint=AZURE_ENDPOINT,\n",
        "            api_key=AZURE_API_KEY,\n",
        "            api_version=AZURE_API_VERSION\n",
        "        )\n",
        "        # Test the connection with a simple call\n",
        "        client.models.list()\n",
        "        print(\"Azure OpenAI client initialized successfully.\")\n",
        "        return client\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to initialize Azure client: {e}. Using MOCK generation.\")\n",
        "        return None\n",
        "\n",
        "client = get_azure_client()\n",
        "\n",
        "SYSTEM_PROMPT = (\n",
        "    \"You are a factual fact-checking assistant for Bangladesh news. \"\n",
        "    \"Classify news as Fake or Real using ONLY the provided context. \"\n",
        "    \"If Real, produce a concise timeline (dated bullet lines). \"\n",
        "    \"If insufficient context, say INSUFFICIENT CONTEXT.\"\n",
        ")\n",
        "\n",
        "def llm_classify_and_timeline(news_text: str, context_docs: List[str], few_shots: List[Dict[str,str]] = None) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Returns structured dict:\n",
        "    {\n",
        "      'classification': 'Real'|'Fake'|'Unknown',\n",
        "      'confidence': float|null,\n",
        "      'timeline': [str]|null,\n",
        "      'reason': str|optional\n",
        "    }\n",
        "    \"\"\"\n",
        "    if client is None:\n",
        "        # MOCK path for offline dev\n",
        "        # naive heuristic: if \"postponed\" or \"announced\" appears ‚Üí real-ish :)\n",
        "        if any(k in news_text.lower() for k in [\"announced\",\"postponed\",\"government\",\"ministry\",\"election\",\"official\"]):\n",
        "            return {\"classification\":\"Real\",\"confidence\":0.7,\"timeline\":[\"2025-07-01 - Government announced X\"],\"reason\":\"Heuristic mock - contains official keywords\"}\n",
        "        elif any(k in news_text.lower() for k in [\"fake\",\"false\",\"rumor\",\"hoax\",\"misinformation\"]):\n",
        "            return {\"classification\":\"Fake\",\"confidence\":0.8,\"timeline\":None,\"reason\":\"Heuristic mock - contains fake indicators\"}\n",
        "        return {\"classification\":\"Unknown\",\"confidence\":0.5,\"timeline\":None,\"reason\":\"Heuristic mock - insufficient keywords\"}\n",
        "\n",
        "    # Build messages with optional few-shot examples\n",
        "    messages = [{\"role\":\"system\",\"content\": SYSTEM_PROMPT}]\n",
        "    if few_shots:\n",
        "        for ex in few_shots:\n",
        "            messages.append({\"role\":\"user\", \"content\": f\"News:\\n{ex['news']}\\nContext:\\n{ex['context']}\"})\n",
        "            messages.append({\"role\":\"assistant\", \"content\": ex[\"answer\"]})\n",
        "\n",
        "    context_joined = \"\\n\\n---\\n\".join(context_docs[:5])  # Limit to top 5 context docs\n",
        "    user_prompt = textwrap.dedent(f\"\"\"\n",
        "    TASK:\n",
        "    1) Decide if the News is Fake or Real using only CONTEXT.\n",
        "    2) If Real: output a dated timeline (YYYY-MM-DD - short event).\n",
        "    3) If insufficient evidence: 'INSUFFICIENT CONTEXT'.\n",
        "\n",
        "    FORMAT (valid JSON):\n",
        "    {{\n",
        "      \"classification\": \"Real\" | \"Fake\" | \"Unknown\",\n",
        "      \"confidence\": 0.0-1.0,\n",
        "      \"timeline\": [\"YYYY-MM-DD - event\", \"...\"] | null,\n",
        "      \"reason\": \"one-line rationale\"\n",
        "    }}\n",
        "\n",
        "    NEWS:\n",
        "    {news_text}\n",
        "\n",
        "    CONTEXT:\n",
        "    {context_joined}\n",
        "    \"\"\").strip()\n",
        "\n",
        "    messages.append({\"role\":\"user\",\"content\": user_prompt})\n",
        "\n",
        "    try:\n",
        "        resp = client.chat.completions.create(\n",
        "            model=AZURE_DEPLOYMENT,  # deployment name\n",
        "            messages=messages,\n",
        "            temperature=0.2,\n",
        "            max_tokens=700,\n",
        "            top_p=0.9,\n",
        "            response_format={\"type\": \"json_object\"}  # Force JSON response\n",
        "        )\n",
        "        out = resp.choices[0].message.content\n",
        "\n",
        "        # Parse JSON\n",
        "        try:\n",
        "            parsed = json.loads(out)\n",
        "            # Validate required fields\n",
        "            required_fields = [\"classification\", \"confidence\", \"timeline\"]\n",
        "            for field in required_fields:\n",
        "                if field not in parsed:\n",
        "                    parsed[field] = None\n",
        "            return parsed\n",
        "        except json.JSONDecodeError:\n",
        "            return {\"classification\":\"Unknown\",\"confidence\":None,\"timeline\":None,\"reason\":\"Invalid JSON response\"}\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Azure API error: {e}\")\n",
        "        return {\"classification\":\"Unknown\",\"confidence\":None,\"timeline\":None,\"reason\":f\"API error: {str(e)}\"}\n",
        "\n",
        "# Test function\n",
        "def test_llm_integration():\n",
        "    \"\"\"Test the LLM integration with a simple example\"\"\"\n",
        "    test_news = \"The government announced new economic policies to boost growth.\"\n",
        "    test_context = [\"Government announces economic stimulus package on 2024-01-15\", \"Finance minister held press conference yesterday\"]\n",
        "\n",
        "    print(\"Testing LLM integration...\")\n",
        "    result = llm_classify_and_timeline(test_news, test_context)\n",
        "    print(\"Result:\", json.dumps(result, indent=2))\n",
        "\n",
        "# Uncomment to test\n",
        "# test_llm_integration()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379,
          "referenced_widgets": [
            "bf5e254fecbc4e63906b5297a0ddfeee",
            "a7240b3d85ba4a65a607fffbf08a4180",
            "7c841c0351af4271ba207e52a38dc4f8",
            "5cd9d26d6c6344b6af47de1160de74dc",
            "d6262c95976e439d9961c79473e8257e",
            "bc294c2ac4384404994bd9cd67542def",
            "bf8606531011440dbb0d1aa47fbf2c33",
            "6b02d55696a945cf9e0a551e4a48790e",
            "c9b3c29bdf3d4dac979200b31c820d39",
            "7d6d0f00347c4af0809623d06967ecd5",
            "e77b4ebbb2d84e9e92aa42f2833e226a"
          ]
        },
        "id": "g2DKYgB_aZSF",
        "outputId": "d8d5ee48-084d-4102-a28d-3b8224e93161"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training classifier on 38550 labeled examples...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bf5e254fecbc4e63906b5297a0ddfeee",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1205 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Embedding classifier trained.\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fake     0.9376    0.9435    0.9406      3471\n",
            "        Real     0.9535    0.9486    0.9510      4239\n",
            "\n",
            "    accuracy                         0.9463      7710\n",
            "   macro avg     0.9456    0.9461    0.9458      7710\n",
            "weighted avg     0.9463    0.9463    0.9463      7710\n",
            "\n",
            "Accuracy: 0.9463\n",
            "üíæ Classifier saved to: /content/fake-news-rag/data/processed/logistic_classifier.joblib\n",
            "X_test and y_test saved for evaluation.\n",
            "\n",
            "Prepared 3 few-shot examples.\n",
            "\n",
            "Test prediction: 'Government announces new economic policies' ‚Üí {'classification': 'Real', 'confidence': 0.940284550138454, 'source': 'LogisticRegression'}\n"
          ]
        }
      ],
      "source": [
        "# ===== 6) OPTIONAL: CLASSIFIER ON EMBEDDINGS + FEW-SHOT =====\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import joblib\n",
        "from pathlib import Path\n",
        "\n",
        "# Define PROC_DIR if not already defined\n",
        "PROC_DIR = Path(\"/content/fake-news-rag/data/processed\")\n",
        "PROC_DIR.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "CLASSIFIER_PATH = PROC_DIR / \"logistic_classifier.joblib\"\n",
        "\n",
        "# Try to load classifier if it already exists\n",
        "if CLASSIFIER_PATH.exists():\n",
        "    clf = joblib.load(CLASSIFIER_PATH)\n",
        "    print(f\"‚úÖ Loaded existing classifier from {CLASSIFIER_PATH}\")\n",
        "else:\n",
        "    # Load processed dataset if not already available\n",
        "    if 'combined_df' not in globals() or len(combined_df) == 0:\n",
        "        PROC_PATH = PROC_DIR / \"clean_dataset.csv\"\n",
        "        if PROC_PATH.exists():\n",
        "            print(\"Loading combined_df from processed file for classifier training...\")\n",
        "            try:\n",
        "                combined_df = pd.read_csv(PROC_PATH)\n",
        "            except Exception as e:\n",
        "                print(f\"Could not load processed file: {e}. Skipping classifier training.\")\n",
        "                combined_df = pd.DataFrame()\n",
        "        else:\n",
        "            print(\"combined_df not found. Skipping classifier training.\")\n",
        "            combined_df = pd.DataFrame()\n",
        "\n",
        "    labeled = combined_df.dropna(subset=[\"label\"]).copy()\n",
        "\n",
        "    if len(labeled) == 0:\n",
        "        print(\"No labeled data available for classifier training. Skipping...\")\n",
        "    else:\n",
        "        print(f\"Training classifier on {len(labeled)} labeled examples...\")\n",
        "\n",
        "        def to_doc(row):\n",
        "            title = str(row['title']) if pd.notna(row['title']) else ''\n",
        "            text = str(row['text']) if pd.notna(row['text']) else ''\n",
        "            return f\"{title}. {text}\"\n",
        "\n",
        "        X_docs = [to_doc(row) for _, row in labeled.iterrows()]\n",
        "        X_docs = [doc for doc in X_docs if isinstance(doc, str) and len(doc.strip()) > 0]\n",
        "\n",
        "        if not X_docs:\n",
        "            print(\"No valid documents generated for embedding. Skipping classifier training.\")\n",
        "        else:\n",
        "            X_emb  = embedder.encode(X_docs, convert_to_numpy=True, show_progress_bar=True, normalize_embeddings=True)\n",
        "            y      = labeled[\"label\"].astype(int).values[:len(X_emb)]\n",
        "\n",
        "            if len(X_emb) >= 10:\n",
        "                X_train, X_test, y_train, y_test = train_test_split(\n",
        "                    X_emb, y, test_size=0.2, random_state=42, stratify=y\n",
        "                )\n",
        "\n",
        "                clf = LogisticRegression(max_iter=300, class_weight=\"balanced\")\n",
        "                clf.fit(X_train, y_train)\n",
        "                print(\"‚úÖ Embedding classifier trained.\")\n",
        "\n",
        "                y_pred = clf.predict(X_test)\n",
        "                print(\"Classification Report:\")\n",
        "                print(classification_report(y_test, y_pred, digits=4, target_names=[\"Fake\", \"Real\"]))\n",
        "                print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "\n",
        "                # Save for reuse\n",
        "                joblib.dump(clf, CLASSIFIER_PATH)\n",
        "                print(f\"üíæ Classifier saved to: {CLASSIFIER_PATH}\")\n",
        "\n",
        "                np.save(PROC_DIR / \"X_test.npy\", X_test)\n",
        "                np.save(PROC_DIR / \"y_test.npy\", y_test)\n",
        "                print(\"X_test and y_test saved for evaluation.\")\n",
        "            else:\n",
        "                print(f\"Not enough data ({len(X_emb)} samples). Need at least 10.\")\n",
        "\n",
        "# Few-shot examples\n",
        "few_shots = [\n",
        "    { \"news\": \"Government announces rural healthcare expansion.\",\n",
        "      \"context\": \"Verified article: Government announced expansion in July 2025 with budget allocation of $500 million.\",\n",
        "      \"answer\": json.dumps({\n",
        "          \"classification\": \"Real\",\n",
        "          \"confidence\": 0.92,\n",
        "          \"timeline\": [\"2025-07-15 - Announcement\", \"2025-08-01 - Budget approved\"],\n",
        "          \"reason\": \"Matches multiple verified sources\"\n",
        "      })\n",
        "    },\n",
        "    { \"news\": \"Secret herb instantly cures COVID claimed by celebrity.\",\n",
        "      \"context\": \"WHO: No herb can cure COVID-19. Health Ministry warning issued.\",\n",
        "      \"answer\": json.dumps({\n",
        "          \"classification\": \"Fake\",\n",
        "          \"confidence\": 0.95,\n",
        "          \"timeline\": None,\n",
        "          \"reason\": \"Contradicted by WHO and medical research\"\n",
        "      })\n",
        "    },\n",
        "    { \"news\": \"Prime Minister resigns unexpectedly amid protests.\",\n",
        "      \"context\": \"Govt statement: PM continues duties. Press conference yesterday confirmed.\",\n",
        "      \"answer\": json.dumps({\n",
        "          \"classification\": \"Fake\",\n",
        "          \"confidence\": 0.88,\n",
        "          \"timeline\": None,\n",
        "          \"reason\": \"No credible evidence; contradicted by official sources\"\n",
        "      })\n",
        "    }\n",
        "]\n",
        "\n",
        "print(f\"\\nPrepared {len(few_shots)} few-shot examples.\")\n",
        "\n",
        "# Prediction function\n",
        "def predict_with_classifier(news_text, title=\"\"):\n",
        "    if 'clf' not in globals() or 'embedder' not in globals():\n",
        "        print(\"Classifier or embedder not available.\")\n",
        "        return None\n",
        "\n",
        "    doc = f\"{title}. {news_text}\" if title else news_text\n",
        "    embedding = embedder.encode([doc], convert_to_numpy=True, normalize_embeddings=True)\n",
        "\n",
        "    try:\n",
        "        prediction = clf.predict(embedding)[0]\n",
        "        probability = clf.predict_proba(embedding)[0]\n",
        "        return {\n",
        "            \"classification\": \"Real\" if prediction == 1 else \"Fake\",\n",
        "            \"confidence\": float(max(probability)),\n",
        "            \"source\": \"LogisticRegression\"\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"Prediction error: {e}\")\n",
        "        return None\n",
        "\n",
        "# Quick test\n",
        "if 'clf' in globals():\n",
        "    test_text = \"Government announces new economic policies\"\n",
        "    result = predict_with_classifier(test_text)\n",
        "    if result:\n",
        "        print(f\"\\nTest prediction: '{test_text}' ‚Üí {result}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "58e605f041e64a76aac13329838ec4bb",
            "205ad7b7b4ed462da27cecbca3d17fa9",
            "14d415dc6cf34b438997e2c2432322c3",
            "ddcf823a347944c293374f5755c2ffe0",
            "a0b233b8b84a40b4841bfdfea3b5fcac",
            "3bab2a2407744a628ea08a109d42cc09",
            "06ec69c82f254aa8a36101b816723e55",
            "f5cac2c8000b455abf136cac4c0cbc19",
            "e0ae953f90ca4fab9dcdd4648fdf17e8",
            "627a8094044940a9a869064ba240470d",
            "84b8446ee385402d8383bc2664496862"
          ]
        },
        "id": "Dnjyojo9xiD-",
        "outputId": "606adbe6-ad96-4bc8-fe55-0ff904dcadac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training classifiers on 38550 labeled examples...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "58e605f041e64a76aac13329838ec4bb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1205 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Training LINEAR_SVC ===\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fake     0.9553    0.9551    0.9552      3471\n",
            "        Real     0.9632    0.9634    0.9633      4239\n",
            "\n",
            "    accuracy                         0.9597      7710\n",
            "   macro avg     0.9593    0.9592    0.9593      7710\n",
            "weighted avg     0.9597    0.9597    0.9597      7710\n",
            "\n",
            "Accuracy: 0.9597\n",
            "üíæ linear_svc model saved to: /content/fake-news-rag/data/processed/linear_svc_classifier.joblib\n",
            "\n",
            "=== Training BERNOULLI_NB ===\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fake     0.8190    0.8433    0.8309      3471\n",
            "        Real     0.8685    0.8474    0.8578      4239\n",
            "\n",
            "    accuracy                         0.8455      7710\n",
            "   macro avg     0.8437    0.8453    0.8444      7710\n",
            "weighted avg     0.8462    0.8455    0.8457      7710\n",
            "\n",
            "Accuracy: 0.8455\n",
            "üíæ bernoulli_nb model saved to: /content/fake-news-rag/data/processed/bernoulli_nb_classifier.joblib\n",
            "\n",
            "=== Training RANDOM_FOREST ===\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fake     0.9194    0.8776    0.8980      3471\n",
            "        Real     0.9033    0.9370    0.9199      4239\n",
            "\n",
            "    accuracy                         0.9102      7710\n",
            "   macro avg     0.9114    0.9073    0.9089      7710\n",
            "weighted avg     0.9106    0.9102    0.9100      7710\n",
            "\n",
            "Accuracy: 0.9102\n",
            "üíæ random_forest model saved to: /content/fake-news-rag/data/processed/random_forest_classifier.joblib\n",
            "\n",
            "=== Training GRADIENT_BOOST ===\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fake     0.9270    0.9107    0.9188      3471\n",
            "        Real     0.9279    0.9413    0.9345      4239\n",
            "\n",
            "    accuracy                         0.9275      7710\n",
            "   macro avg     0.9274    0.9260    0.9266      7710\n",
            "weighted avg     0.9275    0.9275    0.9274      7710\n",
            "\n",
            "Accuracy: 0.9275\n",
            "üíæ gradient_boost model saved to: /content/fake-news-rag/data/processed/gradient_boost_classifier.joblib\n",
            "\n",
            "=== Training KNN ===\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fake     0.9202    0.8300    0.8728      3471\n",
            "        Real     0.8712    0.9410    0.9047      4239\n",
            "\n",
            "    accuracy                         0.8911      7710\n",
            "   macro avg     0.8957    0.8855    0.8888      7710\n",
            "weighted avg     0.8932    0.8911    0.8903      7710\n",
            "\n",
            "Accuracy: 0.8911\n",
            "üíæ knn model saved to: /content/fake-news-rag/data/processed/knn_classifier.joblib\n",
            "X_test and y_test saved for evaluation.\n",
            "\n",
            "Test prediction (random_forest): 'Government announces new economic policies' ‚Üí {'classification': 'Real', 'confidence': 0.725, 'source': 'random_forest'}\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import joblib\n",
        "from pathlib import Path\n",
        "\n",
        "# Define PROC_DIR if not already defined\n",
        "PROC_DIR = Path(\"/content/fake-news-rag/data/processed\")\n",
        "PROC_DIR.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "# Add only NEW classifiers (exclude LogisticRegression since you already have it)\n",
        "CLASSIFIERS = {\n",
        "    \"linear_svc\": LinearSVC(class_weight=\"balanced\"),\n",
        "    \"bernoulli_nb\": BernoulliNB(),\n",
        "    \"random_forest\": RandomForestClassifier(n_estimators=200, class_weight=\"balanced\", random_state=42),\n",
        "    \"gradient_boost\": GradientBoostingClassifier(n_estimators=200, random_state=42),\n",
        "    \"knn\": KNeighborsClassifier(n_neighbors=5)\n",
        "}\n",
        "\n",
        "# Helper: Load dataset\n",
        "def load_dataset():\n",
        "    if 'combined_df' in globals() and len(combined_df) > 0:\n",
        "        return combined_df\n",
        "\n",
        "    PROC_PATH = PROC_DIR / \"clean_dataset.csv\"\n",
        "    if PROC_PATH.exists():\n",
        "        print(\"Loading combined_df from processed file for classifier training...\")\n",
        "        try:\n",
        "            return pd.read_csv(PROC_PATH)\n",
        "        except Exception as e:\n",
        "            print(f\"Could not load processed file: {e}.\")\n",
        "    print(\"combined_df not found. Skipping classifier training.\")\n",
        "    return pd.DataFrame()\n",
        "\n",
        "# Train all classifiers (except LogisticRegression which you already did)\n",
        "combined_df = load_dataset()\n",
        "labeled = combined_df.dropna(subset=[\"label\"]).copy()\n",
        "\n",
        "if len(labeled) == 0:\n",
        "    print(\"No labeled data available for classifier training. Skipping...\")\n",
        "else:\n",
        "    print(f\"Training classifiers on {len(labeled)} labeled examples...\")\n",
        "\n",
        "    def to_doc(row):\n",
        "        title = str(row['title']) if pd.notna(row['title']) else ''\n",
        "        text = str(row['text']) if pd.notna(row['text']) else ''\n",
        "        return f\"{title}. {text}\"\n",
        "\n",
        "    X_docs = [to_doc(row) for _, row in labeled.iterrows()]\n",
        "    X_docs = [doc for doc in X_docs if isinstance(doc, str) and len(doc.strip()) > 0]\n",
        "\n",
        "    if not X_docs:\n",
        "        print(\"No valid documents generated for embedding. Skipping classifier training.\")\n",
        "    else:\n",
        "        X_emb = embedder.encode(X_docs, convert_to_numpy=True, show_progress_bar=True, normalize_embeddings=True)\n",
        "        y     = labeled[\"label\"].astype(int).values[:len(X_emb)]\n",
        "\n",
        "        if len(X_emb) >= 10:\n",
        "            X_train, X_test, y_train, y_test = train_test_split(\n",
        "                X_emb, y, test_size=0.2, random_state=42, stratify=y\n",
        "            )\n",
        "\n",
        "            for name, model in CLASSIFIERS.items():\n",
        "                print(f\"\\n=== Training {name.upper()} ===\")\n",
        "                try:\n",
        "                    model.fit(X_train, y_train)\n",
        "                    y_pred = model.predict(X_test)\n",
        "\n",
        "                    print(\"Classification Report:\")\n",
        "                    print(classification_report(y_test, y_pred, digits=4, target_names=[\"Fake\", \"Real\"]))\n",
        "                    print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "\n",
        "                    # Save model\n",
        "                    path = PROC_DIR / f\"{name}_classifier.joblib\"\n",
        "                    joblib.dump(model, path)\n",
        "                    print(f\"üíæ {name} model saved to: {path}\")\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"‚ùå Error training {name}: {e}\")\n",
        "\n",
        "            # Save test data once\n",
        "            np.save(PROC_DIR / \"X_test.npy\", X_test)\n",
        "            np.save(PROC_DIR / \"y_test.npy\", y_test)\n",
        "            print(\"X_test and y_test saved for evaluation.\")\n",
        "        else:\n",
        "            print(f\"Not enough data ({len(X_emb)} samples). Need at least 10.\")\n",
        "\n",
        "# Prediction function for new classifiers\n",
        "def predict_with_classifier(news_text, title=\"\", model_name=\"random_forest\"):\n",
        "    path = PROC_DIR / f\"{model_name}_classifier.joblib\"\n",
        "    if not path.exists():\n",
        "        print(f\"Model {model_name} not trained or not found.\")\n",
        "        return None\n",
        "\n",
        "    clf = joblib.load(path)\n",
        "    doc = f\"{title}. {news_text}\" if title else news_text\n",
        "    embedding = embedder.encode([doc], convert_to_numpy=True, normalize_embeddings=True)\n",
        "\n",
        "    try:\n",
        "        prediction = clf.predict(embedding)[0]\n",
        "        confidence = None\n",
        "        if hasattr(clf, \"predict_proba\"):\n",
        "            probability = clf.predict_proba(embedding)[0]\n",
        "            confidence = float(max(probability))\n",
        "\n",
        "        return {\n",
        "            \"classification\": \"Real\" if prediction == 1 else \"Fake\",\n",
        "            \"confidence\": confidence,\n",
        "            \"source\": model_name\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"Prediction error with {model_name}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Quick test with RandomForest\n",
        "test_text = \"Government announces new economic policies\"\n",
        "result = predict_with_classifier(test_text, model_name=\"random_forest\")\n",
        "if result:\n",
        "    print(f\"\\nTest prediction ({result['source']}): '{test_text}' ‚Üí {result}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SgeqVBS9zk90",
        "outputId": "b14fef11-4c8f-4669-cf0a-3ff3822a883d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "PROC_DIR = Path(\"/content/fake-news-rag/data/processed\")\n",
        "print((PROC_DIR / \"X_test.npy\").exists())\n",
        "print((PROC_DIR / \"y_test.npy\").exists())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "2ffff4a0f1f34318b40c69518d79f808",
            "83468de6793749fbaa9c34bebd9a0762",
            "87be023f37f044f292ee1d0cefef7db6",
            "56a6a3129a064378ad1b6fb8b41201dd",
            "a6deb61e62964882ac4a82e048029a3f",
            "7786863e4595462d87f503ffa2e8e699",
            "3e69a032c52343328ffd1a009f982a05",
            "bb0d9b67408f4dd0ae03e503f5e20c61",
            "074b6dc9a2d24607b9bb8706e74f4ce8",
            "17f6619ed1a542a2a904d5c26d1afed5",
            "7811768fd2014554b4296cad8d7eee34",
            "9cda829e683d4a41ac148540612d2a43",
            "0ec0626b95d3465b95fce6dcb343385b",
            "1b2c2fc026c3401b9fa76c9e653baf27",
            "d9a9e55000ce4dc1afde50c9372bbad1",
            "76bb6e0ba048489ca89f0f417e1d8b9f",
            "b5e4eecab2b24ec892db0e006ab10fcd",
            "8ad37d379eea4c9284d9a4aa3df16b65",
            "6d07913d38c443449dad825f84a291e8",
            "770af29837c54b328f0fbb5650261591",
            "2aa2f94e7df0442c8b43e5ed43810e02",
            "4f0bcc794983420d834d495fc69c0260"
          ]
        },
        "id": "5Q0FDfqY4iAX",
        "outputId": "02819aea-790d-436c-b48c-2918e3f5a111"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== üöÄ Training Improvements ===\n",
            "Starting with 38550 labeled samples\n",
            "Training samples: 27769, Test samples: 6943\n",
            "üîÑ Creating embeddings...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2ffff4a0f1f34318b40c69518d79f808",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/868 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9cda829e683d4a41ac148540612d2a43",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/217 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== üîπ Training LogisticRegression ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_search.py:317: UserWarning: The total space of parameters 3 is smaller than n_iter=5. Running 3 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Best LogisticRegression params: {'C': 10}\n",
            "‚úÖ CV F1: 0.9551\n",
            "‚úÖ Test Accuracy: 0.9516, Test F1: 0.9518\n",
            "üíæ Saved LogisticRegression to /content/fake-news-rag/data/processed/logisticregression_classifier.joblib\n",
            "\n",
            "=== üîπ Training RandomForest ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_search.py:317: UserWarning: The total space of parameters 4 is smaller than n_iter=5. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Best RandomForest params: {'n_estimators': 200, 'max_depth': None}\n",
            "‚úÖ CV F1: 0.8913\n",
            "‚úÖ Test Accuracy: 0.8874, Test F1: 0.8873\n",
            "üíæ Saved RandomForest to /content/fake-news-rag/data/processed/randomforest_classifier.joblib\n",
            "\n",
            "=== üîπ Training SVM ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Best SVM params: {'kernel': 'rbf', 'C': 2}\n",
            "‚úÖ CV F1: 0.9692\n",
            "‚úÖ Test Accuracy: 0.9703, Test F1: 0.9705\n",
            "üíæ Saved SVM to /content/fake-news-rag/data/processed/svm_classifier.joblib\n",
            "\n",
            "=== üîπ Training LinearSVC ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_search.py:317: UserWarning: The total space of parameters 3 is smaller than n_iter=5. Running 3 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Best LinearSVC params: {'C': 10}\n",
            "‚úÖ CV F1: 0.9599\n",
            "‚úÖ Test Accuracy: 0.9568, Test F1: 0.9570\n",
            "üíæ Saved LinearSVC to /content/fake-news-rag/data/processed/linearsvc_classifier.joblib\n",
            "\n",
            "=== üîπ Training BernoulliNB ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_search.py:317: UserWarning: The total space of parameters 3 is smaller than n_iter=5. Running 3 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Best BernoulliNB params: {'alpha': 1}\n",
            "‚úÖ CV F1: 0.8444\n",
            "‚úÖ Test Accuracy: 0.8457, Test F1: 0.8439\n",
            "üíæ Saved BernoulliNB to /content/fake-news-rag/data/processed/bernoullinb_classifier.joblib\n",
            "\n",
            "=== üîπ Training XGBoost ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [17:44:02] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Best XGBoost params: {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.1}\n",
            "‚úÖ CV F1: 0.9216\n",
            "‚úÖ Test Accuracy: 0.9191, Test F1: 0.9188\n",
            "üíæ Saved XGBoost to /content/fake-news-rag/data/processed/xgboost_classifier.joblib\n",
            "\n",
            "=== üîπ Training LightGBM ===\n",
            "[LightGBM] [Info] Number of positive: 13885, number of negative: 13884\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028203 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 25500\n",
            "[LightGBM] [Info] Number of data points in the train set: 27769, number of used features: 100\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500018 -> initscore=0.000072\n",
            "[LightGBM] [Info] Start training from score 0.000072\n",
            "‚úÖ Best LightGBM params: {'n_estimators': 200, 'max_depth': -1, 'learning_rate': 0.1}\n",
            "‚úÖ CV F1: 0.9240\n",
            "‚úÖ Test Accuracy: 0.9192, Test F1: 0.9189\n",
            "üíæ Saved LightGBM to /content/fake-news-rag/data/processed/lightgbm_classifier.joblib\n",
            "\n",
            "üèÜ Best overall model: SVC with F1 = 0.9705\n",
            "‚úÖ Training data embeddings saved\n",
            "\n",
            "=== üöÄ Fast Training Complete ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üíæ Saved best model metrics to /content/fake-news-rag/data/processed/best_model_metrics.json\n"
          ]
        }
      ],
      "source": [
        "# ===== üöÄ FAST TRAINING PIPELINE =====\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.utils import resample\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "import joblib\n",
        "import numpy as np\n",
        "import os\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "# ==== Directories ====\n",
        "BASE_DIR = Path(\"/content/fake-news-rag\")\n",
        "PROC_DIR = BASE_DIR / \"data\" / \"processed\"\n",
        "os.makedirs(PROC_DIR, exist_ok=True)\n",
        "\n",
        "# ==== Load data ====\n",
        "if 'combined_df' not in globals():\n",
        "    try:\n",
        "        combined_df = pd.read_csv(PROC_DIR / \"clean_dataset.csv\")\n",
        "        print(\"‚úÖ Loaded combined_df from processed file\")\n",
        "    except:\n",
        "        print(\"‚ùå No data available for training improvements\")\n",
        "        combined_df = pd.DataFrame()\n",
        "\n",
        "# ==== Prepare dataset ====\n",
        "labeled_data = combined_df.dropna(subset=[\"label\"]).copy() if not combined_df.empty else pd.DataFrame()\n",
        "if len(labeled_data) < 20:\n",
        "    print(\"‚ö†Ô∏è Not enough labeled data for training improvements. Need at least 20 samples.\")\n",
        "else:\n",
        "    print(f\"\\n=== üöÄ Training Improvements ===\")\n",
        "    print(f\"Starting with {len(labeled_data)} labeled samples\")\n",
        "\n",
        "    # Balance dataset\n",
        "    class_counts = labeled_data[\"label\"].value_counts()\n",
        "    min_class_count = min(class_counts)\n",
        "    df_balanced = (\n",
        "        labeled_data if min_class_count < 10 else pd.concat([\n",
        "            labeled_data[labeled_data[\"label\"]==0].sample(min_class_count, random_state=42),\n",
        "            labeled_data[labeled_data[\"label\"]==1].sample(min_class_count, random_state=42)\n",
        "        ])\n",
        "    )\n",
        "\n",
        "    # Combine title + text\n",
        "    documents = df_balanced.apply(lambda r: f\"{r['title']} {r['text']}\".strip(), axis=1).tolist()\n",
        "    labels = df_balanced[\"label\"].astype(int).values\n",
        "\n",
        "    # Split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        documents, labels, test_size=0.2, random_state=42, stratify=labels\n",
        "    )\n",
        "    print(f\"Training samples: {len(X_train)}, Test samples: {len(X_test)}\")\n",
        "\n",
        "    # Embeddings\n",
        "    print(\"üîÑ Creating embeddings...\")\n",
        "    X_train_emb = embedder.encode(X_train, show_progress_bar=True, convert_to_numpy=True)\n",
        "    X_test_emb = embedder.encode(X_test, show_progress_bar=True, convert_to_numpy=True)\n",
        "\n",
        "    # Dimensionality reduction for tree-based models (keeps 100 features)\n",
        "    svd = TruncatedSVD(n_components=100, random_state=42)\n",
        "    X_train_red = svd.fit_transform(X_train_emb)\n",
        "    X_test_red = svd.transform(X_test_emb)\n",
        "\n",
        "    # ==== Classifiers ====\n",
        "    CLASSIFIERS = {\n",
        "        \"LogisticRegression\": (\n",
        "            LogisticRegression(max_iter=1000, class_weight=\"balanced\"),\n",
        "            {\"C\": [0.1, 1, 10]}\n",
        "        ),\n",
        "        \"RandomForest\": (\n",
        "            RandomForestClassifier(class_weight=\"balanced\", random_state=42, n_jobs=-1),\n",
        "            {\"n_estimators\": [100, 200], \"max_depth\": [10, None]}\n",
        "        ),\n",
        "        \"SVM\": (\n",
        "            SVC(class_weight=\"balanced\", probability=True),\n",
        "            {\"C\": [0.5, 1, 2], \"kernel\": [\"linear\", \"rbf\"]}\n",
        "        ),\n",
        "        \"LinearSVC\": (\n",
        "            LinearSVC(class_weight=\"balanced\", max_iter=5000),\n",
        "            {\"C\": [0.1, 1, 10]}\n",
        "        ),\n",
        "        \"BernoulliNB\": (\n",
        "            BernoulliNB(),\n",
        "            {\"alpha\": [0.1, 1, 5]}\n",
        "        ),\n",
        "        \"XGBoost\": (\n",
        "            XGBClassifier(\n",
        "                tree_method=\"hist\",  # fast training\n",
        "                eval_metric=\"logloss\",\n",
        "                use_label_encoder=False,\n",
        "                n_jobs=-1,\n",
        "                random_state=42\n",
        "            ),\n",
        "            {\"n_estimators\": [100, 200], \"learning_rate\": [0.05, 0.1], \"max_depth\": [3, 5]}\n",
        "        ),\n",
        "        \"LightGBM\": (\n",
        "            LGBMClassifier(random_state=42, n_jobs=-1),\n",
        "            {\"n_estimators\": [100, 200], \"learning_rate\": [0.05, 0.1], \"max_depth\": [-1, 5]}\n",
        "        )\n",
        "    }\n",
        "\n",
        "    # ==== Training Loop ====\n",
        "    best_overall, best_f1 = None, -1\n",
        "    for name, (model, param_dist) in CLASSIFIERS.items():\n",
        "        print(f\"\\n=== üîπ Training {name} ===\")\n",
        "        try:\n",
        "            # Use reduced embeddings for tree models\n",
        "            Xtr, Xte = (X_train_red, X_test_red) if name in [\"RandomForest\", \"XGBoost\", \"LightGBM\"] else (X_train_emb, X_test_emb)\n",
        "\n",
        "            clf = RandomizedSearchCV(\n",
        "                model,\n",
        "                param_distributions=param_dist,\n",
        "                n_iter=5,   # test only 5 random param combos\n",
        "                cv=3,\n",
        "                scoring=\"f1\",\n",
        "                n_jobs=-1,\n",
        "                random_state=42\n",
        "            )\n",
        "            clf.fit(Xtr, y_train)\n",
        "\n",
        "            print(f\"‚úÖ Best {name} params: {clf.best_params_}\")\n",
        "            print(f\"‚úÖ CV F1: {clf.best_score_:.4f}\")\n",
        "\n",
        "            y_pred = clf.predict(Xte)\n",
        "            acc, f1 = accuracy_score(y_test, y_pred), f1_score(y_test, y_pred)\n",
        "            print(f\"‚úÖ Test Accuracy: {acc:.4f}, Test F1: {f1:.4f}\")\n",
        "\n",
        "            # Save model\n",
        "            model_path = PROC_DIR / f\"{name.lower()}_classifier.joblib\"\n",
        "            joblib.dump(clf.best_estimator_, model_path)\n",
        "            print(f\"üíæ Saved {name} to {model_path}\")\n",
        "\n",
        "            if f1 > best_f1:\n",
        "                best_f1, best_overall = f1, clf.best_estimator_\n",
        "                globals()['clf'] = best_overall\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Skipped {name} due to error: {e}\")\n",
        "\n",
        "    print(f\"\\nüèÜ Best overall model: {best_overall.__class__.__name__} with F1 = {best_f1:.4f}\")\n",
        "\n",
        "    # Save embeddings\n",
        "    np.save(PROC_DIR / \"X_train_emb.npy\", X_train_emb)\n",
        "    np.save(PROC_DIR / \"X_test_emb.npy\", X_test_emb)\n",
        "    np.save(PROC_DIR / \"y_train.npy\", y_train)\n",
        "    np.save(PROC_DIR / \"y_test.npy\", y_test)\n",
        "    print(\"‚úÖ Training data embeddings saved\")\n",
        "\n",
        "print(\"\\n=== üöÄ Fast Training Complete ===\")\n",
        "import json\n",
        "\n",
        "# ==== Save best model metrics ====\n",
        "if best_overall is not None:\n",
        "    metrics = {\n",
        "        \"best_model\": best_overall.__class__.__name__,\n",
        "        \"accuracy\": float(accuracy_score(y_test, best_overall.predict(X_test_emb))),\n",
        "        \"f1\": float(f1_score(y_test, best_overall.predict(X_test_emb)))\n",
        "    }\n",
        "    METRICS_PATH = PROC_DIR / \"best_model_metrics.json\"\n",
        "    with open(METRICS_PATH, \"w\") as f:\n",
        "        json.dump(metrics, f, indent=4)\n",
        "    print(f\"üíæ Saved best model metrics to {METRICS_PATH}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-3I7q-aWNbM",
        "outputId": "217089ce-4418-477f-b0a3-1158acf534dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üíæ Saved best model and metrics!\n"
          ]
        }
      ],
      "source": [
        "import json, joblib\n",
        "\n",
        "if best_overall is not None:\n",
        "    metrics = {\n",
        "        \"best_model\": best_overall.__class__.__name__,\n",
        "        \"accuracy\": float(accuracy_score(y_test, best_overall.predict(X_test_emb))),\n",
        "        \"f1\": float(f1_score(y_test, best_overall.predict(X_test_emb)))\n",
        "    }\n",
        "\n",
        "    # Save JSON for human readability\n",
        "    with open(PROC_DIR / \"best_model_metrics.json\", \"w\") as f:\n",
        "        json.dump(metrics, f, indent=4)\n",
        "\n",
        "    # Save JOBLIB with a consistent filename\n",
        "    joblib.dump(metrics, PROC_DIR / \"best_model_metrics.joblib\")\n",
        "\n",
        "    print(\"üíæ Saved best model and metrics!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDDZN6QdXcVc",
        "outputId": "1125003d-0029-4749-dea6-476ccdd31e94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Loaded metrics: {'best_model': 'SVC', 'accuracy': 0.9703298286043497, 'f1': 0.970487106017192}\n"
          ]
        }
      ],
      "source": [
        "import joblib\n",
        "\n",
        "metrics_path = PROC_DIR / \"best_model_metrics.joblib\"\n",
        "\n",
        "if metrics_path.exists():\n",
        "    metrics = joblib.load(metrics_path)\n",
        "    print(f\"‚úÖ Loaded metrics: {metrics}\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No saved metrics found, accuracy will not be displayed.\")\n",
        "    metrics = {\"accuracy\": None, \"f1\": None}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16hBdTWcpuJv",
        "outputId": "1b5804e5-e411-4946-fc1a-f7fcb13b9728"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Metrics loaded: Accuracy=0.9703298286043497, F1=0.970487106017192\n",
            "‚úÖ FAISS index loaded with 41106 vectors\n",
            "\n",
            "üöÄ Running smoke test...\n",
            "‚ö†Ô∏è Classifier prediction failed: X has 384 features, but LGBMClassifier is expecting 100 features as input.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Azure API error: Error code: 500 - {'error': {'code': 'Internal Server Error', 'message': 'An error occurred during the request processing: All connection attempts failed | Type: ConnectError | Traceback (most recent call last):||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/httpx/_transports/default.py\", line 66, in map_httpcore_exceptions||    yield||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/httpx/_transports/default.py\", line 366, in handle_async_request||    resp = await self._pool.handle_async_request(req)||           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/httpcore/_async/connection_pool.py\", line 256, in handle_async_request||    raise exc from None||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/httpcore/_async/connection_pool.py\", line 236, in handle_async_request||    response = await connection.handle_async_request(||               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/httpcore/_async/connection.py\", line 101, in handle_async_request||    raise exc||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/httpcore/_async/connection.py\", line 78, in handle_async_request||    stream = await self._connect(request)||             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/httpcore/_async/connection.py\", line 124, in _connect||    stream = await self._network_backend.connect_tcp(**kwargs)||             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/httpcore/_backends/auto.py\", line 31, in connect_tcp||    return await self._backend.connect_tcp(||           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/httpcore/_backends/anyio.py\", line 113, in connect_tcp||    with map_exceptions(exc_map):||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/contextlib.py\", line 158, in __exit__||    self.gen.throw(typ, value, traceback)||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions||    raise to_exc(exc) from exc||httpcore.ConnectError: All connection attempts failed||||The above exception was the direct cause of the following exception:||||Traceback (most recent call last):||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/starlette/middleware/errors.py\", line 164, in __call__||    await self.app(scope, receive, _send)||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/billingproxy/main.py\", line 452, in __call__||    return await handler_task||           ^^^^^^^^^^^^^^^^^^||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/starlette/middleware/base.py\", line 189, in __call__||    with collapse_excgroups():||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/contextlib.py\", line 158, in __exit__||    self.gen.throw(typ, value, traceback)||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/starlette/_utils.py\", line 93, in collapse_excgroups||    raise exc||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/starlette/middleware/base.py\", line 191, in __call__||    response = await self.dispatch_func(request, call_next)||               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/billingproxy/main.py\", line 418, in dispatch||    response = await call_next(request)||               ^^^^^^^^^^^^^^^^^^^^^^^^||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/starlette/middleware/base.py\", line 165, in call_next||    raise app_exc||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/starlette/middleware/base.py\", line 151, in coro||    await self.app(scope, receive_or_disconnect, send_no_error)||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/starlette/middleware/base.py\", line 189, in __call__||    with collapse_excgroups():||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/contextlib.py\", line 158, in __exit__||    self.gen.throw(typ, value, traceback)||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/starlette/_utils.py\", line 93, in collapse_excgroups||    raise exc||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/starlette/middleware/base.py\", line 191, in __call__||    response = await self.dispatch_func(request, call_next)||               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/billingproxy/main.py\", line 394, in dispatch||    response = await call_next(request)||               ^^^^^^^^^^^^^^^^^^^^^^^^||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/starlette/middleware/base.py\", line 165, in call_next||    raise app_exc||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/starlette/middleware/base.py\", line 151, in coro||    await self.app(scope, receive_or_disconnect, send_no_error)||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/starlette/middleware/cors.py\", line 85, in __call__||    await self.app(scope, receive, send)||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/starlette/middleware/exceptions.py\", line 65, in __call__||    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 64, in wrapped_app||    raise exc||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app||    await app(scope, receive, sender)||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/starlette/routing.py\", line 756, in __call__||    await self.middleware_stack(scope, receive, send)||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/starlette/routing.py\", line 776, in app||    await route.handle(scope, receive, send)||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/starlette/routing.py\", line 297, in handle||    await self.app(scope, receive, send)||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/starlette/routing.py\", line 77, in app||    await wrap_app_handling_exceptions(app, request)(scope, receive, send)||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 64, in wrapped_app||    raise exc||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app||    await app(scope, receive, sender)||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/starlette/routing.py\", line 72, in app||    response = await func(request)||               ^^^^^^^^^^^^^^^^^^^||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/fastapi/routing.py\", line 278, in app||    raw_response = await run_endpoint_function(||                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/fastapi/routing.py\", line 191, in run_endpoint_function||    return await dependant.call(**values)||           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/billingproxy/apis/vllm/chat.py\", line 372, in chat||    response = await downstream_client_getter().send(downstream_request)||               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/httpx/_client.py\", line 1617, in send||    response = await self._send_handling_auth(||               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/httpx/_client.py\", line 1645, in _send_handling_auth||    response = await self._send_handling_redirects(||               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/httpx/_client.py\", line 1682, in _send_handling_redirects||    response = await self._send_single_request(request)||               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/httpx/_client.py\", line 1719, in _send_single_request||    response = await transport.handle_async_request(request)||               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/httpx/_transports/default.py\", line 365, in handle_async_request||    with map_httpcore_exceptions():||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/contextlib.py\", line 158, in __exit__||    self.gen.throw(typ, value, traceback)||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/httpx/_transports/default.py\", line 83, in map_httpcore_exceptions||    raise mapped_exc(message) from exc||httpx.ConnectError: All connection attempts failed||', 'status': 500}}\n",
            "\n",
            "‚úÖ Final classification: Unknown (confidence: None, accuracy: 0.9703298286043497)\n",
            "Reason: No classifier or LLM decision available.\n",
            "Retrieved 5 relevant documents\n",
            "\n",
            "1. Score: 0.6456 - Exclusive: India pares back planned funding for crucial publ...\n",
            "2. Score: 0.5483 - Health reform commission: Form task force to implement its r...\n",
            "3. Score: 0.5462 - Project to combat NCD launched...\n"
          ]
        }
      ],
      "source": [
        "# ===== üöÄ FAST RAG PIPELINE =====\n",
        "import math\n",
        "import joblib\n",
        "import faiss\n",
        "\n",
        "# ‚úÖ Load saved metrics consistently (always same file)\n",
        "metrics_path = PROC_DIR / \"best_model_metrics.joblib\"\n",
        "\n",
        "if metrics_path.exists():\n",
        "    metrics = joblib.load(metrics_path)\n",
        "    print(f\"‚úÖ Metrics loaded: Accuracy={metrics.get('accuracy')}, F1={metrics.get('f1')}\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No saved metrics found, accuracy will not be displayed.\")\n",
        "    metrics = {\"accuracy\": None, \"f1\": None}\n",
        "\n",
        "\n",
        "\n",
        "def faiss_reload() -> faiss.Index:\n",
        "    \"\"\"Reload or build FAISS index\"\"\"\n",
        "    if FAISS_PATH.exists():\n",
        "        return faiss.read_index(str(FAISS_PATH))\n",
        "\n",
        "    print(\"‚ö†Ô∏è FAISS index not found. Creating new index...\")\n",
        "    docs = combined_df.apply(to_doc, axis=1).tolist()\n",
        "    emb = embedder.encode(\n",
        "        docs,\n",
        "        batch_size=128,  # üî• larger batch for speed\n",
        "        convert_to_numpy=True,\n",
        "        show_progress_bar=True,\n",
        "        normalize_embeddings=True\n",
        "    ).astype(\"float32\")\n",
        "\n",
        "    dim = emb.shape[1]\n",
        "    index = faiss.IndexFlatIP(dim)\n",
        "    index.add(emb)\n",
        "    faiss.write_index(index, str(FAISS_PATH))\n",
        "    return index\n",
        "\n",
        "\n",
        "# Load FAISS index once\n",
        "faiss_index = faiss_reload()\n",
        "print(f\"‚úÖ FAISS index loaded with {faiss_index.ntotal} vectors\")\n",
        "\n",
        "\n",
        "def retrieve_top_k(query_text: str, k: int = 5):\n",
        "    \"\"\"Retrieve top-k similar documents with FAISS\"\"\"\n",
        "    q = embedder.encode(\n",
        "        [query_text],\n",
        "        batch_size=1,\n",
        "        convert_to_numpy=True,\n",
        "        normalize_embeddings=True\n",
        "    ).astype(\"float32\")\n",
        "\n",
        "    D, I = faiss_index.search(q, k)\n",
        "    rows = []\n",
        "    for score, idx in zip(D[0], I[0]):\n",
        "        if 0 <= idx < len(combined_df):\n",
        "            row = combined_df.iloc[int(idx)]\n",
        "            rows.append({\n",
        "                \"score\": float(score),\n",
        "                \"title\": row[\"title\"],\n",
        "                \"text\": row[\"text\"],\n",
        "                \"label\": None if pd.isna(row[\"label\"]) else int(row[\"label\"]),\n",
        "                \"lang\": row.get(\"lang\", \"unknown\"),\n",
        "                \"source\": row.get(\"source\", \"\"),\n",
        "                \"idx\": int(idx)\n",
        "            })\n",
        "    return rows\n",
        "\n",
        "\n",
        "def rag_infer(news_title: str, news_text: str, k: int = 5, use_llm: bool = True) -> dict:\n",
        "    \"\"\"\n",
        "    Retrieve docs + classify with fast model + (optionally) LLM.\n",
        "    \"\"\"\n",
        "    inp = f\"{news_title}. {news_text}\".strip()\n",
        "    retrieved = retrieve_top_k(inp, k=k)\n",
        "    context_docs = [f\"{r['title']}\\n{r['text']}\" for r in retrieved]\n",
        "\n",
        "    # ===== Fast classifier prediction =====\n",
        "    fast_label, fast_conf = None, None\n",
        "    if 'clf' in globals() and hasattr(clf, \"predict_proba\"):\n",
        "        try:\n",
        "            fast_emb = embedder.encode(\n",
        "                [inp],\n",
        "                convert_to_numpy=True,\n",
        "                normalize_embeddings=True\n",
        "            )\n",
        "            probs = clf.predict_proba(fast_emb)[0]\n",
        "            fast_label = int(np.argmax(probs))\n",
        "            fast_conf = float(np.max(probs))\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Classifier prediction failed: {e}\")\n",
        "\n",
        "    # ===== LLM classification =====\n",
        "    llm_out = llm_classify_and_timeline(inp, context_docs, few_shots=few_shots) if use_llm else None\n",
        "\n",
        "    # ===== Merge policy =====\n",
        "    final_class, final_conf, timeline, reason = None, None, None, \"\"\n",
        "    if llm_out and llm_out.get(\"classification\") in [\"Real\", \"Fake\"]:\n",
        "        final_class = llm_out[\"classification\"]\n",
        "        final_conf = llm_out.get(\"confidence\")\n",
        "        timeline = llm_out.get(\"timeline\")\n",
        "        reason = llm_out.get(\"reason\", \"\")\n",
        "    elif fast_label is not None:\n",
        "        final_class = \"Real\" if fast_label == 1 else \"Fake\"\n",
        "        final_conf = fast_conf\n",
        "        reason = \"LLM insufficient context; used embedding classifier.\" if llm_out else \"LLM disabled; used embedding classifier.\"\n",
        "    else:\n",
        "        final_class, final_conf, reason = \"Unknown\", None, \"No classifier or LLM decision available.\"\n",
        "\n",
        "    return {\n",
        "        \"input\": {\"title\": news_title, \"text\": news_text},\n",
        "        \"retrieved\": retrieved,\n",
        "        \"fast_classifier\": {\n",
        "            \"label\": (\"Real\" if fast_label == 1 else \"Fake\") if fast_label is not None else None,\n",
        "            \"confidence\": fast_conf,\n",
        "            \"accuracy\": metrics.get(\"accuracy\")\n",
        "        },\n",
        "        \"llm_output\": llm_out,\n",
        "        \"final\": {\n",
        "            \"label\": final_class,\n",
        "            \"confidence\": final_conf,\n",
        "            \"timeline\": timeline,\n",
        "            \"reason\": reason,\n",
        "            \"accuracy\": metrics.get(\"accuracy\")\n",
        "        }\n",
        "    }\n",
        "\n",
        "\n",
        "# ===== Quick Smoke Test =====\n",
        "print(\"\\nüöÄ Running smoke test...\")\n",
        "sample = rag_infer(\n",
        "    news_title=\"Government announces new health initiative\",\n",
        "    news_text=\"The government of Bangladesh announced funding for rural clinics.\"\n",
        ")\n",
        "\n",
        "print(f\"\\n‚úÖ Final classification: {sample['final']['label']} \"\n",
        "      f\"(confidence: {sample['final']['confidence']}, \"\n",
        "      f\"accuracy: {sample['final']['accuracy']})\")\n",
        "print(f\"Reason: {sample['final']['reason']}\")\n",
        "print(f\"Retrieved {len(sample['retrieved'])} relevant documents\\n\")\n",
        "\n",
        "for i, doc in enumerate(sample['retrieved'][:3], 1):\n",
        "    print(f\"{i}. Score: {doc['score']:.4f} - {doc['title'][:60]}...\")\n",
        "\n",
        "if sample['final'].get(\"timeline\"):\n",
        "    print(f\"\\nüóì Timeline: {sample['final']['timeline']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGGrkVelvy5Q",
        "outputId": "17497a34-37d7-4f93-fa55-bb12f8c4f54f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.100.0)\n",
            "Collecting chromadb\n",
            "  Downloading chromadb-1.0.20-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: newspaper3k in /usr/local/lib/python3.12/dist-packages (0.2.8)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (2.7.0)\n",
            "Requirement already satisfied: lxml_html_clean in /usr/local/lib/python3.12/dist-packages (0.4.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.14.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.3.0)\n",
            "Collecting pybase64>=1.4.1 (from chromadb)\n",
            "  Downloading pybase64-1.4.2-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.35.0)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.26.4)\n",
            "Collecting posthog<6.0.0,>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.22.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.36.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.36.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.36.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.21.4)\n",
            "Collecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting overrides>=7.3.1 (from chromadb)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.12/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.74.0)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Downloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.16.0)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb)\n",
            "  Downloading kubernetes-33.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from chromadb) (8.5.0)\n",
            "Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (6.0.2)\n",
            "Collecting mmh3>=4.0.1 (from chromadb)\n",
            "  Downloading mmh3-5.2.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (14 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.12/dist-packages (from chromadb) (3.11.2)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.25.1)\n",
            "Requirement already satisfied: requests<3.0,>=2.7 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.32.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.2 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.9.0.post0)\n",
            "Collecting backoff>=1.10.0 (from posthog<6.0.0,>=2.4.0->chromadb)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0,>=2.7->posthog<6.0.0,>=2.4.0->chromadb) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0,>=2.7->posthog<6.0.0,>=2.4.0->chromadb) (2.5.0)\n",
            "Requirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.12/dist-packages (from newspaper3k) (4.13.4)\n",
            "Requirement already satisfied: Pillow>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from newspaper3k) (11.3.0)\n",
            "Requirement already satisfied: cssselect>=0.9.2 in /usr/local/lib/python3.12/dist-packages (from newspaper3k) (1.3.0)\n",
            "Requirement already satisfied: lxml>=3.6.0 in /usr/local/lib/python3.12/dist-packages (from newspaper3k) (5.4.0)\n",
            "Requirement already satisfied: nltk>=3.2.1 in /usr/local/lib/python3.12/dist-packages (from newspaper3k) (3.9.1)\n",
            "Requirement already satisfied: feedparser>=5.2.1 in /usr/local/lib/python3.12/dist-packages (from newspaper3k) (6.0.11)\n",
            "Requirement already satisfied: tldextract>=2.0.1 in /usr/local/lib/python3.12/dist-packages (from newspaper3k) (5.3.0)\n",
            "Requirement already satisfied: feedfinder2>=0.0.4 in /usr/local/lib/python3.12/dist-packages (from newspaper3k) (0.0.4)\n",
            "Requirement already satisfied: jieba3k>=0.35.1 in /usr/local/lib/python3.12/dist-packages (from newspaper3k) (0.35.1)\n",
            "Requirement already satisfied: tinysegmenter==0.3 in /usr/local/lib/python3.12/dist-packages (from newspaper3k) (0.3)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.55.2)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.8.0+cu126)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.34.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (3.19.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (25.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (1.1.7)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4>=4.4.1->newspaper3k) (2.7)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.12/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
            "Requirement already satisfied: sgmllib3k in /usr/local/lib/python3.12/dist-packages (from feedparser>=5.2.1->newspaper3k) (1.0.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.27.0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.38.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (3.3.1)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
            "  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.12/dist-packages (from rsa<5,>=3.1.4->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk>=3.2.1->newspaper3k) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk>=3.2.1->newspaper3k) (1.5.1)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.3)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.70.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.36.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.36.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.36.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_proto-1.36.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.57b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk>=1.2.0->chromadb) (0.57b0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: requests-file>=1.4 in /usr/local/lib/python3.12/dist-packages (from tldextract>=2.0.1->newspaper3k) (2.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.6.4-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.1)\n",
            "Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvloop-0.21.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-1.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Downloading chromadb-1.0.20-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.8 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m19.8/19.8 MB\u001b[0m \u001b[31m185.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading posthog-5.4.0-py3-none-any.whl (105 kB)\n",
            "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl (284 kB)\n",
            "Downloading kubernetes-33.1.0-py2.py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m99.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
            "Downloading mmh3-5.2.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (103 kB)\n",
            "Downloading onnxruntime-1.22.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.5 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m182.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.36.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.36.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.36.0-py3-none-any.whl (72 kB)\n",
            "Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading pybase64-1.4.2-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (71 kB)\n",
            "Downloading httptools-0.6.4-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (510 kB)\n",
            "Downloading uvloop-0.21.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m138.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (452 kB)\n",
            "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "Building wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53803 sha256=8aa930ddbc500908edf3b45123b64aaa11a18655388eae82a613458b1ea9db10\n",
            "  Stored in directory: /root/.cache/pip/wheels/d5/3d/69/8d68d249cd3de2584f226e27fd431d6344f7d70fd856ebd01b\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, durationpy, uvloop, pybase64, overrides, opentelemetry-proto, mmh3, humanfriendly, httptools, bcrypt, backoff, watchfiles, posthog, opentelemetry-exporter-otlp-proto-common, coloredlogs, onnxruntime, kubernetes, opentelemetry-exporter-otlp-proto-grpc, chromadb\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m19/19\u001b[0m [chromadb]\n",
            "\u001b[1A\u001b[2KSuccessfully installed backoff-2.2.1 bcrypt-4.3.0 chromadb-1.0.20 coloredlogs-15.0.1 durationpy-0.10 httptools-0.6.4 humanfriendly-10.0 kubernetes-33.1.0 mmh3-5.2.0 onnxruntime-1.22.1 opentelemetry-exporter-otlp-proto-common-1.36.0 opentelemetry-exporter-otlp-proto-grpc-1.36.0 opentelemetry-proto-1.36.0 overrides-7.7.0 posthog-5.4.0 pybase64-1.4.2 pypika-0.48.9 uvloop-0.21.0 watchfiles-1.1.0\n",
            "Newspaper3k failed: Article `download()` failed with 404 Client Error: Not Found for url: https://www.thedailystar.net/news/bangladesh/politics/news/pm-meets-opposition-leaders-3472166 on URL https://www.thedailystar.net/news/bangladesh/politics/news/pm-meets-opposition-leaders-3472166, trying manual scrape...\n",
            "Article added to vector store successfully\n",
            "Retrieved 1 relevant documents\n",
            "Azure API Error: Error code: 500 - {'error': {'code': 'Internal Server Error', 'message': 'An error occurred during the request processing: All connection attempts failed | Type: ConnectError | Traceback (most recent call last):||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/httpx/_transports/default.py\", line 66, in map_httpcore_exceptions||    yield||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/httpx/_transports/default.py\", line 366, in handle_async_request||    resp = await self._pool.handle_async_request(req)||           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/httpcore/_async/connection_pool.py\", line 256, in handle_async_request||    raise exc from None||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/httpcore/_async/connection_pool.py\", line 236, in handle_async_request||    response = await connection.handle_async_request(||               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/httpcore/_async/connection.py\", line 101, in handle_async_request||    raise exc||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/httpcore/_async/connection.py\", line 78, in handle_async_request||    stream = await self._connect(request)||             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/httpcore/_async/connection.py\", line 124, in _connect||    stream = await self._network_backend.connect_tcp(**kwargs)||             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/httpcore/_backends/auto.py\", line 31, in connect_tcp||    return await self._backend.connect_tcp(||           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/httpcore/_backends/anyio.py\", line 113, in connect_tcp||    with map_exceptions(exc_map):||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/contextlib.py\", line 158, in __exit__||    self.gen.throw(typ, value, traceback)||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions||    raise to_exc(exc) from exc||httpcore.ConnectError: All connection attempts failed||||The above exception was the direct cause of the following exception:||||Traceback (most recent call last):||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/starlette/middleware/errors.py\", line 164, in __call__||    await self.app(scope, receive, _send)||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/billingproxy/main.py\", line 452, in __call__||    return await handler_task||           ^^^^^^^^^^^^^^^^^^||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/starlette/middleware/base.py\", line 189, in __call__||    with collapse_excgroups():||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/contextlib.py\", line 158, in __exit__||    self.gen.throw(typ, value, traceback)||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/starlette/_utils.py\", line 93, in collapse_excgroups||    raise exc||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/starlette/middleware/base.py\", line 191, in __call__||    response = await self.dispatch_func(request, call_next)||               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/billingproxy/main.py\", line 418, in dispatch||    response = await call_next(request)||               ^^^^^^^^^^^^^^^^^^^^^^^^||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/starlette/middleware/base.py\", line 165, in call_next||    raise app_exc||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/starlette/middleware/base.py\", line 151, in coro||    await self.app(scope, receive_or_disconnect, send_no_error)||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/starlette/middleware/base.py\", line 189, in __call__||    with collapse_excgroups():||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/contextlib.py\", line 158, in __exit__||    self.gen.throw(typ, value, traceback)||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/starlette/_utils.py\", line 93, in collapse_excgroups||    raise exc||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/starlette/middleware/base.py\", line 191, in __call__||    response = await self.dispatch_func(request, call_next)||               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/billingproxy/main.py\", line 394, in dispatch||    response = await call_next(request)||               ^^^^^^^^^^^^^^^^^^^^^^^^||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/starlette/middleware/base.py\", line 165, in call_next||    raise app_exc||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/starlette/middleware/base.py\", line 151, in coro||    await self.app(scope, receive_or_disconnect, send_no_error)||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/starlette/middleware/cors.py\", line 85, in __call__||    await self.app(scope, receive, send)||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/starlette/middleware/exceptions.py\", line 65, in __call__||    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 64, in wrapped_app||    raise exc||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app||    await app(scope, receive, sender)||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/starlette/routing.py\", line 756, in __call__||    await self.middleware_stack(scope, receive, send)||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/starlette/routing.py\", line 776, in app||    await route.handle(scope, receive, send)||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/starlette/routing.py\", line 297, in handle||    await self.app(scope, receive, send)||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/starlette/routing.py\", line 77, in app||    await wrap_app_handling_exceptions(app, request)(scope, receive, send)||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 64, in wrapped_app||    raise exc||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app||    await app(scope, receive, sender)||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/starlette/routing.py\", line 72, in app||    response = await func(request)||               ^^^^^^^^^^^^^^^^^^^||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/fastapi/routing.py\", line 278, in app||    raw_response = await run_endpoint_function(||                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/fastapi/routing.py\", line 191, in run_endpoint_function||    return await dependant.call(**values)||           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/billingproxy/apis/vllm/chat.py\", line 372, in chat||    response = await downstream_client_getter().send(downstream_request)||               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/httpx/_client.py\", line 1617, in send||    response = await self._send_handling_auth(||               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/httpx/_client.py\", line 1645, in _send_handling_auth||    response = await self._send_handling_redirects(||               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/httpx/_client.py\", line 1682, in _send_handling_redirects||    response = await self._send_single_request(request)||               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/httpx/_client.py\", line 1719, in _send_single_request||    response = await transport.handle_async_request(request)||               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/httpx/_transports/default.py\", line 365, in handle_async_request||    with map_httpcore_exceptions():||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/contextlib.py\", line 158, in __exit__||    self.gen.throw(typ, value, traceback)||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/httpx/_transports/default.py\", line 83, in map_httpcore_exceptions||    raise mapped_exc(message) from exc||httpx.ConnectError: All connection attempts failed||', 'status': 500}}\n",
            "\n",
            "Mock response (for demo purposes):\n",
            "\n",
            "Based on the provided sources, I cannot confirm that Sheikh Hasina addressed the nation today.\n",
            "\n",
            "The available information indicates that Prime Minister Sheikh Hasina met with opposition leaders to discuss national issues and political reconciliation. There is no mention of a national address in the provided sources.\n",
            "\n",
            "Source: The Daily Star article about PM meeting opposition leaders.\n",
            "\n",
            "For the most current information about national addresses, please check official government channels or recent news updates.\n",
            "\n",
            "\n",
            "To improve results, you can add more news articles:\n",
            "- https://www.thedailystar.net/news/bangladesh\n",
            "- https://www.prothomalo.com\n",
            "- https://bdnews24.com\n"
          ]
        }
      ],
      "source": [
        "# Step : Install deps\n",
        "!pip install openai chromadb newspaper3k sentence-transformers lxml_html_clean\n",
        "\n",
        "# Step 2: Init Azure client\n",
        "from openai import AzureOpenAI\n",
        "import os\n",
        "\n",
        "# Set your Azure credentials (better to use environment variables)\n",
        "os.environ[\"AZURE_OPENAI_API_KEY\"] = \"\"\n",
        "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"\"\n",
        "\n",
        "client = AzureOpenAI(\n",
        "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
        "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
        "    api_version=\"2024-05-01-preview\"\n",
        ")\n",
        "\n",
        "# Step 3: Scrape latest news\n",
        "from newspaper import Article\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def scrape_article(url):\n",
        "    \"\"\"Robust article scraping with fallback\"\"\"\n",
        "    try:\n",
        "        article = Article(url)\n",
        "        article.download()\n",
        "        article.parse()\n",
        "        return article.text\n",
        "    except Exception as e:\n",
        "        print(f\"Newspaper3k failed: {e}, trying manual scrape...\")\n",
        "        try:\n",
        "            headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}\n",
        "            response = requests.get(url, headers=headers, timeout=10)\n",
        "            soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "            # Try to extract main content\n",
        "            for tag in ['article', 'main', '.content', '.article-body']:\n",
        "                elements = soup.select(tag)\n",
        "                if elements:\n",
        "                    return ' '.join([elem.get_text().strip() for elem in elements])\n",
        "\n",
        "            # Fallback: get all paragraphs\n",
        "            paragraphs = soup.find_all('p')\n",
        "            return ' '.join([p.get_text().strip() for p in paragraphs])\n",
        "        except Exception as e2:\n",
        "            print(f\"Manual scrape also failed: {e2}\")\n",
        "            return None\n",
        "\n",
        "url = \"https://www.thedailystar.net/news/bangladesh/politics/news/pm-meets-opposition-leaders-3472166\"\n",
        "doc_text = scrape_article(url)\n",
        "\n",
        "if not doc_text:\n",
        "    # Fallback example text\n",
        "    doc_text = \"Prime Minister Sheikh Hasina met with opposition leaders today to discuss national issues. The meeting focused on political reconciliation and upcoming elections.\"\n",
        "\n",
        "# Step 4: Embed into vector store\n",
        "import chromadb\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from chromadb.api.types import Documents, EmbeddingFunction, Embeddings # Import necessary types\n",
        "\n",
        "# Initialize embedding model\n",
        "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# Create a wrapper class for the embedding function\n",
        "class SentenceTransformerEmbeddingFunction(EmbeddingFunction):\n",
        "    def __init__(self, model):\n",
        "        self._model = model\n",
        "\n",
        "    def __call__(self, input: Documents) -> Embeddings:\n",
        "        # Encode to numpy array first, then convert to list\n",
        "        embeddings = self._model.encode(list(input), convert_to_numpy=True)\n",
        "        return embeddings.tolist() # Convert numpy array to list\n",
        "\n",
        "\n",
        "# Create Chroma client\n",
        "chroma_client = chromadb.Client()\n",
        "# Use the wrapper class as the embedding function\n",
        "collection = chroma_client.get_or_create_collection(\"news\", embedding_function=SentenceTransformerEmbeddingFunction(embedder)) # Changed from create_collection\n",
        "\n",
        "# Add article with embedding\n",
        "collection.add(\n",
        "    documents=[doc_text],\n",
        "    metadatas=[{\"source\": url, \"type\": \"news_article\"}],\n",
        "    ids=[\"doc1\"]\n",
        ")\n",
        "\n",
        "print(\"Article added to vector store successfully\")\n",
        "\n",
        "# Step 5: User query\n",
        "query = \"Did Sheikh Hasina address the nation today?\"\n",
        "\n",
        "# Embed + retrieve\n",
        "results = collection.query(\n",
        "    query_texts=[query],\n",
        "    n_results=3,\n",
        "    include=[\"documents\", \"metadatas\", \"distances\"]\n",
        ")\n",
        "\n",
        "retrieved_docs = \"\\n\\n---\\n\".join([doc for doc in results['documents'][0]])\n",
        "\n",
        "print(f\"Retrieved {len(results['documents'][0])} relevant documents\")\n",
        "\n",
        "# Step 6: Ask Azure LLM with retrieved context\n",
        "try:\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"Phi-4-mini-reasoning-2\",  # your deployment name\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"You are a factual fact-checking assistant for Bangladesh news. Always cite sources and be precise. If the information isn't in the provided sources, say you don't have enough information.\"\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": f\"Based on the following sources, please fact-check this claim:\\n\\nCLAIM: {query}\\n\\nSOURCES:\\n{retrieved_docs}\\n\\nPlease provide a clear answer with citations from the sources.\"\n",
        "            }\n",
        "        ],\n",
        "        temperature=0.1,\n",
        "        max_tokens=500\n",
        "    )\n",
        "\n",
        "    answer = response.choices[0].message.content\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"ü§ñ AI FACT-CHECK RESULT:\")\n",
        "    print(\"=\"*60)\n",
        "    print(answer)\n",
        "    print(\"=\"*60)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Azure API Error: {e}\")\n",
        "    print(\"\\nMock response (for demo purposes):\")\n",
        "    mock_response = \"\"\"\n",
        "Based on the provided sources, I cannot confirm that Sheikh Hasina addressed the nation today.\n",
        "\n",
        "The available information indicates that Prime Minister Sheikh Hasina met with opposition leaders to discuss national issues and political reconciliation. There is no mention of a national address in the provided sources.\n",
        "\n",
        "Source: The Daily Star article about PM meeting opposition leaders.\n",
        "\n",
        "For the most current information about national addresses, please check official government channels or recent news updates.\n",
        "\"\"\"\n",
        "    print(mock_response)\n",
        "\n",
        "# Additional: Add more documents for better retrieval\n",
        "additional_urls = [\n",
        "    \"https://www.thedailystar.net/news/bangladesh\",\n",
        "    \"https://www.prothomalo.com\",\n",
        "    \"https://bdnews24.com\"\n",
        "]\n",
        "\n",
        "print(\"\\nTo improve results, you can add more news articles:\")\n",
        "for add_url in additional_urls:\n",
        "    print(f\"- {add_url}\")\n",
        "\n",
        "# Utility function to add more articles\n",
        "def add_news_article(url, collection):\n",
        "    \"\"\"Add a news article to the vector database\"\"\"\n",
        "    text = scrape_article(url)\n",
        "    if text and len(text) > 100:  # Minimum length check\n",
        "        doc_id = f\"doc_{len(collection.get()['ids']) + 1}\"\n",
        "        collection.add(\n",
        "            documents=[text],\n",
        "            metadatas=[{\"source\": url, \"type\": \"news_article\"}],\n",
        "            ids=[doc_id]\n",
        "        )\n",
        "        print(f\"‚úì Added: {url}\")\n",
        "        return True\n",
        "    return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-4OM5xSpztm",
        "outputId": "bf1a28fa-f6f7-4b40-efc0-b226a91dffd4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== üìä Baseline Evaluation on ISOT Dataset ===\n",
            "Loaded X_test embeddings from /content/fake-news-rag/data/processed/X_test_emb.npy\n",
            "‚ö†Ô∏è No classifier evaluation possible: X has 384 features, but LGBMClassifier is expecting 100 features as input.\n",
            "\n",
            "=== üåê Real-Time Evaluation on Live News ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using fallback example articles...\n",
            "Fetched 2 live articles for evaluation\n",
            "\n",
            "--- Article 1: Bangladesh Government Announces New Economic Policy ---\n",
            "‚ö†Ô∏è Classifier prediction failed: X has 384 features, but LGBMClassifier is expecting 100 features as input.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Azure API error: Error code: 500 - {'error': {'code': 'Internal Server Error', 'message': 'An error occurred during the request processing: All connection attempts failed | Type: ConnectError | Traceback (most recent call last):||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/httpx/_transports/default.py\", line 66, in map_httpcore_exceptions||    yield||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/httpx/_transports/default.py\", line 366, in handle_async_request||    resp = await self._pool.handle_async_request(req)||           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/httpcore/_async/connection_pool.py\", line 256, in handle_async_request||    raise exc from None||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/httpcore/_async/connection_pool.py\", line 236, in handle_async_request||    response = await connection.handle_async_request(||               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/httpcore/_async/connection.py\", line 101, in handle_async_request||    raise exc||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/httpcore/_async/connection.py\", line 78, in handle_async_request||    stream = await self._connect(request)||             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/httpcore/_async/connection.py\", line 124, in _connect||    stream = await self._network_backend.connect_tcp(**kwargs)||             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/httpcore/_backends/auto.py\", line 31, in connect_tcp||    return await self._backend.connect_tcp(||           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/httpcore/_backends/anyio.py\", line 113, in connect_tcp||    with map_exceptions(exc_map):||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/contextlib.py\", line 158, in __exit__||    self.gen.throw(typ, value, traceback)||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions||    raise to_exc(exc) from exc||httpcore.ConnectError: All connection attempts failed||||The above exception was the direct cause of the following exception:||||Traceback (most recent call last):||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/starlette/middleware/errors.py\", line 164, in __call__||    await self.app(scope, receive, _send)||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/billingproxy/main.py\", line 452, in __call__||    return await handler_task||           ^^^^^^^^^^^^^^^^^^||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/starlette/middleware/base.py\", line 189, in __call__||    with collapse_excgroups():||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/contextlib.py\", line 158, in __exit__||    self.gen.throw(typ, value, traceback)||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/starlette/_utils.py\", line 93, in collapse_excgroups||    raise exc||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/starlette/middleware/base.py\", line 191, in __call__||    response = await self.dispatch_func(request, call_next)||               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/billingproxy/main.py\", line 418, in dispatch||    response = await call_next(request)||               ^^^^^^^^^^^^^^^^^^^^^^^^||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/starlette/middleware/base.py\", line 165, in call_next||    raise app_exc||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/starlette/middleware/base.py\", line 151, in coro||    await self.app(scope, receive_or_disconnect, send_no_error)||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/starlette/middleware/base.py\", line 189, in __call__||    with collapse_excgroups():||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/contextlib.py\", line 158, in __exit__||    self.gen.throw(typ, value, traceback)||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/starlette/_utils.py\", line 93, in collapse_excgroups||    raise exc||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/starlette/middleware/base.py\", line 191, in __call__||    response = await self.dispatch_func(request, call_next)||               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/billingproxy/main.py\", line 394, in dispatch||    response = await call_next(request)||               ^^^^^^^^^^^^^^^^^^^^^^^^||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/starlette/middleware/base.py\", line 165, in call_next||    raise app_exc||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/starlette/middleware/base.py\", line 151, in coro||    await self.app(scope, receive_or_disconnect, send_no_error)||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/starlette/middleware/cors.py\", line 85, in __call__||    await self.app(scope, receive, send)||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/starlette/middleware/exceptions.py\", line 65, in __call__||    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 64, in wrapped_app||    raise exc||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app||    await app(scope, receive, sender)||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/starlette/routing.py\", line 756, in __call__||    await self.middleware_stack(scope, receive, send)||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/starlette/routing.py\", line 776, in app||    await route.handle(scope, receive, send)||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/starlette/routing.py\", line 297, in handle||    await self.app(scope, receive, send)||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/starlette/routing.py\", line 77, in app||    await wrap_app_handling_exceptions(app, request)(scope, receive, send)||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 64, in wrapped_app||    raise exc||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app||    await app(scope, receive, sender)||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/starlette/routing.py\", line 72, in app||    response = await func(request)||               ^^^^^^^^^^^^^^^^^^^||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/fastapi/routing.py\", line 278, in app||    raw_response = await run_endpoint_function(||                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/fastapi/routing.py\", line 191, in run_endpoint_function||    return await dependant.call(**values)||           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/billingproxy/apis/vllm/chat.py\", line 372, in chat||    response = await downstream_client_getter().send(downstream_request)||               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/httpx/_client.py\", line 1617, in send||    response = await self._send_handling_auth(||               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/httpx/_client.py\", line 1645, in _send_handling_auth||    response = await self._send_handling_redirects(||               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/httpx/_client.py\", line 1682, in _send_handling_redirects||    response = await self._send_single_request(request)||               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/httpx/_client.py\", line 1719, in _send_single_request||    response = await transport.handle_async_request(request)||               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/httpx/_transports/default.py\", line 365, in handle_async_request||    with map_httpcore_exceptions():||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/contextlib.py\", line 158, in __exit__||    self.gen.throw(typ, value, traceback)||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/httpx/_transports/default.py\", line 83, in map_httpcore_exceptions||    raise mapped_exc(message) from exc||httpx.ConnectError: All connection attempts failed||', 'status': 500}}\n",
            "Prediction: Unknown\n",
            "Reason: No classifier or LLM decision available.\n",
            "‚è± Latency: 15.29s\n",
            "Top retrieved: New austerity measures amid low revenue receipts (score=0.553)\n",
            "\n",
            "--- Article 2: Dhaka Metro Rail Expansion Project Approved ---\n",
            "‚ö†Ô∏è Classifier prediction failed: X has 384 features, but LGBMClassifier is expecting 100 features as input.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Azure API error: Error code: 500 - {'error': {'code': 'Internal Server Error', 'message': 'An error occurred during the request processing: All connection attempts failed | Type: ConnectError | Traceback (most recent call last):||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/httpx/_transports/default.py\", line 66, in map_httpcore_exceptions||    yield||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/httpx/_transports/default.py\", line 366, in handle_async_request||    resp = await self._pool.handle_async_request(req)||           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/httpcore/_async/connection_pool.py\", line 256, in handle_async_request||    raise exc from None||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/httpcore/_async/connection_pool.py\", line 236, in handle_async_request||    response = await connection.handle_async_request(||               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/httpcore/_async/connection.py\", line 101, in handle_async_request||    raise exc||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/httpcore/_async/connection.py\", line 78, in handle_async_request||    stream = await self._connect(request)||             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/httpcore/_async/connection.py\", line 124, in _connect||    stream = await self._network_backend.connect_tcp(**kwargs)||             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/httpcore/_backends/auto.py\", line 31, in connect_tcp||    return await self._backend.connect_tcp(||           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/httpcore/_backends/anyio.py\", line 113, in connect_tcp||    with map_exceptions(exc_map):||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/contextlib.py\", line 158, in __exit__||    self.gen.throw(typ, value, traceback)||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions||    raise to_exc(exc) from exc||httpcore.ConnectError: All connection attempts failed||||The above exception was the direct cause of the following exception:||||Traceback (most recent call last):||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/starlette/middleware/errors.py\", line 164, in __call__||    await self.app(scope, receive, _send)||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/billingproxy/main.py\", line 452, in __call__||    return await handler_task||           ^^^^^^^^^^^^^^^^^^||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/starlette/middleware/base.py\", line 189, in __call__||    with collapse_excgroups():||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/contextlib.py\", line 158, in __exit__||    self.gen.throw(typ, value, traceback)||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/starlette/_utils.py\", line 93, in collapse_excgroups||    raise exc||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/starlette/middleware/base.py\", line 191, in __call__||    response = await self.dispatch_func(request, call_next)||               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/billingproxy/main.py\", line 418, in dispatch||    response = await call_next(request)||               ^^^^^^^^^^^^^^^^^^^^^^^^||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/starlette/middleware/base.py\", line 165, in call_next||    raise app_exc||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/starlette/middleware/base.py\", line 151, in coro||    await self.app(scope, receive_or_disconnect, send_no_error)||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/starlette/middleware/base.py\", line 189, in __call__||    with collapse_excgroups():||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/contextlib.py\", line 158, in __exit__||    self.gen.throw(typ, value, traceback)||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/starlette/_utils.py\", line 93, in collapse_excgroups||    raise exc||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/starlette/middleware/base.py\", line 191, in __call__||    response = await self.dispatch_func(request, call_next)||               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/billingproxy/main.py\", line 394, in dispatch||    response = await call_next(request)||               ^^^^^^^^^^^^^^^^^^^^^^^^||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/starlette/middleware/base.py\", line 165, in call_next||    raise app_exc||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/starlette/middleware/base.py\", line 151, in coro||    await self.app(scope, receive_or_disconnect, send_no_error)||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/starlette/middleware/cors.py\", line 85, in __call__||    await self.app(scope, receive, send)||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/starlette/middleware/exceptions.py\", line 65, in __call__||    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 64, in wrapped_app||    raise exc||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app||    await app(scope, receive, sender)||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/starlette/routing.py\", line 756, in __call__||    await self.middleware_stack(scope, receive, send)||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/starlette/routing.py\", line 776, in app||    await route.handle(scope, receive, send)||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/starlette/routing.py\", line 297, in handle||    await self.app(scope, receive, send)||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/starlette/routing.py\", line 77, in app||    await wrap_app_handling_exceptions(app, request)(scope, receive, send)||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 64, in wrapped_app||    raise exc||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app||    await app(scope, receive, sender)||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/starlette/routing.py\", line 72, in app||    response = await func(request)||               ^^^^^^^^^^^^^^^^^^^||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/fastapi/routing.py\", line 278, in app||    raw_response = await run_endpoint_function(||                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/fastapi/routing.py\", line 191, in run_endpoint_function||    return await dependant.call(**values)||           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/billingproxy/apis/vllm/chat.py\", line 372, in chat||    response = await downstream_client_getter().send(downstream_request)||               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/httpx/_client.py\", line 1617, in send||    response = await self._send_handling_auth(||               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/httpx/_client.py\", line 1645, in _send_handling_auth||    response = await self._send_handling_redirects(||               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/httpx/_client.py\", line 1682, in _send_handling_redirects||    response = await self._send_single_request(request)||               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/httpx/_client.py\", line 1719, in _send_single_request||    response = await transport.handle_async_request(request)||               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/httpx/_transports/default.py\", line 365, in handle_async_request||    with map_httpcore_exceptions():||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/contextlib.py\", line 158, in __exit__||    self.gen.throw(typ, value, traceback)||  File \"/opt/microsoft-maas/billingproxy/lib/python3.11/site-packages/httpx/_transports/default.py\", line 83, in map_httpcore_exceptions||    raise mapped_exc(message) from exc||httpx.ConnectError: All connection attempts failed||', 'status': 500}}\n",
            "Prediction: Unknown\n",
            "Reason: No classifier or LLM decision available.\n",
            "‚è± Latency: 3.42s\n",
            "Top retrieved: ‚ÄòDhaka Tower‚Äô lies abandoned for 8 years (score=0.528)\n",
            "\n",
            "=== üì∞ Daily Star Evaluation (Unlabeled Predictions) ===\n",
            "Loaded 2573 Daily Star articles from: /content/fake-news-rag/data/raw/dailystar_news.csv\n",
            "‚ö†Ô∏è Daily Star CSV missing 'title' or 'text' columns. Skipping.\n",
            "\n",
            "=== üîç Retrieval Quality Check ===\n",
            "\n",
            "Query: 'Bangladesh elections'\n",
            "  1. Source: dailystar | Score: 0.686 | Snippet: Avijit murder convict Farabi freed on bail Body of missing journalist Bibhuranjan Sarker recovered f...\n",
            "  2. Source: dailystar | Score: 0.667 | Snippet: Avijit murder convict Farabi freed on bail Body of missing journalist Bibhuranjan Sarker recovered f...\n",
            "\n",
            "Query: 'Dhaka metro rail project'\n",
            "  1. Source: dailystar | Score: 0.624 | Snippet: Avijit murder convict Farabi freed on bail Body of missing journalist Bibhuranjan Sarker recovered f...\n",
            "  2. Source: dailystar | Score: 0.603 | Snippet: Avijit murder convict Farabi freed on bail Body of missing journalist Bibhuranjan Sarker recovered f...\n",
            "\n",
            "Query: 'global oil prices'\n",
            "  1. Source: isot | Score: 0.595 | Snippet: President Obama just announced another major shakeup in the last year of his presidency, and the oil...\n",
            "  2. Source: isot | Score: 0.584 | Snippet: For some time now, the United States has been experiencing a rapid decline in gas prices. It s almos...\n",
            "\n",
            "Query: 'COVID treatment'\n",
            "  1. Source: dailystar | Score: 0.492 | Snippet: Avijit murder convict Farabi freed on bail Body of missing journalist Bibhuranjan Sarker recovered f...\n",
            "  2. Source: dailystar | Score: 0.488 | Snippet: Avijit murder convict Farabi freed on bail Body of missing journalist Bibhuranjan Sarker recovered f...\n",
            "\n",
            "‚úÖ Evaluation results saved to: /content/fake-news-rag/data/processed/evaluation_results.json\n",
            "\n",
            "=== üìà Evaluation Summary ===\n",
            "ISOT Classifier Performance: {'accuracy': None, 'precision': None, 'recall': None, 'f1_score': None}\n",
            "Live Articles Processed: 2\n",
            "Daily Star Preds: 0 (Real=0, Fake=0)\n",
            "Retrieval Queries Tested: 4 (with results: 4)\n"
          ]
        }
      ],
      "source": [
        "# ===== 8) EVALUATION (ISOT + Live + DailyStar) =====\n",
        "from pathlib import Path\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_recall_fscore_support,\n",
        "    confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
        ")\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json, time, random\n",
        "import os\n",
        "\n",
        "# Optional (used in Mode 2)\n",
        "try:\n",
        "    from newspaper import Article\n",
        "except Exception:\n",
        "    Article = None\n",
        "\n",
        "# --- Directories (keep in sync with earlier steps) ---\n",
        "BASE_DIR = Path(\"/content/fake-news-rag\")\n",
        "PROC_DIR = BASE_DIR / \"data\" / \"processed\"\n",
        "RAW_DIR  = BASE_DIR / \"data\" / \"raw\"\n",
        "PROC_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# --- Helpers ---\n",
        "def safe_load_numpy(path: Path, allow_missing=False):\n",
        "    \"\"\"Load a numpy file safely; return None if missing and allow_missing=True.\"\"\"\n",
        "    try:\n",
        "        return np.load(path)\n",
        "    except FileNotFoundError:\n",
        "        if not allow_missing:\n",
        "            print(f\"‚ö†Ô∏è Missing file: {path}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Could not load {path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def ensure_embedder_available():\n",
        "    if 'embedder' not in globals():\n",
        "        raise RuntimeError(\"Embedder not found in globals. Run the embeddings step first.\")\n",
        "    return True\n",
        "\n",
        "def ensure_classifier_available():\n",
        "    if 'clf' not in globals():\n",
        "        raise RuntimeError(\"Classifier 'clf' not found in globals. Train or load it first.\")\n",
        "    return True\n",
        "\n",
        "def pretty_confusion_matrix(y_true, y_pred, title=\"Confusion Matrix\"):\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=[0,1])\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Fake(0)\",\"Real(1)\"])\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    disp.plot(cmap='Blues', values_format='d')\n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "\n",
        "def compute_basic_metrics(y_true, y_pred):\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    prec, rec, f1, _ = precision_recall_fscore_support(\n",
        "        y_true, y_pred, average=\"binary\", pos_label=1, zero_division=0\n",
        "    )\n",
        "    return acc, prec, rec, f1\n",
        "\n",
        "# ====================================================\n",
        "# MODE 1: ISOT BASELINE (Classifier on held-out ISOT)\n",
        "# ====================================================\n",
        "print(\"\\n=== üìä Baseline Evaluation on ISOT Dataset ===\")\n",
        "\n",
        "isot_metrics = {\n",
        "    \"accuracy\": None,\n",
        "    \"precision\": None,\n",
        "    \"recall\": None,\n",
        "    \"f1_score\": None\n",
        "}\n",
        "\n",
        "try:\n",
        "    ensure_classifier_available()\n",
        "\n",
        "    # Try multiple filenames for X_test embeddings (support both older and improved training steps)\n",
        "    X_TEST_CANDIDATES = [PROC_DIR / \"X_test_emb.npy\", PROC_DIR / \"X_test.npy\"]\n",
        "    X_test_emb = None\n",
        "    for cand in X_TEST_CANDIDATES:\n",
        "        X_test_emb = safe_load_numpy(cand, allow_missing=True)\n",
        "        if X_test_emb is not None:\n",
        "            print(f\"Loaded X_test embeddings from {cand}\")\n",
        "            break\n",
        "\n",
        "    # Fallback: if not found on disk, check if X_test is in globals\n",
        "    if X_test_emb is None and 'X_test' in globals():\n",
        "        # If shaped like embeddings, use directly; otherwise try to embed (requires embedder)\n",
        "        if isinstance(X_test, np.ndarray) and X_test.ndim == 2:\n",
        "            X_test_emb = X_test\n",
        "            print(\"Using in-memory X_test embeddings from globals()\")\n",
        "        else:\n",
        "            # Treat as documents ‚áí embed them\n",
        "            ensure_embedder_available()\n",
        "            if isinstance(X_test, (list, tuple)):\n",
        "                docs = [str(x) for x in X_test if isinstance(x, (str, bytes))]\n",
        "            else:\n",
        "                # As a last resort, convert to list of strings\n",
        "                docs = [str(X_test)]\n",
        "            if len(docs) > 0:\n",
        "                print(\"Embedding X_test documents from memory...\")\n",
        "                X_test_emb = embedder.encode(docs, show_progress_bar=True, convert_to_numpy=True)\n",
        "            else:\n",
        "                X_test_emb = None\n",
        "\n",
        "    # y_test (labels)\n",
        "    y_test = safe_load_numpy(PROC_DIR / \"y_test.npy\", allow_missing=True)\n",
        "    if y_test is None and 'y_test' in globals():\n",
        "        y_test = y_test  # use in-memory\n",
        "        print(\"Using in-memory y_test from globals()\")\n",
        "\n",
        "    if X_test_emb is None or y_test is None or len(X_test_emb) == 0 or len(y_test) == 0:\n",
        "        print(\"‚ö†Ô∏è Skipping ISOT evaluation - test embeddings or labels missing/empty.\")\n",
        "    else:\n",
        "        if len(X_test_emb) != len(y_test):\n",
        "            n = min(len(X_test_emb), len(y_test))\n",
        "            print(f\"‚ö†Ô∏è Length mismatch: truncating to {n} samples for evaluation.\")\n",
        "            X_test_emb = X_test_emb[:n]\n",
        "            y_test = y_test[:n]\n",
        "\n",
        "        y_pred = clf.predict(X_test_emb)\n",
        "        acc, prec, rec, f1 = compute_basic_metrics(y_test, y_pred)\n",
        "\n",
        "        print(f\"[Embedding Classifier] Acc={acc:.4f}  P={prec:.4f}  R={rec:.4f}  F1={f1:.4f}\")\n",
        "        print(\"\\nDetailed Classification Report:\")\n",
        "        print(classification_report(y_test, y_pred, target_names=[\"Fake\", \"Real\"], digits=4))\n",
        "        pretty_confusion_matrix(y_test, y_pred, title=\"Confusion Matrix - Embedding Classifier (ISOT)\")\n",
        "\n",
        "        isot_metrics = {\n",
        "            \"accuracy\": float(acc),\n",
        "            \"precision\": float(prec),\n",
        "            \"recall\": float(rec),\n",
        "            \"f1_score\": float(f1)\n",
        "        }\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è No classifier evaluation possible: {e}\")\n",
        "\n",
        "# ====================================================\n",
        "# MODE 2: LIVE NEWS EVALUATION (RAG pipeline)\n",
        "# ====================================================\n",
        "print(\"\\n=== üåê Real-Time Evaluation on Live News ===\")\n",
        "\n",
        "def fetch_live_news(limit=5):\n",
        "    \"\"\"Fetch a few recent news articles for evaluation (using requests + BeautifulSoup + newspaper3k).\"\"\"\n",
        "    try:\n",
        "        import requests\n",
        "        from bs4 import BeautifulSoup\n",
        "        # We‚Äôll be polite but robust\n",
        "        headers = {\n",
        "            'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 '\n",
        "                          '(KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36'\n",
        "        }\n",
        "\n",
        "        news_sources = [\n",
        "            \"https://www.thedailystar.net/top-news\",\n",
        "            \"https://www.dhakatribune.com/articles/news/\",\n",
        "            \"https://bdnews24.com/latest-news\"\n",
        "        ]\n",
        "\n",
        "        articles = []\n",
        "        for source_url in news_sources:\n",
        "            try:\n",
        "                resp = requests.get(source_url, headers=headers, timeout=10)\n",
        "                if resp.status_code != 200:\n",
        "                    continue\n",
        "                soup = BeautifulSoup(resp.text, 'html.parser')\n",
        "\n",
        "                # Collect links that look like article pages\n",
        "                links = []\n",
        "                for a in soup.find_all('a', href=True):\n",
        "                    href = a['href']\n",
        "                    if any(tok in href for tok in ['/article/', '/news/']):\n",
        "                        if href.startswith('/'):\n",
        "                            # Normalize relative links\n",
        "                            base = source_url.split('/articles')[0].rstrip('/')\n",
        "                            href = f\"{base}{href}\"\n",
        "                        links.append(href)\n",
        "\n",
        "                # Deduplicate while preserving order\n",
        "                seen = set()\n",
        "                unique_links = []\n",
        "                for l in links:\n",
        "                    if l not in seen:\n",
        "                        seen.add(l)\n",
        "                        unique_links.append(l)\n",
        "\n",
        "                # Parse a few with newspaper3k if available\n",
        "                use_links = unique_links[: max(2, limit // len(news_sources) + 1)]\n",
        "                for link in use_links:\n",
        "                    try:\n",
        "                        art = Article(link)\n",
        "                        art.download()\n",
        "                        art.parse()\n",
        "                        if art.title and art.text:\n",
        "                            articles.append({\n",
        "                                \"title\": art.title,\n",
        "                                \"text\": art.text,\n",
        "                                \"url\": link\n",
        "                            })\n",
        "                            if len(articles) >= limit:\n",
        "                                break\n",
        "                    except Exception:\n",
        "                        continue\n",
        "\n",
        "                if len(articles) >= limit:\n",
        "                    break\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Failed to fetch from {source_url}: {e}\")\n",
        "                continue\n",
        "\n",
        "        if len(articles) == 0:\n",
        "            print(\"Using fallback example articles...\")\n",
        "            articles = [\n",
        "                {\n",
        "                    \"title\": \"Bangladesh Government Announces New Economic Policy\",\n",
        "                    \"text\": \"The government has introduced new economic measures to boost growth and stabilize markets. The policy focuses on inflation control and export promotion.\",\n",
        "                    \"url\": \"https://example.com/economic-policy\"\n",
        "                },\n",
        "                {\n",
        "                    \"title\": \"Dhaka Metro Rail Expansion Project Approved\",\n",
        "                    \"text\": \"The metro rail expansion project has received final approval with funding from international development partners. Construction will begin next month.\",\n",
        "                    \"url\": \"https://example.com/metro-expansion\"\n",
        "                }\n",
        "            ]\n",
        "        return articles\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error in fetch_live_news: {e}\")\n",
        "        return []\n",
        "\n",
        "live_articles = fetch_live_news(limit=3)\n",
        "live_eval = {\n",
        "    \"count\": 0,\n",
        "    \"items\": []\n",
        "}\n",
        "\n",
        "if live_articles and 'rag_infer' in globals():\n",
        "    print(f\"Fetched {len(live_articles)} live articles for evaluation\")\n",
        "    for i, art in enumerate(live_articles, 1):\n",
        "        print(f\"\\n--- Article {i}: {art['title'][:80]} ---\")\n",
        "        t0 = time.time()\n",
        "        try:\n",
        "            out = rag_infer(art[\"title\"], art[\"text\"], k=5, use_llm=True)\n",
        "            latency = time.time() - t0\n",
        "\n",
        "            label = out.get(\"final\", {}).get(\"label\", \"Unknown\")\n",
        "            conf = out.get(\"final\", {}).get(\"confidence\", None)\n",
        "            reason = out.get(\"final\", {}).get(\"reason\", \"\")\n",
        "\n",
        "            if conf is not None:\n",
        "                print(f\"Prediction: {label} | Confidence: {conf:.3f}\")\n",
        "            else:\n",
        "                print(f\"Prediction: {label}\")\n",
        "            print(f\"Reason: {reason}\")\n",
        "            print(f\"‚è± Latency: {latency:.2f}s\")\n",
        "\n",
        "            # Top retrieved\n",
        "            if out.get(\"retrieved\"):\n",
        "                top = out[\"retrieved\"][0]\n",
        "                score = top.get(\"score\", None)\n",
        "                ttitle = top.get(\"title\", \"\")[:80]\n",
        "                if score is not None:\n",
        "                    print(f\"Top retrieved: {ttitle} (score={score:.3f})\")\n",
        "                else:\n",
        "                    print(f\"Top retrieved: {ttitle}\")\n",
        "\n",
        "            live_eval[\"items\"].append({\n",
        "                \"title\": art[\"title\"],\n",
        "                \"url\": art.get(\"url\"),\n",
        "                \"prediction\": label,\n",
        "                \"confidence\": float(conf) if conf is not None else None,\n",
        "                \"latency_sec\": float(latency)\n",
        "            })\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error processing article: {e}\")\n",
        "            continue\n",
        "    live_eval[\"count\"] = len(live_eval[\"items\"])\n",
        "else:\n",
        "    if not live_articles:\n",
        "        print(\"‚ö†Ô∏è No live news could be fetched for evaluation.\")\n",
        "    elif 'rag_infer' not in globals():\n",
        "        print(\"‚ö†Ô∏è `rag_infer` not available. Skipping live RAG evaluation.\")\n",
        "\n",
        "# ====================================================\n",
        "# MODE 3: DAILY STAR (Unlabeled) ‚Äì Classifier-only pass\n",
        "# ====================================================\n",
        "print(\"\\n=== üì∞ Daily Star Evaluation (Unlabeled Predictions) ===\")\n",
        "\n",
        "dailystar_summary = {\n",
        "    \"count\": 0,\n",
        "    \"real\": 0,\n",
        "    \"fake\": 0,\n",
        "    \"output_path\": None\n",
        "}\n",
        "\n",
        "try:\n",
        "    ensure_classifier_available()\n",
        "    ensure_embedder_available()\n",
        "\n",
        "    # Try RAW first; if not found, try PROCESSED (depending on where you saved it earlier)\n",
        "    DAILYSTAR_CSV_CANDIDATES = [\n",
        "        RAW_DIR / \"dailystar_news.csv\",\n",
        "        PROC_DIR / \"dailystar_news.csv\",\n",
        "        PROC_DIR / \"dailystar_clean.csv\"\n",
        "    ]\n",
        "\n",
        "    DAILYSTAR_PATH = None\n",
        "    for c in DAILYSTAR_CSV_CANDIDATES:\n",
        "        if c.exists():\n",
        "            DAILYSTAR_PATH = c\n",
        "            break\n",
        "\n",
        "    if DAILYSTAR_PATH is None:\n",
        "        print(\"‚ö†Ô∏è Daily Star dataset not found in expected locations. Skipping.\")\n",
        "    else:\n",
        "        ds_df = pd.read_csv(DAILYSTAR_PATH)\n",
        "        print(f\"Loaded {len(ds_df)} Daily Star articles from: {DAILYSTAR_PATH}\")\n",
        "\n",
        "        # Ensure columns exist\n",
        "        if not {\"title\", \"text\"}.issubset(set(ds_df.columns)):\n",
        "            print(\"‚ö†Ô∏è Daily Star CSV missing 'title' or 'text' columns. Skipping.\")\n",
        "        else:\n",
        "            docs = [f\"{str(t)}. {str(x)}\" for t, x in zip(ds_df[\"title\"], ds_df[\"text\"])]\n",
        "            ds_emb = embedder.encode(docs, convert_to_numpy=True, normalize_embeddings=True, show_progress_bar=True)\n",
        "\n",
        "            # Prefer predict_proba if available\n",
        "            has_proba = hasattr(clf, \"predict_proba\")\n",
        "            ds_preds = clf.predict(ds_emb)\n",
        "            ds_probs = clf.predict_proba(ds_emb) if has_proba else None\n",
        "\n",
        "            ds_df[\"prediction\"] = np.where(ds_preds == 1, \"Real\", \"Fake\")\n",
        "            if ds_probs is not None:\n",
        "                ds_df[\"confidence\"] = ds_probs.max(axis=1)\n",
        "            else:\n",
        "                ds_df[\"confidence\"] = None\n",
        "\n",
        "            # Simple distribution\n",
        "            counts = ds_df[\"prediction\"].value_counts().to_dict()\n",
        "            dailystar_summary[\"count\"] = int(len(ds_df))\n",
        "            dailystar_summary[\"real\"]  = int(counts.get(\"Real\", 0))\n",
        "            dailystar_summary[\"fake\"]  = int(counts.get(\"Fake\", 0))\n",
        "\n",
        "            # Save predictions\n",
        "            DS_OUT_PATH = PROC_DIR / \"dailystar_predictions.csv\"\n",
        "            ds_df.to_csv(DS_OUT_PATH, index=False)\n",
        "            dailystar_summary[\"output_path\"] = str(DS_OUT_PATH)\n",
        "            print(f\"‚úÖ Saved Daily Star predictions to: {DS_OUT_PATH}\")\n",
        "\n",
        "            # Show a few samples\n",
        "            print(\"\\nSample predictions:\")\n",
        "            for i in range(min(3, len(ds_df))):\n",
        "                title = str(ds_df.iloc[i][\"title\"])[:80]\n",
        "                pred  = ds_df.iloc[i][\"prediction\"]\n",
        "                conf  = ds_df.iloc[i][\"confidence\"]\n",
        "                if conf is not None:\n",
        "                    print(f\"- {title} ‚Üí {pred} (conf {conf:.3f})\")\n",
        "                else:\n",
        "                    print(f\"- {title} ‚Üí {pred}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è Daily Star evaluation error: {e}\")\n",
        "\n",
        "# ====================================================\n",
        "# RETRIEVAL QUALITY CHECK\n",
        "# ====================================================\n",
        "print(\"\\n=== üîç Retrieval Quality Check ===\")\n",
        "retrieve_tests = [\n",
        "    \"Bangladesh elections\",\n",
        "    \"Dhaka metro rail project\",\n",
        "    \"global oil prices\",\n",
        "    \"COVID treatment\"\n",
        "]\n",
        "\n",
        "retrieval_checked = 0\n",
        "if 'retrieve_top_k' in globals():\n",
        "    for query in retrieve_tests:\n",
        "        print(f\"\\nQuery: '{query}'\")\n",
        "        try:\n",
        "            results = retrieve_top_k(query, k=2)  # small k for quick check\n",
        "            if results:\n",
        "                retrieval_checked += 1\n",
        "                for i, res in enumerate(results, 1):\n",
        "                    snippet = res[\"text\"][:100] + (\"...\" if len(res[\"text\"]) > 100 else \"\")\n",
        "                    source_info = res.get('source', 'unknown')\n",
        "                    if isinstance(source_info, str) and len(source_info) > 60:\n",
        "                        source_info = source_info[:60] + \"...\"\n",
        "                    score = res.get(\"score\", None)\n",
        "                    score_part = f\" | Score: {score:.3f}\" if isinstance(score, (float, int)) else \"\"\n",
        "                    print(f\"  {i}. Source: {source_info}{score_part} | Snippet: {snippet}\")\n",
        "            else:\n",
        "                print(\"  No results found\")\n",
        "        except Exception as e:\n",
        "            print(f\"  ‚ùå Error retrieving for query '{query}': {e}\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è `retrieve_top_k` not available. Skipping retrieval check.\")\n",
        "\n",
        "# ====================================================\n",
        "# SAVE EVALUATION SUMMARY\n",
        "# ====================================================\n",
        "EVAL_PATH = PROC_DIR / \"evaluation_results.json\"\n",
        "\n",
        "eval_results = {\n",
        "    \"timestamp\": time.time(),\n",
        "    \"isot_classifier\": isot_metrics,\n",
        "    \"live_news\": {\n",
        "        \"count\": int(live_eval.get(\"count\", 0)),\n",
        "        \"avg_latency_sec\": float(np.mean([x[\"latency_sec\"] for x in live_eval[\"items\"]])) if live_eval.get(\"items\") else None\n",
        "    },\n",
        "    \"dailystar\": dailystar_summary,\n",
        "    \"retrieval_queries_tested\": int(len(retrieve_tests)),\n",
        "    \"retrieval_queries_with_results\": int(retrieval_checked)\n",
        "}\n",
        "\n",
        "try:\n",
        "    with open(EVAL_PATH, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(eval_results, f, indent=2, ensure_ascii=False)\n",
        "    print(f\"\\n‚úÖ Evaluation results saved to: {EVAL_PATH}\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Failed to save evaluation results: {e}\")\n",
        "\n",
        "print(\"\\n=== üìà Evaluation Summary ===\")\n",
        "print(f\"ISOT Classifier Performance: {isot_metrics}\")\n",
        "print(f\"Live Articles Processed: {eval_results['live_news']['count']}\")\n",
        "print(f\"Daily Star Preds: {dailystar_summary['count']} \"\n",
        "      f\"(Real={dailystar_summary['real']}, Fake={dailystar_summary['fake']})\")\n",
        "print(f\"Retrieval Queries Tested: {eval_results['retrieval_queries_tested']} \"\n",
        "      f\"(with results: {eval_results['retrieval_queries_with_results']})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "f-8npPEQqkp9",
        "outputId": "de1b025a-b02f-46ee-a8f3-280d7f88c188"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚ÑπÔ∏è Metrics file not found. Dummy metrics created and saved.\n",
            "üöÄ Starting Gradio interface...\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://3775b54688f3363a3d.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://3775b54688f3363a3d.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# ===== 9) REAL-TIME DEMO (GRADIO) =====\n",
        "import gradio as gr\n",
        "from newspaper import Article\n",
        "import datetime\n",
        "import joblib\n",
        "from pathlib import Path\n",
        "\n",
        "# ===== Setup processed directory and metrics =====\n",
        "PROC_DIR = Path(\"processed\")\n",
        "PROC_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "metrics_path = PROC_DIR / \"best_model_metrics.joblib\"\n",
        "\n",
        "# Auto-create dummy metrics if file doesn't exist\n",
        "if metrics_path.exists():\n",
        "    metrics = joblib.load(metrics_path)\n",
        "    print(f\"‚úÖ Metrics loaded: Accuracy={metrics.get('accuracy')}, F1={metrics.get('f1')}\")\n",
        "else:\n",
        "    metrics = {\"accuracy\": 0.0, \"f1\": 0.0}  # dummy values\n",
        "    joblib.dump(metrics, metrics_path)\n",
        "    print(\"‚ÑπÔ∏è Metrics file not found. Dummy metrics created and saved.\")\n",
        "\n",
        "# ===== Enhanced RAG inference =====\n",
        "def rag_infer(news_title: str, news_text: str, k: int = 5, use_llm: bool = True, extra_context: str = None) -> dict:\n",
        "    inp = f\"{news_title}. {news_text}\".strip()\n",
        "    retrieved = retrieve_top_k(inp, k=k)  # must have your retrieve_top_k defined\n",
        "    context_docs = [f\"{r['title']}\\n{r['text']}\" for r in retrieved]\n",
        "\n",
        "    if extra_context and len(extra_context.strip()) > 0:\n",
        "        context_docs.insert(0, f\"SCRAPED_CONTEXT:\\n{extra_context}\")\n",
        "\n",
        "    # Fast classifier\n",
        "    fast_label, fast_conf = None, None\n",
        "    if 'clf' in globals() and hasattr(clf, 'predict'):\n",
        "        try:\n",
        "            fast_emb = embedder.encode([inp], convert_to_numpy=True, normalize_embeddings=True)\n",
        "            fast_label = int(clf.predict(fast_emb)[0])\n",
        "            fast_conf = float(max(clf.predict_proba(fast_emb)[0]))\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Classifier prediction failed: {e}\")\n",
        "\n",
        "    # LLM output\n",
        "    llm_out = None\n",
        "    if use_llm:\n",
        "        llm_out = llm_classify_and_timeline(inp, context_docs, few_shots=few_shots)\n",
        "\n",
        "    # Final decision\n",
        "    if use_llm and llm_out and llm_out.get(\"classification\") in [\"Real\", \"Fake\"]:\n",
        "        final_class = llm_out[\"classification\"]\n",
        "        final_conf  = llm_out.get(\"confidence\")\n",
        "        timeline    = llm_out.get(\"timeline\")\n",
        "        reason      = llm_out.get(\"reason\", \"\")\n",
        "    elif fast_label is not None:\n",
        "        final_class = \"Real\" if fast_label == 1 else \"Fake\"\n",
        "        final_conf  = fast_conf\n",
        "        timeline    = None\n",
        "        reason      = \"LLM insufficient or disabled; used embedding classifier.\"\n",
        "    else:\n",
        "        final_class, final_conf, timeline, reason = \"Unknown\", None, None, \"No classifier available.\"\n",
        "\n",
        "    return {\n",
        "        \"input\": {\"title\": news_title, \"text\": news_text},\n",
        "        \"retrieved\": retrieved,\n",
        "        \"fast_classifier\": {\n",
        "            \"label\": (\"Real\" if fast_label == 1 else \"Fake\") if fast_label is not None else None,\n",
        "            \"confidence\": fast_conf,\n",
        "            \"accuracy\": metrics.get(\"accuracy\")\n",
        "        },\n",
        "        \"llm_output\": llm_out,\n",
        "        \"final\": {\n",
        "            \"label\": final_class,\n",
        "            \"confidence\": final_conf,\n",
        "            \"timeline\": timeline,\n",
        "            \"reason\": reason,\n",
        "            \"accuracy\": metrics.get(\"accuracy\")\n",
        "        }\n",
        "    }\n",
        "\n",
        "# ===== Gradio Prediction Function =====\n",
        "def ui_predict(news_text):\n",
        "    try:\n",
        "        if not news_text or len(news_text.strip()) < 10:\n",
        "            return \"‚ùå Please provide at least 10 characters of news text\", \"\"\n",
        "\n",
        "        # Clean input\n",
        "        news_text_clean = clean_text(news_text)  # must have clean_text defined\n",
        "        title = news_text_clean.split(\".\")[0][:120] if news_text_clean else \"News\"\n",
        "\n",
        "        # Scrape if URL\n",
        "        scraped_context, scraped_title = \"\", title\n",
        "        if news_text.startswith((\"http://\", \"https://\")):\n",
        "            try:\n",
        "                art = Article(news_text)\n",
        "                art.download()\n",
        "                art.parse()\n",
        "                scraped_context = art.text.strip()\n",
        "                scraped_title = art.title if art.title else title\n",
        "            except Exception as e:\n",
        "                scraped_context = f\"‚ö†Ô∏è Failed to scrape article: {str(e)}\"\n",
        "        else:\n",
        "            scraped_context = news_text_clean\n",
        "\n",
        "        # Run RAG inference\n",
        "        out = rag_infer(scraped_title, scraped_context, k=5, use_llm=True, extra_context=scraped_context)\n",
        "        final = out[\"final\"]\n",
        "\n",
        "        # Build result markdown\n",
        "        result = f\"## üéØ **Fact-Checking Result** ({datetime.date.today()})\\n\\n\"\n",
        "        label = final.get(\"label\", \"Unknown\")\n",
        "        if label == \"Real\":\n",
        "            result += \"<span style='color: green; font-weight: bold; font-size: 20px;'>‚úÖ REAL NEWS</span>\"\n",
        "        elif label == \"Fake\":\n",
        "            result += \"<span style='color: red; font-weight: bold; font-size: 20px;'>‚ùå FAKE NEWS</span>\"\n",
        "        else:\n",
        "            result += \"<span style='color: orange; font-weight: bold; font-size: 20px;'>‚ùì UNCERTAIN</span>\"\n",
        "\n",
        "        if final.get(\"confidence\"):\n",
        "            result += f\"  \\n**Confidence:** {final['confidence']:.3f}\"\n",
        "        if final.get(\"accuracy\"):\n",
        "            result += f\"  \\n**Model Accuracy (on test set):** {final['accuracy']:.3f}\"\n",
        "        if final.get(\"reason\"):\n",
        "            result += f\"  \\n**Reason:** {final['reason']}\"\n",
        "\n",
        "        if final.get(\"timeline\"):\n",
        "            result += \"\\n\\n## üìÖ **Timeline of Related Events:**\"\n",
        "            for line in final[\"timeline\"][:5]:\n",
        "                result += f\"\\n- üìå {line}\"\n",
        "\n",
        "        # Evidence\n",
        "        retrieved_view = \"## üîç **Retrieved Context Sources:**\\n\\n\"\n",
        "        if out[\"retrieved\"]:\n",
        "            for i, r in enumerate(out[\"retrieved\"][:3], start=1):\n",
        "                source_type = \"üìÅ Other\"\n",
        "                if r.get(\"source\") == \"isot\":\n",
        "                    source_type = \"üì∞ Archive (ISOT)\"\n",
        "                elif r.get(\"source\") == \"scraped\":\n",
        "                    source_type = \"üåê Live Scraped News\"\n",
        "                snippet = (r[\"text\"][:400] + \"‚Ä¶\") if len(r[\"text\"]) > 400 else r[\"text\"]\n",
        "                retrieved_view += f\"### Source {i} (Relevance: {r['score']:.3f})\\n**{source_type}**\\n{snippet}\\n---\\n\"\n",
        "        else:\n",
        "            retrieved_view += \"‚ö†Ô∏è No relevant context found in current databases.\"\n",
        "\n",
        "        return result, retrieved_view\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è UI Prediction Error: {e}\")\n",
        "        return f\"‚ùå Error: {str(e)}\", \"Please try again with different text.\"\n",
        "\n",
        "# ===== Gradio UI =====\n",
        "with gr.Blocks(title=\"Bangladesh News Fact-Checker\", theme=gr.themes.Soft()) as demo:\n",
        "    gr.Markdown(\"\"\"\n",
        "    # üì∞ Bangladesh News Fact-Checker\n",
        "    ## Real-time RAG + Azure LLM + Live Scraping\n",
        "\n",
        "    *Fact-check Bangladeshi news using AI and live context retrieval*\n",
        "    \"\"\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=2):\n",
        "            gr.Markdown(\"### üìù Enter News Article or URL\")\n",
        "            inp = gr.Textbox(lines=10, label=\"Paste article text or URL\", placeholder=\"URL or article text\", max_lines=15)\n",
        "            btn = gr.Button(\"üîç Analyze & Verify\", variant=\"primary\")\n",
        "\n",
        "        with gr.Column(scale=3):\n",
        "            gr.Markdown(\"### üìä Results\")\n",
        "            out_md = gr.Markdown(value=\"*Results will appear here after analysis...*\")\n",
        "            gr.Markdown(\"### üîç Evidence\")\n",
        "            ctx_md = gr.Markdown(value=\"*Context will appear here...*\")\n",
        "\n",
        "    gr.Examples(\n",
        "        examples=[\n",
        "            \"https://www.thedailystar.net/news/bangladesh/politics/news/pm-meets-opposition-leaders-3472166\",\n",
        "            \"Prime Minister announced new healthcare funding of 500 million taka\",\n",
        "            \"A secret herbal cure eliminates COVID-19 instantly without treatment\"\n",
        "        ],\n",
        "        inputs=inp,\n",
        "        label=\"üí° Try these:\"\n",
        "    )\n",
        "\n",
        "    btn.click(ui_predict, inputs=[inp], outputs=[out_md, ctx_md])\n",
        "\n",
        "# Launch\n",
        "print(\"üöÄ Starting Gradio interface...\")\n",
        "demo.launch(share=True, server_name=\"0.0.0.0\", show_error=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "WPm1eaU4u6Fv"
      },
      "outputs": [],
      "source": [
        "# Save/Load small project config (optional)\n",
        "CONFIG_PATH = BASE_DIR / \"config.json\"\n",
        "\n",
        "def save_config(**kwargs):\n",
        "    cfg = {}\n",
        "    if CONFIG_PATH.exists():\n",
        "        try:\n",
        "            cfg = json.loads(CONFIG_PATH.read_text())\n",
        "        except Exception:\n",
        "            cfg = {}\n",
        "    cfg.update(kwargs)\n",
        "    CONFIG_PATH.write_text(json.dumps(cfg, indent=2))\n",
        "    print(\"Config saved:\", CONFIG_PATH)\n",
        "\n",
        "def load_config():\n",
        "    if CONFIG_PATH.exists():\n",
        "        return json.loads(CONFIG_PATH.read_text())\n",
        "    return {}\n",
        "\n",
        "# Example:\n",
        "# save_config(azure_endpoint=AZURE_ENDPOINT, deployment=AZURE_DEPLOYMENT)\n",
        "# print(load_config())\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0072a138386946ea81513fc31686eba8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "00d835220a134d9894ec9ca61182dca8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "031e78b85e694f1691b2025e8df50f91": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "04014c3dc9af461aa4c646a8fd3583da": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0464c326ac564d579fbe73ebd012e90a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db1a31a0375a4880be9eeb18abb29e73",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_a241b6e430424a54abea72fbc8b2cdcc",
            "value": "‚Äá350/350‚Äá[00:00&lt;00:00,‚Äá33.7kB/s]"
          }
        },
        "05e22d82b626439b8b571cb5562e9adf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f296912f9b1c4c9db3ce031becda7e09",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_0c3dda43cbff46c7bd0f95efdf8eb9b1",
            "value": "tokenizer.json:‚Äá"
          }
        },
        "06ec69c82f254aa8a36101b816723e55": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "073aaa7d800648699288619ed9595582": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0e9a74fdd2ad440f995d8cffed3ff9e7",
              "IPY_MODEL_78fae15523c349a39849802d10f270b3",
              "IPY_MODEL_720c0c8b186c4214a5d09fdf1b4eb2c5"
            ],
            "layout": "IPY_MODEL_1b7e17aeb2bd4f4c958509e2dcf85274"
          }
        },
        "074b6dc9a2d24607b9bb8706e74f4ce8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0aae48e5fb854dd398898b078db9200c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0c3dda43cbff46c7bd0f95efdf8eb9b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0cac8e0a9407486cab22195ea3f43938": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d25f9e7460b84cd38709afd757d22a86",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_d393aa1e9cea44239435f8e7ebd5747d",
            "value": "model.safetensors:‚Äá100%"
          }
        },
        "0e9a74fdd2ad440f995d8cffed3ff9e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0072a138386946ea81513fc31686eba8",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_ff905cbc53944959b7d2f566edf86ee0",
            "value": "README.md:‚Äá"
          }
        },
        "0ec0626b95d3465b95fce6dcb343385b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b5e4eecab2b24ec892db0e006ab10fcd",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_8ad37d379eea4c9284d9a4aa3df16b65",
            "value": "Batches:‚Äá100%"
          }
        },
        "0f057ca26f1f4392950c872b752a9d00": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14d415dc6cf34b438997e2c2432322c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5cac2c8000b455abf136cac4c0cbc19",
            "max": 1205,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e0ae953f90ca4fab9dcdd4648fdf17e8",
            "value": 1205
          }
        },
        "17f6619ed1a542a2a904d5c26d1afed5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1add4484d62d48f9ac4bf7cd8ef8943b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1b2c2fc026c3401b9fa76c9e653baf27": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d07913d38c443449dad825f84a291e8",
            "max": 217,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_770af29837c54b328f0fbb5650261591",
            "value": 217
          }
        },
        "1b7e17aeb2bd4f4c958509e2dcf85274": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ccc32a07af94551abaad81ca76b7d36": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_54386a0a68c348c3aaf05717a93581c7",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_ba61a61a707e4f12a5c4f5ada82a0afe",
            "value": "‚Äá90.9M/90.9M‚Äá[00:01&lt;00:00,‚Äá67.5MB/s]"
          }
        },
        "1d94cfe2f2ed4cfdbc560956b1dfa6c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57a252f89c5f4dbca6f762a1adf69669",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_4f75e53a9f614e1c80d472bff9c8140f",
            "value": "vocab.txt:‚Äá"
          }
        },
        "1ddaa8806cd2490d8f0c58962a15ff09": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f1cf1f11d514086a6aa8b4c351dc879": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_768134f2917c4e608b44a5b08adc98d1",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_66a578809f74419fb0b005f6ea3a3685",
            "value": "‚Äá232k/?‚Äá[00:00&lt;00:00,‚Äá12.8MB/s]"
          }
        },
        "205ad7b7b4ed462da27cecbca3d17fa9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3bab2a2407744a628ea08a109d42cc09",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_06ec69c82f254aa8a36101b816723e55",
            "value": "Batches:‚Äá100%"
          }
        },
        "215f5ef8a0544666a08b4561d986ab3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_24dbbfd546624dbe9fa792a69a5dd5c5",
              "IPY_MODEL_bf838dfdc9e84e939da40419ee168b2c",
              "IPY_MODEL_dd6039a0f6224492a472f5be47fedd9f"
            ],
            "layout": "IPY_MODEL_b3aeb2e5f52f4580b941dd17af06cd3c"
          }
        },
        "23d5c3ea6ec7415aa8f975ca817e4050": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24dbbfd546624dbe9fa792a69a5dd5c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ad64d8e7d3b4c86ac8ac55382630278",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_77aaf5fa5ab9418d9b2a9d2000aeec10",
            "value": "special_tokens_map.json:‚Äá100%"
          }
        },
        "26472bcf39734d33950ddc12e5dd123b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26b7dcb1622a45439c3c9b0671b4eae5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28816f7017014f00b7b9f01f1c9da8df": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_819327bf3744425796173ee322e3713e",
              "IPY_MODEL_c3efff7950694371ab5c2b6bb0ec7475",
              "IPY_MODEL_3ae8c99acb014c40b60e34013813cc05"
            ],
            "layout": "IPY_MODEL_8b23374b437b49a39d56b8386b4d3c75"
          }
        },
        "2aa2f94e7df0442c8b43e5ed43810e02": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d1faa0237e64ea28735751f9d79bc47": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3dca4dfa644e47268d3e11869eec8863",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_734b599fe6e1407e9f2d49c1ce2fe438",
            "value": "‚Äá53.0/53.0‚Äá[00:00&lt;00:00,‚Äá3.68kB/s]"
          }
        },
        "2f9ad5024a3e4d018e1daa8c7b59e536": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f4848866aed14d0b9c34ed83517c3ffa",
              "IPY_MODEL_ab49787838f9431e8989c4353ac06cc4",
              "IPY_MODEL_de634170aae94f0f908241d053355240"
            ],
            "layout": "IPY_MODEL_1ddaa8806cd2490d8f0c58962a15ff09"
          }
        },
        "2ffff4a0f1f34318b40c69518d79f808": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_83468de6793749fbaa9c34bebd9a0762",
              "IPY_MODEL_87be023f37f044f292ee1d0cefef7db6",
              "IPY_MODEL_56a6a3129a064378ad1b6fb8b41201dd"
            ],
            "layout": "IPY_MODEL_a6deb61e62964882ac4a82e048029a3f"
          }
        },
        "3370a3cccfc74ebc8bedc04fe34b8660": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9aa1c83fd6404a0997d41b3144c5fbe9",
              "IPY_MODEL_b722e6dde45f40ad91de2c73cc8568d5",
              "IPY_MODEL_7cddaf24bc9749acaa67aac27b92182b"
            ],
            "layout": "IPY_MODEL_6bfd5b1568924b0cb8636523ee5137d9"
          }
        },
        "39da3935f477495bba954048ed3071c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3ae8c99acb014c40b60e34013813cc05": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc70116afe1f4259bdf5a71e24f71b12",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_78f5be1d67e2495ca555018d94bdec84",
            "value": "‚Äá612/612‚Äá[00:00&lt;00:00,‚Äá39.0kB/s]"
          }
        },
        "3bab2a2407744a628ea08a109d42cc09": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3dca4dfa644e47268d3e11869eec8863": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e69a032c52343328ffd1a009f982a05": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "41660cd5b6484e918a7b5a28a5b7b1c0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44be934c6dd24cfe8d20f2ed7579b478": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "483b033f5aa04f21a66b0009c2f58462": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4a845836d78847528d3954188cb5ec6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_05e22d82b626439b8b571cb5562e9adf",
              "IPY_MODEL_4b632dafd1f243ea82e172dd43a795b1",
              "IPY_MODEL_f0cdba05febf42f69330938839cd211e"
            ],
            "layout": "IPY_MODEL_26b7dcb1622a45439c3c9b0671b4eae5"
          }
        },
        "4ad64d8e7d3b4c86ac8ac55382630278": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b632dafd1f243ea82e172dd43a795b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_852d66f125f34983a7a4dd0dbdce010f",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5627043e037d4a8db3d62fb4296b1c97",
            "value": 1
          }
        },
        "4f0bcc794983420d834d495fc69c0260": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4f75e53a9f614e1c80d472bff9c8140f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5053df7e4b894db4a9a3e5dd57b0e3d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0cac8e0a9407486cab22195ea3f43938",
              "IPY_MODEL_7e1358ec934741de8d4c39ce35d172cb",
              "IPY_MODEL_1ccc32a07af94551abaad81ca76b7d36"
            ],
            "layout": "IPY_MODEL_df132ecf32664796a26eff18ba1d2905"
          }
        },
        "508e5a0bd3f9472ea76c040d0c128b2d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50f67d13731247c2a74a34c20d6ad938": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5201d68284db4ede9a924ab7364a9e6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5389f2b090e046b3bbc0a04d3f9d4db5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc8bbe6be44b4efbb071721fe69368c9",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_efff53f20e1746e1b3af769d231ba9db",
            "value": "tokenizer_config.json:‚Äá100%"
          }
        },
        "54386a0a68c348c3aaf05717a93581c7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5627043e037d4a8db3d62fb4296b1c97": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "56a6a3129a064378ad1b6fb8b41201dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_17f6619ed1a542a2a904d5c26d1afed5",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_7811768fd2014554b4296cad8d7eee34",
            "value": "‚Äá868/868‚Äá[01:30&lt;00:00,‚Äá38.30it/s]"
          }
        },
        "57a252f89c5f4dbca6f762a1adf69669": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58e605f041e64a76aac13329838ec4bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_205ad7b7b4ed462da27cecbca3d17fa9",
              "IPY_MODEL_14d415dc6cf34b438997e2c2432322c3",
              "IPY_MODEL_ddcf823a347944c293374f5755c2ffe0"
            ],
            "layout": "IPY_MODEL_a0b233b8b84a40b4841bfdfea3b5fcac"
          }
        },
        "5a09c93c579542c19be9dba04e9ea8c9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c027b3f1f254500a17991e789be5d55": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5cd9d26d6c6344b6af47de1160de74dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d6d0f00347c4af0809623d06967ecd5",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_e77b4ebbb2d84e9e92aa42f2833e226a",
            "value": "‚Äá1205/1205‚Äá[02:02&lt;00:00,‚Äá46.71it/s]"
          }
        },
        "6174e162802848a48974c8090e534b6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "623029aa8f1f4550884eaac59b66334d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "627a8094044940a9a869064ba240470d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "655cd10efac14126adb8a82dff15033f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66a578809f74419fb0b005f6ea3a3685": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6af96c869f8e4e87a3ee8b1e7708847b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6b02d55696a945cf9e0a551e4a48790e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b109ac4c2fb4298848155d2ca086e87": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6bfd5b1568924b0cb8636523ee5137d9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d07913d38c443449dad825f84a291e8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f6e83929dac4fc3bf9df7dae6d9a8ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "720c0c8b186c4214a5d09fdf1b4eb2c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8299d8e55bff443382ba45b66ceb6308",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_39da3935f477495bba954048ed3071c1",
            "value": "‚Äá10.5k/?‚Äá[00:00&lt;00:00,‚Äá548kB/s]"
          }
        },
        "7253acf5fdf0493c9e936c2c5c6ae9f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5389f2b090e046b3bbc0a04d3f9d4db5",
              "IPY_MODEL_d9bdd5ed3b3a48e3a79a0ada5aeafed9",
              "IPY_MODEL_0464c326ac564d579fbe73ebd012e90a"
            ],
            "layout": "IPY_MODEL_e208c8e75c044c60bff704344b33fb45"
          }
        },
        "734b599fe6e1407e9f2d49c1ce2fe438": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "768134f2917c4e608b44a5b08adc98d1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76bb6e0ba048489ca89f0f417e1d8b9f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "770af29837c54b328f0fbb5650261591": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7786863e4595462d87f503ffa2e8e699": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77aaf5fa5ab9418d9b2a9d2000aeec10": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7811768fd2014554b4296cad8d7eee34": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "78a18a14ba2f41bfae95b30e6b3afe21": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac992cc0c3684def8d883dc472fad3ff",
            "max": 116,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a4de35a08564472c83f9355c20028e77",
            "value": 116
          }
        },
        "78f5be1d67e2495ca555018d94bdec84": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "78fae15523c349a39849802d10f270b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9141647d1c04412b64f185a783c1f15",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d1a836be77cf44e98580127d77131514",
            "value": 1
          }
        },
        "7c841c0351af4271ba207e52a38dc4f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b02d55696a945cf9e0a551e4a48790e",
            "max": 1205,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c9b3c29bdf3d4dac979200b31c820d39",
            "value": 1205
          }
        },
        "7cddaf24bc9749acaa67aac27b92182b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a04a817b04664b3489cc904de9a55372",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_5201d68284db4ede9a924ab7364a9e6a",
            "value": "‚Äá190/190‚Äá[00:00&lt;00:00,‚Äá19.1kB/s]"
          }
        },
        "7d6d0f00347c4af0809623d06967ecd5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7da29a3c8de34ac79660dfcb9611543f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e1358ec934741de8d4c39ce35d172cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_26472bcf39734d33950ddc12e5dd123b",
            "max": 90868376,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_483b033f5aa04f21a66b0009c2f58462",
            "value": 90868376
          }
        },
        "80499a2236a6468f9900cbb2e96ee9f6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "808ac88693ed4a568cd708471494f5a4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "819327bf3744425796173ee322e3713e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc78f3a22a174727a95197bb028ed3b4",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_c00f810178144fa49b3d61e2e1afe685",
            "value": "config.json:‚Äá100%"
          }
        },
        "8299d8e55bff443382ba45b66ceb6308": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83468de6793749fbaa9c34bebd9a0762": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7786863e4595462d87f503ffa2e8e699",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_3e69a032c52343328ffd1a009f982a05",
            "value": "Batches:‚Äá100%"
          }
        },
        "84b8446ee385402d8383bc2664496862": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "852d66f125f34983a7a4dd0dbdce010f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "87a2a3f5059c4943b4dadc6d38040510": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad73f82470f94dcda3c7cfcef1551ec3",
            "max": 643,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_de23b16033b540e7be5136077ce1df3b",
            "value": 643
          }
        },
        "87be023f37f044f292ee1d0cefef7db6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb0d9b67408f4dd0ae03e503f5e20c61",
            "max": 868,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_074b6dc9a2d24607b9bb8706e74f4ce8",
            "value": 868
          }
        },
        "8ad37d379eea4c9284d9a4aa3df16b65": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8b23374b437b49a39d56b8386b4d3c75": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "963109c277a64d8198c91192594f485b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23d5c3ea6ec7415aa8f975ca817e4050",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_623029aa8f1f4550884eaac59b66334d",
            "value": "config_sentence_transformers.json:‚Äá100%"
          }
        },
        "9a876577cacc46fb9c5782b7fbc51970": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9aa1c83fd6404a0997d41b3144c5fbe9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f208df844b974a928609a6a8eac792d9",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_6f6e83929dac4fc3bf9df7dae6d9a8ff",
            "value": "config.json:‚Äá100%"
          }
        },
        "9aa98daf9603439081e0ec54990c8b9a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9cda829e683d4a41ac148540612d2a43": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0ec0626b95d3465b95fce6dcb343385b",
              "IPY_MODEL_1b2c2fc026c3401b9fa76c9e653baf27",
              "IPY_MODEL_d9a9e55000ce4dc1afde50c9372bbad1"
            ],
            "layout": "IPY_MODEL_76bb6e0ba048489ca89f0f417e1d8b9f"
          }
        },
        "9f6b68e5b86b47578c433338eb0eb0ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9fdb7a17910e4aa4ab0b3731cb658474": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a04a817b04664b3489cc904de9a55372": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0b233b8b84a40b4841bfdfea3b5fcac": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a241b6e430424a54abea72fbc8b2cdcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a2473a44d0e546a5aaf0f7ba73d9cd05": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a359bf0eccc746549e17dd2e25638475": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4de35a08564472c83f9355c20028e77": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a6d4d1926e05489599d8e225a27c2392": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6deb61e62964882ac4a82e048029a3f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7240b3d85ba4a65a607fffbf08a4180": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc294c2ac4384404994bd9cd67542def",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_bf8606531011440dbb0d1aa47fbf2c33",
            "value": "Batches:‚Äá100%"
          }
        },
        "ab49787838f9431e8989c4353ac06cc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a359bf0eccc746549e17dd2e25638475",
            "max": 349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6b109ac4c2fb4298848155d2ca086e87",
            "value": 349
          }
        },
        "ac992cc0c3684def8d883dc472fad3ff": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad73f82470f94dcda3c7cfcef1551ec3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2bfc3119ead46059fb9d29a85cdd307": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff0f01e2f8114b91ae720deac404c5a2",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_6af96c869f8e4e87a3ee8b1e7708847b",
            "value": "sentence_bert_config.json:‚Äá100%"
          }
        },
        "b3aeb2e5f52f4580b941dd17af06cd3c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b47f36d9e2664f599ce59179bf2bedee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a09c93c579542c19be9dba04e9ea8c9",
            "max": 53,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6174e162802848a48974c8090e534b6a",
            "value": 53
          }
        },
        "b4a9719dbf2d4e70b370d48f66299aa2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_41660cd5b6484e918a7b5a28a5b7b1c0",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_0aae48e5fb854dd398898b078db9200c",
            "value": "‚Äá643/643‚Äá[02:17&lt;00:00,‚Äá19.16it/s]"
          }
        },
        "b5e4eecab2b24ec892db0e006ab10fcd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b722e6dde45f40ad91de2c73cc8568d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f057ca26f1f4392950c872b752a9d00",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_44be934c6dd24cfe8d20f2ed7579b478",
            "value": 190
          }
        },
        "ba61a61a707e4f12a5c4f5ada82a0afe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bac9c8af2f00460b9f86b988809e7d76": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50f67d13731247c2a74a34c20d6ad938",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_031e78b85e694f1691b2025e8df50f91",
            "value": "‚Äá116/116‚Äá[00:00&lt;00:00,‚Äá7.62kB/s]"
          }
        },
        "bb0d9b67408f4dd0ae03e503f5e20c61": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc294c2ac4384404994bd9cd67542def": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc70116afe1f4259bdf5a71e24f71b12": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc8bbe6be44b4efbb071721fe69368c9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf5e254fecbc4e63906b5297a0ddfeee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a7240b3d85ba4a65a607fffbf08a4180",
              "IPY_MODEL_7c841c0351af4271ba207e52a38dc4f8",
              "IPY_MODEL_5cd9d26d6c6344b6af47de1160de74dc"
            ],
            "layout": "IPY_MODEL_d6262c95976e439d9961c79473e8257e"
          }
        },
        "bf838dfdc9e84e939da40419ee168b2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dbc3d6be1300404e96463b436b18f15a",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_00d835220a134d9894ec9ca61182dca8",
            "value": 112
          }
        },
        "bf8606531011440dbb0d1aa47fbf2c33": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bfd5d7316e9e43cc9c3e03152965ca55": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1d94cfe2f2ed4cfdbc560956b1dfa6c8",
              "IPY_MODEL_cb9540ef20ea4ae1b72ad68e0cc87c53",
              "IPY_MODEL_1f1cf1f11d514086a6aa8b4c351dc879"
            ],
            "layout": "IPY_MODEL_508e5a0bd3f9472ea76c040d0c128b2d"
          }
        },
        "c00f810178144fa49b3d61e2e1afe685": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c2567507212542efae5971e7a17dd52d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3efff7950694371ab5c2b6bb0ec7475": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7da29a3c8de34ac79660dfcb9611543f",
            "max": 612,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a2473a44d0e546a5aaf0f7ba73d9cd05",
            "value": 612
          }
        },
        "c7affbf1141346f297f8f6dd025fe283": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b2bfc3119ead46059fb9d29a85cdd307",
              "IPY_MODEL_b47f36d9e2664f599ce59179bf2bedee",
              "IPY_MODEL_2d1faa0237e64ea28735751f9d79bc47"
            ],
            "layout": "IPY_MODEL_c2567507212542efae5971e7a17dd52d"
          }
        },
        "c8197f984195441eb211f30cd2c1a5b3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c99c6694ca4e4e8385416df0a2dbabd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80499a2236a6468f9900cbb2e96ee9f6",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_1add4484d62d48f9ac4bf7cd8ef8943b",
            "value": "Batches:‚Äá100%"
          }
        },
        "c9b3c29bdf3d4dac979200b31c820d39": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cb9540ef20ea4ae1b72ad68e0cc87c53": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_808ac88693ed4a568cd708471494f5a4",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ff0ee30d0b594e768df74b1311d3bf54",
            "value": 1
          }
        },
        "d1a836be77cf44e98580127d77131514": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d25f9e7460b84cd38709afd757d22a86": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d393aa1e9cea44239435f8e7ebd5747d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d49b83e1ec92416d8aecbfd3c1be3f4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d6262c95976e439d9961c79473e8257e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9141647d1c04412b64f185a783c1f15": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "d9a9e55000ce4dc1afde50c9372bbad1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2aa2f94e7df0442c8b43e5ed43810e02",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_4f0bcc794983420d834d495fc69c0260",
            "value": "‚Äá217/217‚Äá[00:22&lt;00:00,‚Äá28.11it/s]"
          }
        },
        "d9bdd5ed3b3a48e3a79a0ada5aeafed9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6d4d1926e05489599d8e225a27c2392",
            "max": 350,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9f6b68e5b86b47578c433338eb0eb0ca",
            "value": 350
          }
        },
        "db1a31a0375a4880be9eeb18abb29e73": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbc3d6be1300404e96463b436b18f15a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc78f3a22a174727a95197bb028ed3b4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd6039a0f6224492a472f5be47fedd9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_655cd10efac14126adb8a82dff15033f",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_04014c3dc9af461aa4c646a8fd3583da",
            "value": "‚Äá112/112‚Äá[00:00&lt;00:00,‚Äá7.26kB/s]"
          }
        },
        "ddcf823a347944c293374f5755c2ffe0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_627a8094044940a9a869064ba240470d",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_84b8446ee385402d8383bc2664496862",
            "value": "‚Äá1205/1205‚Äá[02:02&lt;00:00,‚Äá46.83it/s]"
          }
        },
        "de23b16033b540e7be5136077ce1df3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "de634170aae94f0f908241d053355240": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f473b89b15a1485d95529d3a1ecd1ed5",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_9a876577cacc46fb9c5782b7fbc51970",
            "value": "‚Äá349/349‚Äá[00:00&lt;00:00,‚Äá37.6kB/s]"
          }
        },
        "df132ecf32664796a26eff18ba1d2905": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0ae953f90ca4fab9dcdd4648fdf17e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e208c8e75c044c60bff704344b33fb45": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e77b4ebbb2d84e9e92aa42f2833e226a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ef8d017153304b8f8b6e5adbbf061296": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c99c6694ca4e4e8385416df0a2dbabd2",
              "IPY_MODEL_87a2a3f5059c4943b4dadc6d38040510",
              "IPY_MODEL_b4a9719dbf2d4e70b370d48f66299aa2"
            ],
            "layout": "IPY_MODEL_efc0489f16764aae9c4bd190a42fda84"
          }
        },
        "efc0489f16764aae9c4bd190a42fda84": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "efff53f20e1746e1b3af769d231ba9db": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f0cdba05febf42f69330938839cd211e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8197f984195441eb211f30cd2c1a5b3",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_9fdb7a17910e4aa4ab0b3731cb658474",
            "value": "‚Äá466k/?‚Äá[00:00&lt;00:00,‚Äá28.6MB/s]"
          }
        },
        "f208df844b974a928609a6a8eac792d9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f296912f9b1c4c9db3ce031becda7e09": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f473b89b15a1485d95529d3a1ecd1ed5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4848866aed14d0b9c34ed83517c3ffa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c027b3f1f254500a17991e789be5d55",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_d49b83e1ec92416d8aecbfd3c1be3f4b",
            "value": "modules.json:‚Äá100%"
          }
        },
        "f4e9109c2019456daad2e2033a4e1b2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_963109c277a64d8198c91192594f485b",
              "IPY_MODEL_78a18a14ba2f41bfae95b30e6b3afe21",
              "IPY_MODEL_bac9c8af2f00460b9f86b988809e7d76"
            ],
            "layout": "IPY_MODEL_9aa98daf9603439081e0ec54990c8b9a"
          }
        },
        "f5cac2c8000b455abf136cac4c0cbc19": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff0ee30d0b594e768df74b1311d3bf54": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ff0f01e2f8114b91ae720deac404c5a2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff905cbc53944959b7d2f566edf86ee0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
